{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1afecbd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.25.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import fiftyone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68c114a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading split 'train' to '../../coco_dataset\\train' if necessary\n",
      "Found annotations at '..\\..\\coco_dataset\\raw\\instances_train2017.json'\n",
      "65 images found; downloading the remaining 84121\n",
      " 100% |██████████████| 84121/84121 [2.7h elapsed, 0s remaining, 3.0 images/s]       \n",
      "Writing annotations for 84195 downloaded samples to '../../coco_dataset\\train\\labels.json'\n",
      "Dataset info written to '../../coco_dataset\\info.json'\n",
      "Loading 'coco-2017' split 'train'\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Failed to construct importer of type <class 'fiftyone.utils.coco.COCODetectionDatasetImporter'> using the provided parameters. See above for the error. You may need to supply additional mandatory arguments. Please consult the documentation of <class 'fiftyone.utils.coco.COCODetectionDatasetImporter'> to learn more",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fiftyone\\utils\\data\\importers.py\u001b[0m in \u001b[0;36mbuild_dataset_importer\u001b[1;34m(dataset_type, strip_none, warn_unused, name, **kwargs)\u001b[0m\n\u001b[0;32m    597\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m         \u001b[0mdataset_importer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset_importer_cls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    599\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fiftyone\\utils\\coco.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, dataset_dir, data_path, labels_path, label_types, classes, image_ids, include_id, include_annotation_id, include_license, extra_attrs, only_matching, use_polylines, tolerance, shuffle, seed, max_samples)\u001b[0m\n\u001b[0;32m    378\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 379\u001b[1;33m         \u001b[0m_label_types\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_parse_label_types\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    380\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fiftyone\\utils\\coco.py\u001b[0m in \u001b[0;36m_parse_label_types\u001b[1;34m(label_types)\u001b[0m\n\u001b[0;32m   1769\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbad_types\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1770\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m   1771\u001b[0m             \u001b[1;34m\"Unsupported label type '%s'. Supported types are %s\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unsupported label type 'captions'. Supported types are ['detections', 'segmentations', 'keypoints']",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16568/617592958.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m dataset = fiftyone.zoo.load_zoo_dataset(\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;34m\"coco-2017\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m#split=\"validation\",\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0msplit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"train\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mlabel_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"captions\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fiftyone\\zoo\\datasets\\__init__.py\u001b[0m in \u001b[0;36mload_zoo_dataset\u001b[1;34m(name, split, splits, label_field, dataset_name, dataset_dir, download_if_necessary, drop_existing_dataset, overwrite, cleanup, **kwargs)\u001b[0m\n\u001b[0;32m    337\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Loading '%s' split '%s'\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzoo_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m             \u001b[0msplit_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzoo_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_split_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 339\u001b[1;33m             dataset_importer, _ = foud.build_dataset_importer(\n\u001b[0m\u001b[0;32m    340\u001b[0m                 \u001b[0mdataset_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msplit_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mimporter_kwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m             )\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fiftyone\\utils\\data\\importers.py\u001b[0m in \u001b[0;36mbuild_dataset_importer\u001b[1;34m(dataset_type, strip_none, warn_unused, name, **kwargs)\u001b[0m\n\u001b[0;32m    598\u001b[0m         \u001b[0mdataset_importer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset_importer_cls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    601\u001b[0m             \u001b[1;34m\"Failed to construct importer of type %s using the provided \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m             \u001b[1;34m\"parameters. See above for the error. You may need to supply \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to construct importer of type <class 'fiftyone.utils.coco.COCODetectionDatasetImporter'> using the provided parameters. See above for the error. You may need to supply additional mandatory arguments. Please consult the documentation of <class 'fiftyone.utils.coco.COCODetectionDatasetImporter'> to learn more"
     ]
    }
   ],
   "source": [
    "dataset = fiftyone.zoo.load_zoo_dataset(\n",
    "    \"coco-2017\",\n",
    "    #split=\"validation\",\n",
    "    split=\"train\",\n",
    "    label_types=[\"captions\"],\n",
    "    classes=[\"person\", \"car\", \"bird\", \"cat\", \"dog\", \"horse\", \"cow\", \"bear\", \"airplane\", \"bus\", \"train\", \"backpack\", \"truck\", \"boat\", \"bottle\", \"fork\", \"banana\", \"apple\", \"pizza\", \"chair\", \"couch\", \"dining table\", \"tv\", \"laptop\", \"cell phone\", \"sink\", \"book\", \"clock\", \"carrot\", \"sandwich\", \"bowl\", \"elephant\"],\n",
    "    max_samples=84186,\n",
    "    dataset_dir='../../coco_dataset'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac254875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84195\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "#скопировать картинки в основную папку\n",
    "p = Path('E:/PYTHON/coco_dataset/train/data')\n",
    "print(len(list(p.rglob(\"*\"))))\n",
    "for img_name in p.rglob(\"*\"):\n",
    "    #print(img_name)\n",
    "    img_name_short = str(img_name).replace('E:\\\\PYTHON\\\\coco_dataset\\\\train\\\\data\\\\', '')\n",
    "    shutil.copyfile(img_name, 'data\\imgs\\\\' + img_name_short)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fdcbb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "path = 'E:/PYTHON/coco_dataset/raw/captions_train2017.json'\n",
    "#df = pd.read_json(path)\n",
    "#df\n",
    "\n",
    "f = open(path)\n",
    "# returns JSON object as\n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    "# Closing file\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a6b68c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['info', 'licenses', 'images', 'annotations'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72995ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = pd.DataFrame(data['images'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d17d2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = pd.DataFrame(data['annotations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61e5e38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = images.merge(annotations, on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfd07d33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000000391895.jpg</td>\n",
       "      <td>A cow on a hill top looking for something to eat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000000522418.jpg</td>\n",
       "      <td>A rustic wood kitchen with rustic cabinets, ki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000000184613.jpg</td>\n",
       "      <td>A street with signs, people, cars and a lamppost.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000000318219.jpg</td>\n",
       "      <td>A person on the horse halfway in the lake.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000000574769.jpg</td>\n",
       "      <td>The young woman behind the bar is pouring a dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84181</th>\n",
       "      <td>000000053136.jpg</td>\n",
       "      <td>Woman giving a man a stuffed teddy bear.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84182</th>\n",
       "      <td>000000471345.jpg</td>\n",
       "      <td>A man with a racquet that is standing on a ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84183</th>\n",
       "      <td>000000444010.jpg</td>\n",
       "      <td>A fridge in the kitchen with many notes attach...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84184</th>\n",
       "      <td>000000565004.jpg</td>\n",
       "      <td>A bowl filled with food sitting on a plate.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84185</th>\n",
       "      <td>000000516168.jpg</td>\n",
       "      <td>A CUP OF COFFEE SITTING ON A DESK FULL OF PAPE...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84186 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              file_name                                            caption\n",
       "0      000000391895.jpg   A cow on a hill top looking for something to eat\n",
       "1      000000522418.jpg  A rustic wood kitchen with rustic cabinets, ki...\n",
       "2      000000184613.jpg  A street with signs, people, cars and a lamppost.\n",
       "3      000000318219.jpg        A person on the horse halfway in the lake. \n",
       "4      000000574769.jpg  The young woman behind the bar is pouring a dr...\n",
       "...                 ...                                                ...\n",
       "84181  000000053136.jpg           Woman giving a man a stuffed teddy bear.\n",
       "84182  000000471345.jpg  A man with a racquet that is standing on a ten...\n",
       "84183  000000444010.jpg  A fridge in the kitchen with many notes attach...\n",
       "84184  000000565004.jpg        A bowl filled with food sitting on a plate.\n",
       "84185  000000516168.jpg  A CUP OF COFFEE SITTING ON A DESK FULL OF PAPE...\n",
       "\n",
       "[84186 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['file_name', 'caption']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fdd9e5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        <<000000391895.jpg>>description: A cow on a hi...\n",
       "1        <<000000522418.jpg>>description: A rustic wood...\n",
       "2        <<000000184613.jpg>>description: A street with...\n",
       "3        <<000000318219.jpg>>description: A person on t...\n",
       "4        <<000000574769.jpg>>description: The young wom...\n",
       "                               ...                        \n",
       "84181    <<000000053136.jpg>>description: Woman giving ...\n",
       "84182    <<000000471345.jpg>>description: A man with a ...\n",
       "84183    <<000000444010.jpg>>description: A fridge in t...\n",
       "84184    <<000000565004.jpg>>description: A bowl filled...\n",
       "84185    <<000000516168.jpg>>description: A CUP OF COFF...\n",
       "Name: desc, Length: 84186, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['desc'] = '<<' + df['file_name'] + '>>description: ' + df['caption'] + '<END>\\n'\n",
    "df['desc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2800424e",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_text = ''.join(df['desc'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fe530da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<<000000391895.jpg>>description: A cow on a hill top looking for something to eat<END>\\n<<000000522418.jpg>>description: A rustic wood kitchen with rustic cabinets, kitchen sink, microwave and shelves.<END>\\n<<000000184613.jpg>>description: A street with signs, people, cars and a lamppost.<END>\\n<<000000318219.jpg>>description: A person on the horse halfway in the lake. <END>\\n<<000000574769.jpg>>description: The young woman behind the bar is pouring a drink.<END>\\n<<000000060623.jpg>>description: Businessmen poring over a presentation on a laptop computer<END>\\n<<000000005802.jpg>>description: A large decorative chocolate cake sit on top of a table.<END>\\n<<000000222564.jpg>>description: A woman on a tennis court holding a tennis racquet.<END>\\n<<000000118113.jpg>>description: A little girl holding a teddy bear in front of  four slices of chocolate cake.<END>\\n<<000000193271.jpg>>description: A white toilet sitting in a bathroom next to a wall.<END>\\n<<000000224736.jpg>>description: A bicycle is mounted on the front of a public bus near a bagel cafe.<END>\\n<<000000483108.jpg>>description: Man working with paper item on floor in tiled room.<END>\\n<<000000403013.jpg>>description: some baseball players playing baseball and some fans<END>\\n<<000000384213.jpg>>description: A small pizza on a metal pan on a table.<END>\\n<<000000086408.jpg>>description: two cats in a home office looking out of a window<END>\\n<<000000372938.jpg>>description: The luggage cart is filled with various bags.<END>\\n<<000000386164.jpg>>description: A boy in a tank top looks away from the Wii game he is playing.<END>\\n<<000000204805.jpg>>description: a stuffed teddy bear sitting in the middle of a grassy area<END>\\n<<000000113588.jpg>>description: This little boy is enjoying eating his snack.<END>\\n<<000000384553.jpg>>description: A baseball player standing next to home plate.<END>\\n<<000000337264.jpg>>description: A boy flying a kite during the day.<END>\\n<<000000368402.jpg>>description: A white toilet sitting in a bathroom next to a shower and a sink.<END>\\n<<000000012448.jpg>>description: A coffee cup filled with different colored tooth brushes.<END>\\n<<000000079841.jpg>>description: A convoy of police on motorcycles riding down the street.<END>\\n<<000000562150.jpg>>description: a small trashed and abandoned bathroom with toilets<END>\\n<<000000540186.jpg>>description: a young boy is dressed in a shirt and tie<END>\\n<<000000242611.jpg>>description: A green room containing several plants and vases.<END>\\n<<000000462565.jpg>>description: A tennis play swings his racket at a tennis ball in front of a net.<END>\\n<<000000144941.jpg>>description: A food entree with an entree is served next to a rice side.<END>\\n<<000000173350.jpg>>description: A MAN IS TAKING A PHOTO OF ZOO ANIMLAS <END>\\n<<000000262284.jpg>>description: A group of people on a beach flying a kite.<END>\\n<<000000191381.jpg>>description: A pair of men at a wedding have drinks at a bar.<END>\\n<<000000111076.jpg>>description: A living room with a couch tv and a chair<END>\\n<<000000258985.jpg>>description: A dog attempting to use its mouth to pick up a pair of scissors from the floor.<END>\\n<<000000509822.jpg>>description: One horse grazing on grass with another horse behind it.<END>\\n<<000000321107.jpg>>description: A variety of motorcycles in a parking lot.<END>\\n<<000000229643.jpg>>description: A man on a camel and some trucks on a beach<END>\\n<<000000125059.jpg>>description: A man tosses a Frisbee towards metal contraption.<END>\\n<<000000436141.jpg>>description: a clock attached to a wall with satutes <END>\\n<<000000232262.jpg>>description: Three Zebras standing next to each other in grassy area.<END>\\n<<000000061181.jpg>>description: A group of cows cross a desert road.<END>\\n<<000000166323.jpg>>description: A double decker bus travels down an uncrowded road.<END>\\n<<000000580041.jpg>>description: A large clock on a wall in a room.<END>\\n<<000000326781.jpg>>description: Two men pose for the cameras in front of a screen.<END>\\n<<000000138079.jpg>>description: A group pf zebras are heading up a hilly plain.<END>\\n<<000000556616.jpg>>description: A river with a bunch of colorful kites flying over it.<END>\\n<<000000192440.jpg>>description: Fluffy white cat laying on a lightly colored bed.<END>\\n<<000000256668.jpg>>description: A gentleman and child in a vintage picture with a horse. <END>\\n<<000000383445.jpg>>description: A small child sitting in a big suitcase.<END>\\n<<000000565797.jpg>>description: a motorcycle rider a road and some rocks <END>\\n<<000000050125.jpg>>description: A man in a green sweatshirt holding a wii remote.<END>\\n<<000000364521.jpg>>description: a number of people in a body of water <END>\\n<<000000394892.jpg>>description: Contemporary living room setting in urban residential building.<END>\\n<<000000001146.jpg>>description: A meal of hot dogs and stuffed vegetables<END>\\n<<000000310391.jpg>>description: A fire hydrant by a sidewalk marked with paint.<END>\\n<<000000097434.jpg>>description: A man does snowboarding tricks on a jump.<END>\\n<<000000463836.jpg>>description: A young boy is sitting at a table with a laptop.<END>\\n<<000000156832.jpg>>description: a person sitting on the floor covered in white dust<END>\\n<<000000270721.jpg>>description: two old green trucks and two green buildings<END>\\n<<000000462341.jpg>>description: A man holding a baseball bat in his hand.<END>\\n<<000000310103.jpg>>description: A group of people on skis with trees in background.<END>\\n<<000000032992.jpg>>description: A suitcase containing only a pair of shoes and a magazine.<END>\\n<<000000122851.jpg>>description: Young people posing with surfboards on the beach.<END>\\n<<000000197254.jpg>>description: Bald man in suit and jacket standing the corner of a room.<END>\\n<<000000032907.jpg>>description: There is a toilet with the seat up.<END>\\n<<000000251252.jpg>>description: A bowl of oranges, lemons and a single red pepper.<END>\\n<<000000037675.jpg>>description: An open laptop is chained to a table in a diner.<END>\\n<<000000159537.jpg>>description: Woman in red shirt standing in a kitchen.<END>\\n<<000000268556.jpg>>description: A pot and pan sitting on a stove top under a microwave next to a collection of knives.<END>\\n<<000000549399.jpg>>description: a person really getting into a video game<END>\\n<<000000559665.jpg>>description: A laptop on a table in a room.<END>\\n<<000000019358.jpg>>description: A pile of stuff is stacked next to a blue car<END>\\n<<000000459912.jpg>>description: a pizza on a wooden platter and some drinks<END>\\n<<000000015827.jpg>>description: A photo of a landscape from an airplane.<END>\\n<<000000510755.jpg>>description: A dog laying on the street wearing a hat.<END>\\n<<000000175831.jpg>>description: The tennis player extends to hit a tennis ball.<END>\\n<<000000079472.jpg>>description: A young man is swinging a tennis racket.<END>\\n<<000000250108.jpg>>description: A woman sitting at a table that has flowers and plates of food on it.<END>\\n<<000000315601.jpg>>description: A plane about to take off near some water<END>\\n<<000000503707.jpg>>description: a person riding a skate board on a skate park<END>\\n<<000000074331.jpg>>description: Two ships are off in the distance in the ocean.<END>\\n<<000000579664.jpg>>description: Dog curled up on large purple bean bag chair<END>\\n<<000000199951.jpg>>description: A woman in a red swim suit with a paddle standing up trying to move.<END>\\n<<000000213687.jpg>>description: A man is eating a sandwich and french fries.<END>\\n<<000000527040.jpg>>description: a double decked bus sits parked as people take pictures <END>\\n<<000000550529.jpg>>description: A pepper, broccoli and a half eaten strawberry on a plate. <END>\\n<<000000432176.jpg>>description: A couple of cows standing on a dirt road.<END>\\n<<000000281533.jpg>>description: A group of people and bicycles and an orange sign that reads \"orange.\"<END>\\n<<000000369826.jpg>>description: A uniformed man prepares a ball for rugby.<END>\\n<<000000551334.jpg>>description: Old motorcycle parked outside next to a camper.<END>\\n<<000000291380.jpg>>description: A bowl filled with stuffing next to piles of meat and bread<END>\\n<<000000368978.jpg>>description: A black and white photo shows a woman sitting on a bench.<END>\\n<<000000513681.jpg>>description: The goat is sitting by the door. <END>\\n<<000000078371.jpg>>description: A man is checking the time as he walks through a town square.<END>\\n<<000000560623.jpg>>description: A female tennis player with a racket waiting for the ball<END>\\n<<000000289173.jpg>>description: Three zebras in the wilderness in their natural habitat<END>\\n<<000000052759.jpg>>description: Cooktop is heating up a pan to cook food.<END>\\n<<000000128939.jpg>>description: A man throwing a baseball at a baseball game<END>\\n<<000000339974.jpg>>description: A lady holding a bag standing before a large mirror.<END>\\n<<000000561100.jpg>>description: a tennis player player swinging a racket at a ball<END>\\n<<000000150410.jpg>>description: some surfers are surfing on a sunny day<END>\\n<<000000009426.jpg>>description: Four people sit at a banquet table with nearly finished plates and glasses.<END>\\n<<000000014869.jpg>>description: A line of traffic, including a truck, car, and vehicle for transporting a horse.<END>\\n<<000000440575.jpg>>description: some women sitting around an outdoor restaurant table <END>\\n<<000000242139.jpg>>description: A large purple flower is hanging on a tree.<END>\\n<<000000381021.jpg>>description: A couple of young children kicking around a soccer ball.<END>\\n<<000000170629.jpg>>description: A bird is standing on a tree branch.<END>\\n<<000000207797.jpg>>description: Two tall wooden clocks sitting next to each other.<END>\\n<<000000179558.jpg>>description: A man looks inside of an empty fridge.<END>\\n<<000000467522.jpg>>description: a person riding a surf board with a sail<END>\\n<<000000040102.jpg>>description: a red stop sign against a blue sky<END>\\n<<000000006005.jpg>>description: Two street signs, with a little bit of rust.<END>\\n<<000000125476.jpg>>description: Tw'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated_text[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a21fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with codecs.open('data/image_annotations_coco.txt', 'w', 'utf8') as f:\n",
    "    f.write(annotated_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
