{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98f3259",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VQ-GAN 1024 \n",
    "Model = \"f16_1024\" #param [\"f16_1024\", \"f16_16384\", \"f16_16384_hf\"]\n",
    "import cv2\n",
    "import torch\n",
    "import yaml\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from omegaconf import OmegaConf\n",
    "from taming.models.vqgan import VQModel\n",
    "\n",
    "def load_config(config_path, display=False):\n",
    "  config = OmegaConf.load(config_path)\n",
    "  if display:\n",
    "    print(yaml.dump(OmegaConf.to_container(config)))\n",
    "  return config\n",
    "\n",
    "def load_vqgan(config, ckpt_path=None):\n",
    "  model = VQModel(**config.model.params)\n",
    "  if ckpt_path is not None:\n",
    "    sd = torch.load(ckpt_path, map_location=\"cpu\")[\"state_dict\"]\n",
    "    missing, unexpected = model.load_state_dict(sd, strict=False)\n",
    "  return model.eval()\n",
    "\n",
    "def preprocess_vqgan(x, roll=True):\n",
    "  x = 2.*x - 1.\n",
    "  if roll:\n",
    "    x = np.rollaxis(x,3,1)\n",
    "  x = torch.Tensor(x)\n",
    "  return x\n",
    "\n",
    "def preprocess(x, permt=True):\n",
    "  if permt:\n",
    "    x = x.permute(0,2,3,1).numpy()\n",
    "  x = np.clip(x, -1., 1.)\n",
    "  x = (x + 1.)/2.\n",
    "  return x\n",
    "\n",
    "def custom_to_pil(x):\n",
    "  x = np.clip(x, -1., 1.)\n",
    "  x = (x + 1.)/2.\n",
    "  x = (255*x).astype(np.uint8)\n",
    "  x = Image.fromarray(x)\n",
    "  if not x.mode == \"RGB\":\n",
    "    x = x.convert(\"RGB\")\n",
    "  return x\n",
    "\n",
    "vq_conf = load_config(f\"chk_points/vqgan_imagenet_{Model}.yaml\", display=False)\n",
    "vq_model = load_vqgan(vq_conf, ckpt_path=f\"chk_points/vqgan_imagenet_{Model}.ckpt\").to('cuda')\n",
    "\n",
    "'''\n",
    "sz = []\n",
    "\n",
    "plt.figure(figsize=(20, 40))\n",
    "img_rec = []\n",
    "for i in range(1):\n",
    "  #quant_states, indices = V_encoder.encode(DS.obs[i+2][0])\n",
    "  x = preprocess_vqgan(DS.obs[i+2])\n",
    "  with torch.no_grad():\n",
    "    z, _, [_, _, ind] = vq_model.encode(x.to('cuda'))\n",
    "    b,c,h,w = z.shape\n",
    "    nz = vq_model.quantize.get_codebook_entry(ind, (b,h,w,c))\n",
    "    rec = vq_model.decode(nz).detach().cpu()\n",
    "    sz.append(h*w)\n",
    "  #print(rec.shape)\n",
    "  img_rec.append(preprocess(rec))\n",
    "\n",
    "for i in range(1):\n",
    "  for j in range(1):\n",
    "    plt.subplot(10, 6, i*6+j+1)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(DS.obs[j+2][i])\n",
    "    plt.title(f'origin {DS.obs[j+2][i].shape}')\n",
    "  for j in range(1):\n",
    "    plt.subplot(10, 6, i*6+j+4)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img_rec[j][i])\n",
    "    plt.title(f'sintetic {sz[j]} token')\n",
    "\n",
    "plt.show();\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac27df97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "#time.sleep(3600*7)#6:30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b4bc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "imsize = [16*9, 16*9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c749c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381b3665",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = sorted(Path(\"./data/imgs\").iterdir(), key=os.path.getmtime)\n",
    "lst.reverse()\n",
    "lst[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387d1f0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "path = './data/imgs_descs.txt'\n",
    "#path = './data/image_annotations_plans.txt'#################\n",
    "with codecs.open(f'{path}', 'r', 'utf8', errors='ignore') as f:\n",
    "    text = ''.join(f.readlines())\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "p = Path(\"./data/imgs\")\n",
    "i = 0\n",
    "for img_name in lst:#p.rglob(\"*\"):\n",
    "    i += 1\n",
    "    if np.random.rand()<0.001:\n",
    "        if not ('<<' in text):\n",
    "            break\n",
    "    img_name_short = str(img_name).replace('data\\imgs\\\\', '')\n",
    "    if img_name_short in text:\n",
    "        #скачать и декодировать картинку\n",
    "        img_orig = np.array(cv2.resize(cv2.imread(str(img_name)), imsize), dtype=np.float32)/255.\n",
    "        b,g,r = img_orig[:,:,0], img_orig[:,:,1], img_orig[:,:,2]\n",
    "        img_orig = np.dstack([r, g, b])\n",
    "        img = preprocess_vqgan(np.stack(1*[img_orig]), True)       \n",
    "        \n",
    "        z, _, [_, _, ind] = vq_model.encode(img.to('cuda'))\n",
    "        ind.squeeze_()\n",
    "        b,c,h,w = z.shape\n",
    "        #nz = vq_model.quantize.get_codebook_entry(ind, (b,h,w,c))\n",
    "        #print('nz', nz)\n",
    "        token_string = '<' + '><'.join( [str(el) for el in list(ind.detach().cpu().numpy())] ) + '>'\n",
    "        nz = vq_model.quantize.get_codebook_entry(ind, (b,h,w,c))\n",
    "        rec = vq_model.decode(nz).detach().cpu()\n",
    "        if np.random.rand()<0.002:\n",
    "            print('i', i)\n",
    "            plt.imshow(img_orig)\n",
    "            plt.show()\n",
    "            plt.imshow(preprocess(rec)[0])\n",
    "            plt.show()\n",
    "        \n",
    "        \n",
    "        text = text.replace(f'<<{img_name_short}>>', token_string)\n",
    "        \n",
    "#text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c1f9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.replace('description:', 'description:<OUT>').replace('forecast vars:', 'forecast vars:<OUT>').replace('forecast img:', 'forecast img:<OUT>').replace('plan:', 'plan:<OUT>').replace('<END>\\r\\n', '<END>\\r\\n<IN>')\n",
    "text = '<IN>' + text\n",
    "#text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44556e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Добавить датасет видео\n",
    "import tqdm\n",
    "from subprocess import Popen, PIPE\n",
    "import torchvision.transforms as T\n",
    "from base64 import b64encode\n",
    "from IPython.display import HTML\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "Actions = ['No','Fwd','Bck','Rgt','Lft','Rsf','Lsf']\n",
    "Semantic = ['-','Barrel','Picture','Boxes','Vine box','Market','Gate','Door']\n",
    "a,t,_,v = torch.load(\"./data/test_data.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b99a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a3569d",
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c75b61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 12\n",
    "for seq_num in range(v.shape[0]):\n",
    "    print(seq_num, 'from', v.shape[0])\n",
    "    for pointer_in_seq in range(0, v.shape[1] - step, step):\n",
    "        \n",
    "        img_orig = v[seq_num, pointer_in_seq]\n",
    "        img_orig = np.rollaxis(img_orig.numpy(),0,3)\n",
    "        img_orig = np.array(cv2.resize(img_orig, imsize), dtype=np.float32)\n",
    "        #plt.imshow(np.rollaxis(img_orig.numpy(),0,3))\n",
    "        #plt.show()\n",
    "        img = preprocess_vqgan(np.stack(1*[img_orig]), True)     \n",
    "        z, _, [_, _, ind] = vq_model.encode(img.to('cuda'))\n",
    "        ind.squeeze_()\n",
    "        b,c,h,w = z.shape\n",
    "        #nz = vq_model.quantize.get_codebook_entry(ind, (b,h,w,c))\n",
    "        #print('nz', nz)\n",
    "        token_string = '<' + '><'.join( [str(el) for el in list(ind.detach().cpu().numpy())] ) + '>'\n",
    "        nz = vq_model.quantize.get_codebook_entry(ind, (b,h,w,c))\n",
    "        rec = vq_model.decode(nz).detach().cpu()\n",
    "        \n",
    "        item = Semantic[t[seq_num, pointer_in_seq]]\n",
    "        #print(item)\n",
    "        if 0:\n",
    "            plt.imshow(img_orig)\n",
    "            plt.show()\n",
    "            plt.imshow(preprocess(rec)[0])\n",
    "            plt.show()\n",
    "        to_write = f'<IN>{token_string} description<OUT> {item}<END>\\r\\n'\n",
    "        \n",
    "        text += to_write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094aef5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with codecs.open('data/image_annotations_plans.txt', 'w', 'utf8') as f:\n",
    "    f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8036a35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f927f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#аннотированные картинки\n",
    "path = 'data/image_annotations_plans.txt' \n",
    "with codecs.open(f'{path}', 'r', 'utf8') as f:\n",
    "    texts = ''.join(f.readlines())\n",
    "texts = texts.replace('<s>', '<END>').replace('\\r\\n', '\\n').replace('</s>', '')\n",
    "#.replace('<IN>', '')\n",
    "texts = texts.replace('>f', '> f').replace('>d', '> d').replace('>p', '> p').replace('>s', '> s').replace('>k', '> k').replace('  ', ' ').replace('\\n', '\\n<IN>').replace('<IN><IN>', '<IN>')\n",
    "print('texts', len(texts))\n",
    "with codecs.open('data/all_txt.txt', 'w', 'utf8') as f:\n",
    "    f.write(texts)\n",
    "    \n",
    "    \n",
    "def process_book(path, drop_spaces=True):  \n",
    "    with codecs.open(f'{path}', 'r', 'utf8', errors='ignore') as f:\n",
    "        texts = ''.join(f.readlines())\n",
    "    texts = texts.replace('<s>', '<END>').replace('\\r\\n', '\\n').replace('</s>', '')\n",
    "    if drop_spaces:\n",
    "        texts = texts.replace('\\n', '\\t')#у нас датасет такой\n",
    "        texts = '\\n' + texts\n",
    "    print(path, 'texts', len(texts))\n",
    "    with codecs.open('data/all_txt.txt', 'a', 'utf8') as f:\n",
    "        f.write(texts)\n",
    "#вики\n",
    "path = 'data/wiki_data.txt'\n",
    "process_book(path)\n",
    "process_book(path, drop_spaces=False)\n",
    "\n",
    "    \n",
    "#/toy_text_doom_tasks\n",
    "path = 'data/toy_text_doom_tasks.txt'     \n",
    "process_book(path, drop_spaces=False)\n",
    "    \n",
    "#logic\n",
    "path = 'data/formal_logic_textbook.txt'     \n",
    "process_book(path)\n",
    "process_book(path, drop_spaces=False)\n",
    "    \n",
    "    \n",
    "#hpmor\n",
    "path = 'data/hpmor.txt'     \n",
    "process_book(path)   \n",
    "process_book(path, drop_spaces=False)\n",
    "\n",
    "path = \"data/Book 1 - The Philosopher's Stone.txt\"\n",
    "process_book(path)   \n",
    "process_book(path, drop_spaces=False)\n",
    "\n",
    "path = 'data/Book 2 - The Chamber of Secrets.txt'\n",
    "process_book(path)\n",
    "process_book(path, drop_spaces=False)\n",
    "\n",
    "path = 'data/Book 4 - The Goblet of Fire.txt'\n",
    "process_book(path)\n",
    "process_book(path, drop_spaces=False)\n",
    "    \n",
    "#rationality.txt\n",
    "path = 'data/Map and Territory.txt'     \n",
    "process_book(path)\n",
    "process_book(path, drop_spaces=False)\n",
    "\n",
    "path = 'data/doom fanfics.txt' \n",
    "process_book(path)\n",
    "process_book(path, drop_spaces=False)\n",
    "\n",
    "path = 'data/treasure island.txt' \n",
    "process_book(path)\n",
    "process_book(path, drop_spaces=False)\n",
    "\n",
    "path = 'data/robinson crusoe.txt' \n",
    "process_book(path)\n",
    "process_book(path, drop_spaces=False)\n",
    "\n",
    "path = 'data/Sherlock Holmes.txt' \n",
    "process_book(path)\n",
    "\n",
    "path = 'data/scrum.txt' \n",
    "process_book(path)\n",
    "process_book(path, drop_spaces=False)\n",
    "\n",
    "path = 'data/military stories.txt' \n",
    "process_book(path)\n",
    "process_book(path, drop_spaces=False)\n",
    "\n",
    "path = 'data/military stories 2.txt' \n",
    "process_book(path)\n",
    "process_book(path, drop_spaces=False)\n",
    "\n",
    "path = 'data/doom wiki.txt'\n",
    "process_book(path)\n",
    "process_book(path, drop_spaces=False)\n",
    "\n",
    "path = 'data/homm.txt'\n",
    "process_book(path)\n",
    "process_book(path, drop_spaces=False)\n",
    "\n",
    "path = 'data/military materials.txt'\n",
    "process_book(path)\n",
    "process_book(path, drop_spaces=False)\n",
    "\n",
    "path = 'data/military materials 2.txt'\n",
    "process_book(path)\n",
    "process_book(path, drop_spaces=False)\n",
    "\n",
    "path = 'data/anatomy.txt'\n",
    "process_book(path)\n",
    "process_book(path, drop_spaces=False)\n",
    "\n",
    "path = 'data/churchill.txt'\n",
    "process_book(path)\n",
    "process_book(path, drop_spaces=False)\n",
    "\n",
    "path = 'data/summary_data.txt'\n",
    "process_book(path, drop_spaces=False)\n",
    "\n",
    "path = 'data/dialogues_text.txt'\n",
    "process_book(path, drop_spaces=False)\n",
    "\n",
    "path = 'data/chat_data.txt'\n",
    "process_book(path, drop_spaces=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca802d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#аннотированные картинки с памятью\n",
    "path = 'data/imgs_descs_memory.txt' \n",
    "with codecs.open(f'{path}', 'r', 'utf8') as f:\n",
    "    texts = ''.join(f.readlines())\n",
    "texts = texts.replace('<s>', '<END>').replace('\\r\\n', '\\n').replace('</s>', '')\n",
    "print('texts', len(texts))\n",
    "with codecs.open('data/all_txt.txt', 'a', 'utf8') as f:\n",
    "    f.write(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba91c14c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987e7331",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cut text\n",
    "import codecs\n",
    "thresh = 100000000\n",
    "with codecs.open('data/all_txt.txt', 'r', 'utf8', errors='ignore') as f:\n",
    "    lines = f.readlines()\n",
    "lines = [line[:thresh] for line in lines]\n",
    "lines = '\\n'.join(lines)\n",
    "\n",
    "with codecs.open('data/all_txt_cut.txt', 'w', 'utf8') as f:\n",
    "    f.write(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8efce0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6376480e",
   "metadata": {},
   "outputs": [],
   "source": [
    "1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6ee7ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ce4951",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab8c142",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b330b79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06af04f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962f8185",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4323e62a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b2f8b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e0714b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67e2b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#здесь мы выгружаем GPT-2 и пытаемся дообучать на кроссдоменном датасете\n",
    "import torch\n",
    "from transformers import GPT2Tokenizer\n",
    "import codecs\n",
    "import numpy as np\n",
    "\n",
    "from trl import AutoModelForCausalLMWithValueHead\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5e3e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt2_finetuned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84144b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. load a pretrained model\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "#model = AutoModelForCausalLMWithValueHead.from_pretrained(model_name)\n",
    "#model_ref = AutoModelForCausalLMWithValueHead.from_pretrained(model_name)\n",
    "\n",
    "#tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "#tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90805bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Учим эту модель. У Nehc есть пример, как это делать\n",
    "#Модификация токенайзера \n",
    "#добавляем несколько токенов нашей разметки\n",
    "\n",
    "#сюда надо фигануть весь словарь картинок\n",
    "video_tokens_cnt = 1024\n",
    "video_tokens = []\n",
    "for i in range(video_tokens_cnt):\n",
    "    video_tokens.append(f'<{i}>')\n",
    "    \n",
    "special_tokens_dict = {'additional_special_tokens': video_tokens + ['<IN>','<OUT>','<END>','|PAD|']}\n",
    "num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "print(tokenizer.all_special_tokens)\n",
    "tokenizer.pad_token = '|PAD|'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ceea69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Загрузка датасета\n",
    "# теоретически, это устревший формат датасета, но на практике\n",
    "# он дает равномерную загрузку графической памяти и позволяет \n",
    "# использовать больший батч.\n",
    "\n",
    "'''\n",
    "\n",
    "Предполагается, что датасет выглядит как-то так: \n",
    "\n",
    "<IN>Современное прочтение СТЭ не отрицает наличие ЭС и ее влияние на видообразование, но делает акцент на \"мутационном факторе\" изменчивости. В любом случае, благодарю за ваш ответ по существу. 🤝\n",
    "<OUT>Все примеры мутационной изменчивости не столь очевидны (особенно с учетом отсутствия прямого соответствия ген-признак).  Всегда есть вероятность априорного существования соответствующего морфоза.\n",
    "<END>\n",
    "<IN>Просто тема сама рифмуется с соразмерным госфинансированием...\n",
    "<OUT>ну что вам так финансирование далось... всем фундаментальным проектам не хватает финансирования, точнее, с финансированием происходит полный рандом. это нормально. вот будет конкретный прикладной проект — тогда и надо будет выбивать для него финансирование\n",
    "<END>\n",
    "\n",
    "В простом тесктовом файле...\n",
    "\n",
    "'''\n",
    "\n",
    "if 0:\n",
    "    texts = ''\n",
    "    paths = ['data/thougths_my.txt', 'data/public_my.txt', 'data/dialogues_my.txt']\n",
    "    for path in paths:\n",
    "        with codecs.open(f'{path}', 'r', 'utf8') as f:\n",
    "            texts += ''.join(f.readlines())\n",
    "    texts = texts.replace('<s>', '<END>').replace('\\r\\n', '\\n').replace('</s>', '')\n",
    "    #IN OUT не будет\n",
    "    with codecs.open('data/all_txt.txt', 'w', 'utf8') as f:\n",
    "        f.write(texts)\n",
    "\n",
    "\n",
    "#аннотированные картинки\n",
    "path = 'data/image_annotations_plans.txt' \n",
    "with codecs.open(f'{path}', 'r', 'utf8') as f:\n",
    "    texts = ''.join(f.readlines())\n",
    "texts = texts.replace('<s>', '<END>').replace('\\r\\n', '\\n').replace('</s>', '')\n",
    "with codecs.open('data/all_txt.txt', 'w', 'utf8') as f:\n",
    "    f.write(texts)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc83cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#вики\n",
    "path = 'data/wiki_data.txt'     \n",
    "with codecs.open(f'{path}', 'r', 'utf8') as f:\n",
    "    texts = ''.join(f.readlines())\n",
    "texts = texts.replace('<s>', '<END>').replace('\\r\\n', '\\n').replace('</s>', '')\n",
    "\n",
    "with codecs.open('data/all_txt.txt', 'a', 'utf8') as f:\n",
    "    f.write(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bd128e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextDataset,DataCollatorForLanguageModeling\n",
    "\n",
    "train_dataset = TextDataset(\n",
    "          tokenizer=tokenizer,\n",
    "          file_path='data/all_txt.txt',\n",
    "          block_size=128)\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c20e680",
   "metadata": {},
   "outputs": [],
   "source": [
    "#обучение\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import torch\n",
    "\n",
    "# если не лезет в память, можно уменьшать **per_device_train_batch_size**\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./models/gpt_bot\", #The output directory\n",
    "    #evaluation_strategy=\"epoch\",\n",
    "    overwrite_output_dir=True, #overwrite the content of the output directory\n",
    "    num_train_epochs=4, # number of training epochs\n",
    "    per_device_train_batch_size= 19, # batch size for training\n",
    "    gradient_accumulation_steps=20,\n",
    "    #per_device_eval_batch_size=50,  # batch size for evaluation\n",
    "    eval_steps = 200, # Number of update steps between two evaluations.\n",
    "    save_steps=1000, # after # steps model is saved \n",
    "    warmup_steps=500,# number of warmup steps for learning rate scheduler\n",
    "    prediction_loss_only=True,\n",
    "    )\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    #train_dataset=tokenized_dataset['train'],\n",
    "    train_dataset=train_dataset,\n",
    "    #eval_dataset=test_dataset,\n",
    "    #compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4a8a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5366049",
   "metadata": {},
   "outputs": [],
   "source": [
    "#можно засейвить модель и потом применять в RL\n",
    "if 1:\n",
    "    # save it locally\n",
    "    model.save_pretrained(\"gpt2_finetuned\")\n",
    "    tokenizer.save_pretrained('gpt2_finetuned')\n",
    "\n",
    "    # load the model from the Hub\n",
    "    #from transformers import AutoModelForCausalLM\n",
    "\n",
    "    #model = AutoModelForCausalLM.from_pretrained(\"my-fine-tuned-model-ppo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c33ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#специальные токены { vertical-output: true }\n",
    "T_OUT = tokenizer.encode('<OUT>')[0]\n",
    "T_END = tokenizer.encode('<END>')[0]\n",
    "T_PAD = tokenizer.encode('|PAD|')[0]\n",
    "T_124 = tokenizer.encode('<124>')[0]\n",
    "\n",
    "T_OUT, T_END, T_PAD, T_124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348d7b43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669dd0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Здравствуй железяка разумная! Как у тебя сегодня дела?\"\n",
    "model.cuda()\n",
    "\n",
    "text = f\"<IN>{text}\\n<OUT>\"\n",
    "inpt = tokenizer.encode(text, return_tensors=\"pt\")\n",
    "inpt= inpt.cuda()\n",
    "\n",
    "out = model.generate(inpt,  max_length=len(inpt[0])+300, do_sample=True, top_k=5, top_p=0.95, temperature=1, eos_token_id=T_END, pad_token_id=T_PAD)\n",
    "\n",
    "out_tokens = torch.where(out[0]==T_OUT)\n",
    "last_repl = out[0][out_tokens[0][-1]+1:-1]\n",
    "repl = tokenizer.decode(last_repl)\n",
    "\n",
    "print(repl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9b2210",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer(text):\n",
    "    inpt = tokenizer.encode(text, return_tensors=\"pt\")\n",
    "    inpt= inpt.cuda()\n",
    "    print(text)\n",
    "\n",
    "    out = model.generate(inpt,  max_length=len(inpt[0])+300, do_sample=True, top_k=5, top_p=0.95, temperature=1, eos_token_id=T_END, pad_token_id=T_PAD)\n",
    "\n",
    "    out_tokens = torch.where(out[0]==T_OUT)\n",
    "    last_repl = out[0][out_tokens[0][-1]+1:-1]\n",
    "    repl = tokenizer.decode(last_repl)\n",
    "\n",
    "    print(repl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287963c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a11\n",
    "text = '<916><61><922><922><922><922><922><922><55><906><1022><830><376><830><830><830><830><61><771><402><438><751><830><925><925><830><61><580><519><920><462><830><925><925><925><61><120><519><255><327><61><925><328><55><483><657><255><49><328><830><925><147><120><287><328><830><328><61><830><706><957><29><222><925><55><55><55><328><851><590><596><164><376><61><328><328><328><801><925><422><255> description:'\n",
    "text = f\"<IN>{text}<OUT>\"\n",
    "answer(text)\n",
    "text = '<916><61><922><922><922><922><922><922><55><906><1022><830><376><830><830><830><830><61><771><402><438><751><830><925><925><830><61><580><519><920><462><830><925><925><925><61><120><519><255><327><61><925><328><55><483><657><255><49><328><830><925><147><120><287><328><830><328><61><830><706><957><29><222><925><55><55><55><328><851><590><596><164><376><61><328><328><328><801><925><422><255> save hp plan:'\n",
    "text = f\"<IN>{text}<OUT>\"\n",
    "answer(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb58d689",
   "metadata": {},
   "outputs": [],
   "source": [
    "#images (10).jpg\n",
    "text = '<597><813><813><110><813><813><556><714><937><778><985><173><891><893><61><873><261><96><761><189><481><230><215><140><661><192><444><548><897><548><720><333><828><884><171><192><508><966><577><805><611><965><661><414><966><638><255><406><979><254><966><92><244><439><404><811><187><906><164><297><313><330><514><925><979><681><671><758><608><36><49><1019><468><140><574><325><287><217><714><562><432> description:'\n",
    "text = f\"<IN>{text}<OUT>\"\n",
    "answer(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab53c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#images (2).jpg\n",
    "text = '<685><714><719><632><910><590><299><894><473><634><812><334><607><382><250><526><422><862><710><774><780><552><437><20><894><746><597><323><1006><422><406><813><370><414><854><473><330><941><681><323><813><870><845><432><7><642><599><57><717><845><269><473><714><96><29><596><870><477><283><477><974><884><215><881><596><698><333><517><460><893><813><222><402><110><714><996><407><718><172><189><150> description:'\n",
    "text = f\"<IN>{text}<OUT>\"\n",
    "answer(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f5753e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44c087b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39666ace",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a4d187",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
