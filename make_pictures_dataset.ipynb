{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98f3259",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VQ-GAN 1024 \n",
    "Model = \"f16_1024\" #param [\"f16_1024\", \"f16_16384\", \"f16_16384_hf\"]\n",
    "import cv2\n",
    "import torch\n",
    "import yaml\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from omegaconf import OmegaConf\n",
    "from taming.models.vqgan import VQModel\n",
    "\n",
    "def load_config(config_path, display=False):\n",
    "  config = OmegaConf.load(config_path)\n",
    "  if display:\n",
    "    print(yaml.dump(OmegaConf.to_container(config)))\n",
    "  return config\n",
    "\n",
    "def load_vqgan(config, ckpt_path=None):\n",
    "  model = VQModel(**config.model.params)\n",
    "  if ckpt_path is not None:\n",
    "    sd = torch.load(ckpt_path, map_location=\"cpu\")[\"state_dict\"]\n",
    "    missing, unexpected = model.load_state_dict(sd, strict=False)\n",
    "  return model.eval()\n",
    "\n",
    "def preprocess_vqgan(x, roll=True):\n",
    "  x = 2.*x - 1.\n",
    "  if roll:\n",
    "    x = np.rollaxis(x,3,1)\n",
    "  x = torch.Tensor(x)\n",
    "  return x\n",
    "\n",
    "def preprocess(x, permt=True):\n",
    "  if permt:\n",
    "    x = x.permute(0,2,3,1).numpy()\n",
    "  x = np.clip(x, -1., 1.)\n",
    "  x = (x + 1.)/2.\n",
    "  return x\n",
    "\n",
    "def custom_to_pil(x):\n",
    "  x = np.clip(x, -1., 1.)\n",
    "  x = (x + 1.)/2.\n",
    "  x = (255*x).astype(np.uint8)\n",
    "  x = Image.fromarray(x)\n",
    "  if not x.mode == \"RGB\":\n",
    "    x = x.convert(\"RGB\")\n",
    "  return x\n",
    "\n",
    "vq_conf = load_config(f\"chk_points/vqgan_imagenet_{Model}.yaml\", display=False)\n",
    "vq_model = load_vqgan(vq_conf, ckpt_path=f\"chk_points/vqgan_imagenet_{Model}.ckpt\").to('cuda')\n",
    "\n",
    "'''\n",
    "sz = []\n",
    "\n",
    "plt.figure(figsize=(20, 40))\n",
    "img_rec = []\n",
    "for i in range(1):\n",
    "  #quant_states, indices = V_encoder.encode(DS.obs[i+2][0])\n",
    "  x = preprocess_vqgan(DS.obs[i+2])\n",
    "  with torch.no_grad():\n",
    "    z, _, [_, _, ind] = vq_model.encode(x.to('cuda'))\n",
    "    b,c,h,w = z.shape\n",
    "    nz = vq_model.quantize.get_codebook_entry(ind, (b,h,w,c))\n",
    "    rec = vq_model.decode(nz).detach().cpu()\n",
    "    sz.append(h*w)\n",
    "  #print(rec.shape)\n",
    "  img_rec.append(preprocess(rec))\n",
    "\n",
    "for i in range(1):\n",
    "  for j in range(1):\n",
    "    plt.subplot(10, 6, i*6+j+1)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(DS.obs[j+2][i])\n",
    "    plt.title(f'origin {DS.obs[j+2][i].shape}')\n",
    "  for j in range(1):\n",
    "    plt.subplot(10, 6, i*6+j+4)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img_rec[j][i])\n",
    "    plt.title(f'sintetic {sz[j]} token')\n",
    "\n",
    "plt.show();\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac27df97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "#time.sleep(3600*7)#6:30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b4bc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "imsize = [16*9, 16*9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c749c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381b3665",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = sorted(Path(\"./data/imgs\").iterdir(), key=os.path.getmtime)\n",
    "lst.reverse()\n",
    "lst[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387d1f0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "path = './data/imgs_descs.txt'\n",
    "#path = './data/image_annotations_plans.txt'#################\n",
    "with codecs.open(f'{path}', 'r', 'utf8', errors='ignore') as f:\n",
    "    text = ''.join(f.readlines())\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "p = Path(\"./data/imgs\")\n",
    "i = 0\n",
    "for img_name in lst:#p.rglob(\"*\"):\n",
    "    i += 1\n",
    "    if np.random.rand()<0.001:\n",
    "        if not ('<<' in text):\n",
    "            break\n",
    "    img_name_short = str(img_name).replace('data\\imgs\\\\', '')\n",
    "    if img_name_short in text:\n",
    "        #—Å–∫–∞—á–∞—Ç—å –∏ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å –∫–∞—Ä—Ç–∏–Ω–∫—É\n",
    "        img_orig = np.array(cv2.resize(cv2.imread(str(img_name)), imsize), dtype=np.float32)/255.\n",
    "        b,g,r = img_orig[:,:,0], img_orig[:,:,1], img_orig[:,:,2]\n",
    "        img_orig = np.dstack([r, g, b])\n",
    "        img = preprocess_vqgan(np.stack(1*[img_orig]), True)       \n",
    "        \n",
    "        z, _, [_, _, ind] = vq_model.encode(img.to('cuda'))\n",
    "        ind.squeeze_()\n",
    "        b,c,h,w = z.shape\n",
    "        #nz = vq_model.quantize.get_codebook_entry(ind, (b,h,w,c))\n",
    "        #print('nz', nz)\n",
    "        token_string = '<' + '><'.join( [str(el) for el in list(ind.detach().cpu().numpy())] ) + '>'\n",
    "        nz = vq_model.quantize.get_codebook_entry(ind, (b,h,w,c))\n",
    "        rec = vq_model.decode(nz).detach().cpu()\n",
    "        if np.random.rand()<0.002:\n",
    "            print('i', i)\n",
    "            plt.imshow(img_orig)\n",
    "            plt.show()\n",
    "            plt.imshow(preprocess(rec)[0])\n",
    "            plt.show()\n",
    "        \n",
    "        \n",
    "        text = text.replace(f'<<{img_name_short}>>', token_string)\n",
    "        \n",
    "#text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c1f9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.replace('description:', 'description:<OUT>').replace('forecast vars:', 'forecast vars:<OUT>').replace('forecast img:', 'forecast img:<OUT>').replace('plan:', 'plan:<OUT>').replace('<END>\\r\\n', '<END>\\r\\n<IN>')\n",
    "text = '<IN>' + text\n",
    "#text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44556e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#–î–æ–±–∞–≤–∏—Ç—å –¥–∞—Ç–∞—Å–µ—Ç –≤–∏–¥–µ–æ\n",
    "import tqdm\n",
    "from subprocess import Popen, PIPE\n",
    "import torchvision.transforms as T\n",
    "from base64 import b64encode\n",
    "from IPython.display import HTML\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "Actions = ['No','Fwd','Bck','Rgt','Lft','Rsf','Lsf']\n",
    "Semantic = ['-','Barrel','Picture','Boxes','Vine box','Market','Gate','Door']\n",
    "a,t,_,v = torch.load(\"./data/test_data.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b99a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a3569d",
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c75b61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 12\n",
    "for seq_num in range(v.shape[0]):\n",
    "    print(seq_num, 'from', v.shape[0])\n",
    "    for pointer_in_seq in range(0, v.shape[1] - step, step):\n",
    "        \n",
    "        img_orig = v[seq_num, pointer_in_seq]\n",
    "        img_orig = np.rollaxis(img_orig.numpy(),0,3)\n",
    "        img_orig = np.array(cv2.resize(img_orig, imsize), dtype=np.float32)\n",
    "        #plt.imshow(np.rollaxis(img_orig.numpy(),0,3))\n",
    "        #plt.show()\n",
    "        img = preprocess_vqgan(np.stack(1*[img_orig]), True)     \n",
    "        z, _, [_, _, ind] = vq_model.encode(img.to('cuda'))\n",
    "        ind.squeeze_()\n",
    "        b,c,h,w = z.shape\n",
    "        #nz = vq_model.quantize.get_codebook_entry(ind, (b,h,w,c))\n",
    "        #print('nz', nz)\n",
    "        token_string = '<' + '><'.join( [str(el) for el in list(ind.detach().cpu().numpy())] ) + '>'\n",
    "        nz = vq_model.quantize.get_codebook_entry(ind, (b,h,w,c))\n",
    "        rec = vq_model.decode(nz).detach().cpu()\n",
    "        \n",
    "        item = Semantic[t[seq_num, pointer_in_seq]]\n",
    "        #print(item)\n",
    "        if 0:\n",
    "            plt.imshow(img_orig)\n",
    "            plt.show()\n",
    "            plt.imshow(preprocess(rec)[0])\n",
    "            plt.show()\n",
    "        to_write = f'<IN>{token_string} description<OUT> {item}<END>\\r\\n'\n",
    "        \n",
    "        text += to_write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094aef5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with codecs.open('data/image_annotations_plans.txt', 'w', 'utf8') as f:\n",
    "    f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8036a35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f927f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#–∞–Ω–Ω–æ—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–∞—Ä—Ç–∏–Ω–∫–∏\n",
    "path = 'data/image_annotations_plans.txt' \n",
    "with codecs.open(f'{path}', 'r', 'utf8') as f:\n",
    "    texts = ''.join(f.readlines())\n",
    "texts = texts.replace('<s>', '<END>').replace('\\r\\n', '\\n').replace('</s>', '')\n",
    "#.replace('<IN>', '')\n",
    "texts = texts.replace('>f', '> f').replace('>d', '> d').replace('>p', '> p').replace('>s', '> s').replace('>k', '> k').replace('  ', ' ').replace('\\n', '\\n<IN>').replace('<IN><IN>', '<IN>')\n",
    "print('texts', len(texts))\n",
    "with codecs.open('data/all_txt.txt', 'w', 'utf8') as f:\n",
    "    f.write(texts)\n",
    "    \n",
    "    \n",
    "def process_book(path, drop_spaces=True):  \n",
    "    with codecs.open(f'{path}', 'r', 'utf8', errors='ignore') as f:\n",
    "        texts = ''.join(f.readlines())\n",
    "    texts = texts.replace('<s>', '<END>').replace('\\r\\n', '\\n').replace('</s>', '')\n",
    "    if drop_spaces:\n",
    "        texts = texts.replace('\\n', '\\t')#—É –Ω–∞—Å –¥–∞—Ç–∞—Å–µ—Ç —Ç–∞–∫–æ–π\n",
    "        texts = '\\n' + texts\n",
    "    print(path, 'texts', len(texts))\n",
    "    with codecs.open('data/all_txt.txt', 'a', 'utf8') as f:\n",
    "        f.write(texts)\n",
    "#–≤–∏–∫–∏\n",
    "path = 'data/wiki_data.txt'\n",
    "process_book(path)\n",
    "process_book(path, drop_spaces=False)\n",
    "\n",
    "    \n",
    "#/toy_text_doom_tasks\n",
    "path = 'data/toy_text_doom_tasks.txt'     \n",
    "process_book(path, drop_spaces=False)\n",
    "    \n",
    "#logic\n",
    "path = 'data/formal_logic_textbook.txt'     \n",
    "process_book(path)\n",
    "process_book(path, drop_spaces=False)\n",
    "    \n",
    "    \n",
    "#hpmor\n",
    "path = 'data/hpmor.txt'     \n",
    "process_book(path)   \n",
    "process_book(path, drop_spaces=False)\n",
    "\n",
    "path = \"data/Book 1 - The Philosopher's Stone.txt\"\n",
    "process_book(path)   \n",
    "process_book(path, drop_spaces=False)\n",
    "\n",
    "path = 'data/Book 2 - The Chamber of Secrets.txt'\n",
    "process_book(path)\n",
    "process_book(path, drop_spaces=False)\n",
    "\n",
    "path = 'data/Book 4 - The Goblet of Fire.txt'\n",
    "process_book(path)\n",
    "process_book(path, drop_spaces=False)\n",
    "    \n",
    "#rationality.txt\n",
    "path = 'data/Map and Territory.txt'     \n",
    "process_book(path)\n",
    "process_book(path, drop_spaces=False)\n",
    "\n",
    "path = 'data/doom fanfics.txt' \n",
    "process_book(path)\n",
    "process_book(path, drop_spaces=False)\n",
    "\n",
    "path = 'data/treasure island.txt' \n",
    "process_book(path)\n",
    "process_book(path, drop_spaces=False)\n",
    "\n",
    "path = 'data/robinson crusoe.txt' \n",
    "process_book(path)\n",
    "process_book(path, drop_spaces=False)\n",
    "\n",
    "path = 'data/Sherlock Holmes.txt' \n",
    "process_book(path)\n",
    "\n",
    "path = 'data/scrum.txt' \n",
    "process_book(path)\n",
    "process_book(path, drop_spaces=False)\n",
    "\n",
    "path = 'data/military stories.txt' \n",
    "process_book(path)\n",
    "process_book(path, drop_spaces=False)\n",
    "\n",
    "path = 'data/military stories 2.txt' \n",
    "process_book(path)\n",
    "process_book(path, drop_spaces=False)\n",
    "\n",
    "path = 'data/doom wiki.txt'\n",
    "process_book(path)\n",
    "process_book(path, drop_spaces=False)\n",
    "\n",
    "path = 'data/homm.txt'\n",
    "process_book(path)\n",
    "process_book(path, drop_spaces=False)\n",
    "\n",
    "path = 'data/military materials.txt'\n",
    "process_book(path)\n",
    "process_book(path, drop_spaces=False)\n",
    "\n",
    "path = 'data/military materials 2.txt'\n",
    "process_book(path)\n",
    "process_book(path, drop_spaces=False)\n",
    "\n",
    "path = 'data/anatomy.txt'\n",
    "process_book(path)\n",
    "process_book(path, drop_spaces=False)\n",
    "\n",
    "path = 'data/churchill.txt'\n",
    "process_book(path)\n",
    "process_book(path, drop_spaces=False)\n",
    "\n",
    "path = 'data/summary_data.txt'\n",
    "process_book(path, drop_spaces=False)\n",
    "\n",
    "path = 'data/dialogues_text.txt'\n",
    "process_book(path, drop_spaces=False)\n",
    "\n",
    "path = 'data/chat_data.txt'\n",
    "process_book(path, drop_spaces=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca802d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#–∞–Ω–Ω–æ—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–∞—Ä—Ç–∏–Ω–∫–∏ —Å –ø–∞–º—è—Ç—å—é\n",
    "path = 'data/imgs_descs_memory.txt' \n",
    "with codecs.open(f'{path}', 'r', 'utf8') as f:\n",
    "    texts = ''.join(f.readlines())\n",
    "texts = texts.replace('<s>', '<END>').replace('\\r\\n', '\\n').replace('</s>', '')\n",
    "print('texts', len(texts))\n",
    "with codecs.open('data/all_txt.txt', 'a', 'utf8') as f:\n",
    "    f.write(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba91c14c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987e7331",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cut text\n",
    "import codecs\n",
    "thresh = 100000000\n",
    "with codecs.open('data/all_txt.txt', 'r', 'utf8', errors='ignore') as f:\n",
    "    lines = f.readlines()\n",
    "lines = [line[:thresh] for line in lines]\n",
    "lines = '\\n'.join(lines)\n",
    "\n",
    "with codecs.open('data/all_txt_cut.txt', 'w', 'utf8') as f:\n",
    "    f.write(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8efce0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6376480e",
   "metadata": {},
   "outputs": [],
   "source": [
    "1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6ee7ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ce4951",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab8c142",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b330b79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06af04f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962f8185",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4323e62a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b2f8b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e0714b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67e2b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#–∑–¥–µ—Å—å –º—ã –≤—ã–≥—Ä—É–∂–∞–µ–º GPT-2 –∏ –ø—ã—Ç–∞–µ–º—Å—è –¥–æ–æ–±—É—á–∞—Ç—å –Ω–∞ –∫—Ä–æ—Å—Å–¥–æ–º–µ–Ω–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ\n",
    "import torch\n",
    "from transformers import GPT2Tokenizer\n",
    "import codecs\n",
    "import numpy as np\n",
    "\n",
    "from trl import AutoModelForCausalLMWithValueHead\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5e3e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt2_finetuned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84144b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. load a pretrained model\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "#model = AutoModelForCausalLMWithValueHead.from_pretrained(model_name)\n",
    "#model_ref = AutoModelForCausalLMWithValueHead.from_pretrained(model_name)\n",
    "\n",
    "#tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "#tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90805bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#–£—á–∏–º —ç—Ç—É –º–æ–¥–µ–ª—å. –£ Nehc –µ—Å—Ç—å –ø—Ä–∏–º–µ—Ä, –∫–∞–∫ —ç—Ç–æ –¥–µ–ª–∞—Ç—å\n",
    "#–ú–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–æ–∫–µ–Ω–∞–π–∑–µ—Ä–∞ \n",
    "#–¥–æ–±–∞–≤–ª—è–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ç–æ–∫–µ–Ω–æ–≤ –Ω–∞—à–µ–π —Ä–∞–∑–º–µ—Ç–∫–∏\n",
    "\n",
    "#—Å—é–¥–∞ –Ω–∞–¥–æ —Ñ–∏–≥–∞–Ω—É—Ç—å –≤–µ—Å—å —Å–ª–æ–≤–∞—Ä—å –∫–∞—Ä—Ç–∏–Ω–æ–∫\n",
    "video_tokens_cnt = 1024\n",
    "video_tokens = []\n",
    "for i in range(video_tokens_cnt):\n",
    "    video_tokens.append(f'<{i}>')\n",
    "    \n",
    "special_tokens_dict = {'additional_special_tokens': video_tokens + ['<IN>','<OUT>','<END>','|PAD|']}\n",
    "num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "print(tokenizer.all_special_tokens)\n",
    "tokenizer.pad_token = '|PAD|'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ceea69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
    "# —Ç–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∏, —ç—Ç–æ —É—Å—Ç—Ä–µ–≤—à–∏–π —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç–∞—Å–µ—Ç–∞, –Ω–æ –Ω–∞ –ø—Ä–∞–∫—Ç–∏–∫–µ\n",
    "# –æ–Ω –¥–∞–µ—Ç —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω—É—é –∑–∞–≥—Ä—É–∑–∫—É –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–æ–π –ø–∞–º—è—Ç–∏ –∏ –ø–æ–∑–≤–æ–ª—è–µ—Ç \n",
    "# –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–æ–ª—å—à–∏–π –±–∞—Ç—á.\n",
    "\n",
    "'''\n",
    "\n",
    "–ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç—Å—è, —á—Ç–æ –¥–∞—Ç–∞—Å–µ—Ç –≤—ã–≥–ª—è–¥–∏—Ç –∫–∞–∫-—Ç–æ —Ç–∞–∫: \n",
    "\n",
    "<IN>–°–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–µ –ø—Ä–æ—á—Ç–µ–Ω–∏–µ –°–¢–≠ –Ω–µ –æ—Ç—Ä–∏—Ü–∞–µ—Ç –Ω–∞–ª–∏—á–∏–µ –≠–° –∏ –µ–µ –≤–ª–∏—è–Ω–∏–µ –Ω–∞ –≤–∏–¥–æ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ, –Ω–æ –¥–µ–ª–∞–µ—Ç –∞–∫—Ü–µ–Ω—Ç –Ω–∞ \"–º—É—Ç–∞—Ü–∏–æ–Ω–Ω–æ–º —Ñ–∞–∫—Ç–æ—Ä–µ\" –∏–∑–º–µ–Ω—á–∏–≤–æ—Å—Ç–∏. –í –ª—é–±–æ–º —Å–ª—É—á–∞–µ, –±–ª–∞–≥–æ–¥–∞—Ä—é –∑–∞ –≤–∞—à –æ—Ç–≤–µ—Ç –ø–æ —Å—É—â–µ—Å—Ç–≤—É. ü§ù\n",
    "<OUT>–í—Å–µ –ø—Ä–∏–º–µ—Ä—ã –º—É—Ç–∞—Ü–∏–æ–Ω–Ω–æ–π –∏–∑–º–µ–Ω—á–∏–≤–æ—Å—Ç–∏ –Ω–µ —Å—Ç–æ–ª—å –æ—á–µ–≤–∏–¥–Ω—ã (–æ—Å–æ–±–µ–Ω–Ω–æ —Å —É—á–µ—Ç–æ–º –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è –ø—Ä—è–º–æ–≥–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –≥–µ–Ω-–ø—Ä–∏–∑–Ω–∞–∫).  –í—Å–µ–≥–¥–∞ –µ—Å—Ç—å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∞–ø—Ä–∏–æ—Ä–Ω–æ–≥–æ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–≥–æ –º–æ—Ä—Ñ–æ–∑–∞.\n",
    "<END>\n",
    "<IN>–ü—Ä–æ—Å—Ç–æ —Ç–µ–º–∞ —Å–∞–º–∞ —Ä–∏—Ñ–º—É–µ—Ç—Å—è —Å —Å–æ—Ä–∞–∑–º–µ—Ä–Ω—ã–º –≥–æ—Å—Ñ–∏–Ω–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–∏–µ–º...\n",
    "<OUT>–Ω—É —á—Ç–æ –≤–∞–º —Ç–∞–∫ —Ñ–∏–Ω–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–ª–æ—Å—å... –≤—Å–µ–º —Ñ—É–Ω–¥–∞–º–µ–Ω—Ç–∞–ª—å–Ω—ã–º –ø—Ä–æ–µ–∫—Ç–∞–º –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç —Ñ–∏–Ω–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–∏—è, —Ç–æ—á–Ω–µ–µ, —Å —Ñ–∏–Ω–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–∏–µ–º –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –ø–æ–ª–Ω—ã–π —Ä–∞–Ω–¥–æ–º. —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ. –≤–æ—Ç –±—É–¥–µ—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –ø—Ä–∏–∫–ª–∞–¥–Ω–æ–π –ø—Ä–æ–µ–∫—Ç ‚Äî —Ç–æ–≥–¥–∞ –∏ –Ω–∞–¥–æ –±—É–¥–µ—Ç –≤—ã–±–∏–≤–∞—Ç—å –¥–ª—è –Ω–µ–≥–æ —Ñ–∏–Ω–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–∏–µ\n",
    "<END>\n",
    "\n",
    "–í –ø—Ä–æ—Å—Ç–æ–º —Ç–µ—Å–∫—Ç–æ–≤–æ–º —Ñ–∞–π–ª–µ...\n",
    "\n",
    "'''\n",
    "\n",
    "if 0:\n",
    "    texts = ''\n",
    "    paths = ['data/thougths_my.txt', 'data/public_my.txt', 'data/dialogues_my.txt']\n",
    "    for path in paths:\n",
    "        with codecs.open(f'{path}', 'r', 'utf8') as f:\n",
    "            texts += ''.join(f.readlines())\n",
    "    texts = texts.replace('<s>', '<END>').replace('\\r\\n', '\\n').replace('</s>', '')\n",
    "    #IN OUT –Ω–µ –±—É–¥–µ—Ç\n",
    "    with codecs.open('data/all_txt.txt', 'w', 'utf8') as f:\n",
    "        f.write(texts)\n",
    "\n",
    "\n",
    "#–∞–Ω–Ω–æ—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–∞—Ä—Ç–∏–Ω–∫–∏\n",
    "path = 'data/image_annotations_plans.txt' \n",
    "with codecs.open(f'{path}', 'r', 'utf8') as f:\n",
    "    texts = ''.join(f.readlines())\n",
    "texts = texts.replace('<s>', '<END>').replace('\\r\\n', '\\n').replace('</s>', '')\n",
    "with codecs.open('data/all_txt.txt', 'w', 'utf8') as f:\n",
    "    f.write(texts)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc83cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#–≤–∏–∫–∏\n",
    "path = 'data/wiki_data.txt'     \n",
    "with codecs.open(f'{path}', 'r', 'utf8') as f:\n",
    "    texts = ''.join(f.readlines())\n",
    "texts = texts.replace('<s>', '<END>').replace('\\r\\n', '\\n').replace('</s>', '')\n",
    "\n",
    "with codecs.open('data/all_txt.txt', 'a', 'utf8') as f:\n",
    "    f.write(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bd128e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextDataset,DataCollatorForLanguageModeling\n",
    "\n",
    "train_dataset = TextDataset(\n",
    "          tokenizer=tokenizer,\n",
    "          file_path='data/all_txt.txt',\n",
    "          block_size=128)\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c20e680",
   "metadata": {},
   "outputs": [],
   "source": [
    "#–æ–±—É—á–µ–Ω–∏–µ\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import torch\n",
    "\n",
    "# –µ—Å–ª–∏ –Ω–µ –ª–µ–∑–µ—Ç –≤ –ø–∞–º—è—Ç—å, –º–æ–∂–Ω–æ —É–º–µ–Ω—å—à–∞—Ç—å **per_device_train_batch_size**\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./models/gpt_bot\", #The output directory\n",
    "    #evaluation_strategy=\"epoch\",\n",
    "    overwrite_output_dir=True, #overwrite the content of the output directory\n",
    "    num_train_epochs=4, # number of training epochs\n",
    "    per_device_train_batch_size= 19, # batch size for training\n",
    "    gradient_accumulation_steps=20,\n",
    "    #per_device_eval_batch_size=50,  # batch size for evaluation\n",
    "    eval_steps = 200, # Number of update steps between two evaluations.\n",
    "    save_steps=1000, # after # steps model is saved \n",
    "    warmup_steps=500,# number of warmup steps for learning rate scheduler\n",
    "    prediction_loss_only=True,\n",
    "    )\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    #train_dataset=tokenized_dataset['train'],\n",
    "    train_dataset=train_dataset,\n",
    "    #eval_dataset=test_dataset,\n",
    "    #compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4a8a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5366049",
   "metadata": {},
   "outputs": [],
   "source": [
    "#–º–æ–∂–Ω–æ –∑–∞—Å–µ–π–≤–∏—Ç—å –º–æ–¥–µ–ª—å –∏ –ø–æ—Ç–æ–º –ø—Ä–∏–º–µ–Ω—è—Ç—å –≤ RL\n",
    "if 1:\n",
    "    # save it locally\n",
    "    model.save_pretrained(\"gpt2_finetuned\")\n",
    "    tokenizer.save_pretrained('gpt2_finetuned')\n",
    "\n",
    "    # load the model from the Hub\n",
    "    #from transformers import AutoModelForCausalLM\n",
    "\n",
    "    #model = AutoModelForCausalLM.from_pretrained(\"my-fine-tuned-model-ppo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c33ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#—Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã { vertical-output: true }\n",
    "T_OUT = tokenizer.encode('<OUT>')[0]\n",
    "T_END = tokenizer.encode('<END>')[0]\n",
    "T_PAD = tokenizer.encode('|PAD|')[0]\n",
    "T_124 = tokenizer.encode('<124>')[0]\n",
    "\n",
    "T_OUT, T_END, T_PAD, T_124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348d7b43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669dd0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π –∂–µ–ª–µ–∑—è–∫–∞ —Ä–∞–∑—É–º–Ω–∞—è! –ö–∞–∫ —É —Ç–µ–±—è —Å–µ–≥–æ–¥–Ω—è –¥–µ–ª–∞?\"\n",
    "model.cuda()\n",
    "\n",
    "text = f\"<IN>{text}\\n<OUT>\"\n",
    "inpt = tokenizer.encode(text, return_tensors=\"pt\")\n",
    "inpt= inpt.cuda()\n",
    "\n",
    "out = model.generate(inpt,  max_length=len(inpt[0])+300, do_sample=True, top_k=5, top_p=0.95, temperature=1, eos_token_id=T_END, pad_token_id=T_PAD)\n",
    "\n",
    "out_tokens = torch.where(out[0]==T_OUT)\n",
    "last_repl = out[0][out_tokens[0][-1]+1:-1]\n",
    "repl = tokenizer.decode(last_repl)\n",
    "\n",
    "print(repl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9b2210",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer(text):\n",
    "    inpt = tokenizer.encode(text, return_tensors=\"pt\")\n",
    "    inpt= inpt.cuda()\n",
    "    print(text)\n",
    "\n",
    "    out = model.generate(inpt,  max_length=len(inpt[0])+300, do_sample=True, top_k=5, top_p=0.95, temperature=1, eos_token_id=T_END, pad_token_id=T_PAD)\n",
    "\n",
    "    out_tokens = torch.where(out[0]==T_OUT)\n",
    "    last_repl = out[0][out_tokens[0][-1]+1:-1]\n",
    "    repl = tokenizer.decode(last_repl)\n",
    "\n",
    "    print(repl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287963c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a11\n",
    "text = '<916><61><922><922><922><922><922><922><55><906><1022><830><376><830><830><830><830><61><771><402><438><751><830><925><925><830><61><580><519><920><462><830><925><925><925><61><120><519><255><327><61><925><328><55><483><657><255><49><328><830><925><147><120><287><328><830><328><61><830><706><957><29><222><925><55><55><55><328><851><590><596><164><376><61><328><328><328><801><925><422><255> description:'\n",
    "text = f\"<IN>{text}<OUT>\"\n",
    "answer(text)\n",
    "text = '<916><61><922><922><922><922><922><922><55><906><1022><830><376><830><830><830><830><61><771><402><438><751><830><925><925><830><61><580><519><920><462><830><925><925><925><61><120><519><255><327><61><925><328><55><483><657><255><49><328><830><925><147><120><287><328><830><328><61><830><706><957><29><222><925><55><55><55><328><851><590><596><164><376><61><328><328><328><801><925><422><255> save hp plan:'\n",
    "text = f\"<IN>{text}<OUT>\"\n",
    "answer(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb58d689",
   "metadata": {},
   "outputs": [],
   "source": [
    "#images (10).jpg\n",
    "text = '<597><813><813><110><813><813><556><714><937><778><985><173><891><893><61><873><261><96><761><189><481><230><215><140><661><192><444><548><897><548><720><333><828><884><171><192><508><966><577><805><611><965><661><414><966><638><255><406><979><254><966><92><244><439><404><811><187><906><164><297><313><330><514><925><979><681><671><758><608><36><49><1019><468><140><574><325><287><217><714><562><432> description:'\n",
    "text = f\"<IN>{text}<OUT>\"\n",
    "answer(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab53c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#images (2).jpg\n",
    "text = '<685><714><719><632><910><590><299><894><473><634><812><334><607><382><250><526><422><862><710><774><780><552><437><20><894><746><597><323><1006><422><406><813><370><414><854><473><330><941><681><323><813><870><845><432><7><642><599><57><717><845><269><473><714><96><29><596><870><477><283><477><974><884><215><881><596><698><333><517><460><893><813><222><402><110><714><996><407><718><172><189><150> description:'\n",
    "text = f\"<IN>{text}<OUT>\"\n",
    "answer(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f5753e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44c087b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39666ace",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a4d187",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
