{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a98f3259",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "E:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "E:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\numpy\\.libs\\libopenblas.JPIJNSWNNAN3CE6LLI5FWSPHUT2VXMTH.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n",
      "E:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "#Это пример изготовления датасета с картинками\n",
    "import cv2\n",
    "import torch\n",
    "import yaml\n",
    "import torch\n",
    "import os\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import codecs\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from omegaconf import OmegaConf\n",
    "from taming.models.vqgan import VQModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac27df97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "E:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips\\vgg.pth\n",
      "VQLPIPSWithDiscriminator running with hinge loss.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nsz = []\\n\\nplt.figure(figsize=(20, 40))\\nimg_rec = []\\nfor i in range(1):\\n  #quant_states, indices = V_encoder.encode(DS.obs[i+2][0])\\n  x = preprocess_vqgan(DS.obs[i+2])\\n  with torch.no_grad():\\n    z, _, [_, _, ind] = vq_model.encode(x.to(\\'cuda\\'))\\n    b,c,h,w = z.shape\\n    nz = vq_model.quantize.get_codebook_entry(ind, (b,h,w,c))\\n    rec = vq_model.decode(nz).detach().cpu()\\n    sz.append(h*w)\\n  #print(rec.shape)\\n  img_rec.append(preprocess(rec))\\n\\nfor i in range(1):\\n  for j in range(1):\\n    plt.subplot(10, 6, i*6+j+1)\\n    plt.axis(\"off\")\\n    plt.imshow(DS.obs[j+2][i])\\n    plt.title(f\\'origin {DS.obs[j+2][i].shape}\\')\\n  for j in range(1):\\n    plt.subplot(10, 6, i*6+j+4)\\n    plt.axis(\"off\")\\n    plt.imshow(img_rec[j][i])\\n    plt.title(f\\'sintetic {sz[j]} token\\')\\n\\nplt.show();\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#VQ-GAN 1024 \n",
    "Model = \"f16_1024\" #param [\"f16_1024\", \"f16_16384\", \"f16_16384_hf\"]\n",
    "\n",
    "\n",
    "def load_config(config_path, display=False):\n",
    "  config = OmegaConf.load(config_path)\n",
    "  if display:\n",
    "    print(yaml.dump(OmegaConf.to_container(config)))\n",
    "  return config\n",
    "\n",
    "def load_vqgan(config, ckpt_path=None):\n",
    "  model = VQModel(**config.model.params)\n",
    "  if ckpt_path is not None:\n",
    "    sd = torch.load(ckpt_path, map_location=\"cpu\")[\"state_dict\"]\n",
    "    missing, unexpected = model.load_state_dict(sd, strict=False)\n",
    "  return model.eval()\n",
    "\n",
    "def preprocess_vqgan(x, roll=True):\n",
    "  x = 2.*x - 1.\n",
    "  if roll:\n",
    "    x = np.rollaxis(x,3,1)\n",
    "  x = torch.Tensor(x)\n",
    "  return x\n",
    "\n",
    "def preprocess(x, permt=True):\n",
    "  if permt:\n",
    "    x = x.permute(0,2,3,1).numpy()\n",
    "  x = np.clip(x, -1., 1.)\n",
    "  x = (x + 1.)/2.\n",
    "  return x\n",
    "\n",
    "def custom_to_pil(x):\n",
    "  x = np.clip(x, -1., 1.)\n",
    "  x = (x + 1.)/2.\n",
    "  x = (255*x).astype(np.uint8)\n",
    "  x = Image.fromarray(x)\n",
    "  if not x.mode == \"RGB\":\n",
    "    x = x.convert(\"RGB\")\n",
    "  return x\n",
    "\n",
    "vq_conf = load_config(f\"chk_points/vqgan_imagenet_{Model}.yaml\", display=False)\n",
    "vq_model = load_vqgan(vq_conf, ckpt_path=f\"chk_points/vqgan_imagenet_{Model}.ckpt\").to('cuda')\n",
    "\n",
    "'''\n",
    "sz = []\n",
    "\n",
    "plt.figure(figsize=(20, 40))\n",
    "img_rec = []\n",
    "for i in range(1):\n",
    "  #quant_states, indices = V_encoder.encode(DS.obs[i+2][0])\n",
    "  x = preprocess_vqgan(DS.obs[i+2])\n",
    "  with torch.no_grad():\n",
    "    z, _, [_, _, ind] = vq_model.encode(x.to('cuda'))\n",
    "    b,c,h,w = z.shape\n",
    "    nz = vq_model.quantize.get_codebook_entry(ind, (b,h,w,c))\n",
    "    rec = vq_model.decode(nz).detach().cpu()\n",
    "    sz.append(h*w)\n",
    "  #print(rec.shape)\n",
    "  img_rec.append(preprocess(rec))\n",
    "\n",
    "for i in range(1):\n",
    "  for j in range(1):\n",
    "    plt.subplot(10, 6, i*6+j+1)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(DS.obs[j+2][i])\n",
    "    plt.title(f'origin {DS.obs[j+2][i].shape}')\n",
    "  for j in range(1):\n",
    "    plt.subplot(10, 6, i*6+j+4)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img_rec[j][i])\n",
    "    plt.title(f'sintetic {sz[j]} token')\n",
    "\n",
    "plt.show();\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35b4bc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "imsize = [16*9, 16*9]\n",
    "images_storage = \"./data/imgs\"\n",
    "txt_to_process = './data/parts/imgs_descs.txt'\n",
    "txt_to_write = './data/parts/imgs_descs_tokenized.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "381b3665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('data/imgs/a1.png'),\n",
       " WindowsPath('data/imgs/doom-eternal-2020.03.20-07.55.18.02_trim_dvd.original.jpg'),\n",
       " WindowsPath('data/imgs/50299867.jpg'),\n",
       " WindowsPath('data/imgs/2YYBfaq.jpg'),\n",
       " WindowsPath('data/imgs/SlzvQI.png')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = sorted(Path(images_storage).iterdir(), key=os.path.getmtime)\n",
    "lst.reverse()\n",
    "lst[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "387d1f0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with codecs.open(f'{txt_to_process}', 'r', 'utf8', errors='ignore') as f:\n",
    "    text = ''.join(f.readlines())\n",
    "\n",
    "p = Path(images_storage)\n",
    "i = 0\n",
    "for img_name in lst:#p.rglob(\"*\"):\n",
    "    i += 1\n",
    "    if np.random.rand()<0.001:\n",
    "        if not ('<<' in text):\n",
    "            break\n",
    "    img_name_short = str(img_name).split('/')[-1].split('\\\\')[-1]\n",
    "    if img_name_short in text:\n",
    "        #скачать и декодировать картинку\n",
    "        img_orig = np.array(cv2.resize(cv2.imread(str(img_name)), imsize), dtype=np.float32)/255.\n",
    "        b,g,r = img_orig[:,:,0], img_orig[:,:,1], img_orig[:,:,2]\n",
    "        img_orig = np.dstack([r, g, b])\n",
    "        img = preprocess_vqgan(np.stack(1*[img_orig]), True)       \n",
    "        \n",
    "        z, _, [_, _, ind] = vq_model.encode(img.to('cuda'))\n",
    "        ind.squeeze_()\n",
    "        b,c,h,w = z.shape\n",
    "        #nz = vq_model.quantize.get_codebook_entry(ind, (b,h,w,c))\n",
    "        #print('nz', nz)\n",
    "        token_string = '<' + '><'.join( [str(el) for el in list(ind.detach().cpu().numpy())] ) + '>'\n",
    "        nz = vq_model.quantize.get_codebook_entry(ind, (b,h,w,c))\n",
    "        rec = vq_model.decode(nz).detach().cpu()\n",
    "        if np.random.rand()<0.002:\n",
    "            print('i', i)\n",
    "            plt.imshow(img_orig)\n",
    "            plt.show()\n",
    "            plt.imshow(preprocess(rec)[0])\n",
    "            plt.show()\n",
    "        \n",
    "        \n",
    "        text = text.replace(f'<<{img_name_short}>>', token_string)\n",
    "        \n",
    "#text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66c1f9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.replace('description:', 'description:<OUT>').replace('forecast vars:', 'forecast vars:<OUT>').replace('forecast img:', 'forecast img:<OUT>').replace('plan:', 'plan:<OUT>').replace('<END>\\r\\n', '<END>\\r\\n<IN>')\n",
    "text = '<IN>' + text\n",
    "text = text.replace(\"<OUT><OUT>\", \"<OUT>\").replace(\"<IN><IN>\", \"<IN>\")\n",
    "#text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "094aef5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with codecs.open(txt_to_write, 'w', 'utf8') as f:\n",
    "    f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a4d187",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
