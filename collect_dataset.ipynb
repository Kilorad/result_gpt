{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b2b642",
   "metadata": {},
   "outputs": [],
   "source": [
    "#собрать датасет из кусков\n",
    "from pathlib import Path\n",
    "import codecs\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680ccc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#аннотированные картинки\n",
    "path = 'data/parts/image_annotations_plans.txt' \n",
    "with codecs.open(f'{path}', 'r', 'utf8') as f:\n",
    "    lst = f.readlines()\n",
    "    lst = sample(lst, int(len(lst)*0.8))\n",
    "    texts = ''.join(lst)\n",
    "texts = texts.replace('<s>', '<END>').replace('\\r\\n', '\\n').replace('</s>', '')\n",
    "#.replace('<IN>', '')\n",
    "texts = texts.replace('>f', '> f').replace('>d', '> d').replace('>p', '> p').replace('>s', '> s').replace('>k', '> k').replace('  ', ' ').replace('\\n', '\\n<IN>').replace('<IN><IN>', '<IN>')\n",
    "print('texts', len(texts))\n",
    "with codecs.open('data/parts/all_txt.txt', 'w', 'utf8') as f:\n",
    "    f.write(texts)\n",
    "    \n",
    "    \n",
    "def process_book(path, drop_spaces=True):  \n",
    "    with codecs.open(f'{path}', 'r', 'utf8', errors='ignore') as f:\n",
    "        texts = ''.join(f.readlines())\n",
    "    texts = texts.replace('<s>', '<END>').replace('\\r\\n', '\\n').replace('</s>', '')\n",
    "    if drop_spaces:\n",
    "        texts = texts.replace('\\n', '\\t')#у нас датасет такой\n",
    "        texts = '\\n' + texts\n",
    "    print(path, 'texts', len(texts))\n",
    "    with codecs.open('data/parts/all_txt.txt', 'a', 'utf8') as f:\n",
    "        f.write(texts)\n",
    "        \n",
    "if 1:\n",
    "    #вики\n",
    "    path = 'data/parts/wiki_data.txt'\n",
    "    process_book(path)\n",
    "    process_book(path, drop_spaces=False)\n",
    "\n",
    "\n",
    "    #/toy_text_doom_tasks\n",
    "    path = 'data/parts/toy_text_doom_tasks.txt'     \n",
    "    process_book(path, drop_spaces=False)\n",
    "\n",
    "    #logic\n",
    "    #path = 'data/parts/formal_logic_textbook.txt'     \n",
    "    #process_book(path)\n",
    "    #process_book(path, drop_spaces=False)\n",
    "\n",
    "\n",
    "    #hpmor\n",
    "    path = 'data/parts/hpmor.txt'     \n",
    "    process_book(path)   \n",
    "    process_book(path, drop_spaces=False)\n",
    "\n",
    "    path = \"data/parts/Book 1 - The Philosopher's Stone.txt\"\n",
    "    process_book(path)   \n",
    "    process_book(path, drop_spaces=False)\n",
    "\n",
    "    path = 'data/parts/Book 2 - The Chamber of Secrets.txt'\n",
    "    process_book(path)\n",
    "    process_book(path, drop_spaces=False)\n",
    "\n",
    "    path = 'data/parts/Book 4 - The Goblet of Fire.txt'\n",
    "    process_book(path)\n",
    "    process_book(path, drop_spaces=False)\n",
    "\n",
    "    #rationality.txt\n",
    "    path = 'data/parts/Map and Territory.txt'     \n",
    "    process_book(path)\n",
    "    process_book(path, drop_spaces=False)\n",
    "\n",
    "    path = 'data/parts/doom fanfics.txt' \n",
    "    process_book(path)\n",
    "    process_book(path, drop_spaces=False)\n",
    "\n",
    "    path = 'data/parts/treasure island.txt' \n",
    "    process_book(path)\n",
    "    process_book(path, drop_spaces=False)\n",
    "\n",
    "    path = 'data/parts/robinson crusoe.txt' \n",
    "    process_book(path)\n",
    "    process_book(path, drop_spaces=False)\n",
    "\n",
    "    #path = 'data/parts/Sherlock Holmes.txt' \n",
    "    #process_book(path)\n",
    "\n",
    "    path = 'data/parts/scrum.txt' \n",
    "    process_book(path)\n",
    "    process_book(path, drop_spaces=False)\n",
    "\n",
    "    path = 'data/parts/military stories.txt' \n",
    "    process_book(path)\n",
    "    process_book(path, drop_spaces=False)\n",
    "\n",
    "    path = 'data/parts/military stories 2.txt' \n",
    "    process_book(path)\n",
    "    process_book(path, drop_spaces=False)\n",
    "\n",
    "    path = 'data/parts/doom wiki.txt'\n",
    "    process_book(path)\n",
    "    process_book(path, drop_spaces=False)\n",
    "\n",
    "    path = 'data/parts/homm.txt'\n",
    "    process_book(path)\n",
    "    process_book(path, drop_spaces=False)\n",
    "\n",
    "    path = 'data/parts/military materials.txt'\n",
    "    process_book(path)\n",
    "    process_book(path, drop_spaces=False)\n",
    "\n",
    "    path = 'data/parts/military materials 2.txt'\n",
    "    process_book(path)\n",
    "    process_book(path, drop_spaces=False)\n",
    "\n",
    "    path = 'data/parts/anatomy.txt'\n",
    "    process_book(path)\n",
    "    process_book(path, drop_spaces=False)\n",
    "\n",
    "    path = 'data/parts/churchill.txt'\n",
    "    process_book(path)\n",
    "    process_book(path, drop_spaces=False)\n",
    "\n",
    "    path = 'data/parts/summary_data.txt'\n",
    "    process_book(path, drop_spaces=False)\n",
    "\n",
    "    path = 'data/parts/dialogues_text.txt'\n",
    "    process_book(path, drop_spaces=False)\n",
    "\n",
    "    path = 'data/parts/chat_data.txt'\n",
    "    process_book(path, drop_spaces=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dfd250",
   "metadata": {},
   "outputs": [],
   "source": [
    "#аннотированные картинки с памятью\n",
    "if 0:\n",
    "    path = 'data/parts/imgs_descs_memory.txt' \n",
    "    with codecs.open(f'{path}', 'r', 'utf8') as f:\n",
    "        lst = f.readlines()\n",
    "        lst = sample(lst, int(len(lst)*0.9))\n",
    "        texts += '\\n' + ''.join(lst)\n",
    "    texts = texts.replace('<s>', '<END>').replace('\\r\\n', '\\n').replace('</s>', '')\n",
    "    print('texts', len(texts))\n",
    "    with codecs.open('data/parts/all_txt.txt', 'a', 'utf8') as f:\n",
    "        f.write(texts)\n",
    "\n",
    "    path = 'data/parts/imgs_descs_memory_2.txt' \n",
    "    with codecs.open(f'{path}', 'r', 'utf8') as f:\n",
    "        lst = f.readlines()\n",
    "        lst = sample(lst, int(len(lst)*0.9))\n",
    "        texts += '\\n' + ''.join(lst)\n",
    "    texts = texts.replace('<s>', '<END>').replace('\\r\\n', '\\n').replace('</s>', '')\n",
    "    print('texts', len(texts))\n",
    "\n",
    "path = 'data/parts/imgs_descs_memory_3.txt' \n",
    "with codecs.open(f'{path}', 'r', 'utf8') as f:\n",
    "    lst = f.readlines()\n",
    "    lst = sample(lst, int(len(lst)*0.9))\n",
    "    texts += '\\n' + ''.join(lst)\n",
    "texts = texts.replace('<s>', '<END>').replace('\\r\\n', '\\n').replace('</s>', '')\n",
    "print('texts', len(texts))\n",
    "    \n",
    "#R\n",
    "if 0:\n",
    "    path = 'data/parts/imgs_descs_memory_4.txt' \n",
    "    with codecs.open(f'{path}', 'r', 'utf8') as f:\n",
    "        lst = f.readlines()\n",
    "        lst = sample(lst, int(len(lst)*0.99))\n",
    "        texts += '\\n' + ''.join(lst)\n",
    "    print('texts', path, len(texts))\n",
    "\n",
    "    path = 'data/parts/imgs_descs_memory_5.txt' \n",
    "    with codecs.open(f'{path}', 'r', 'utf8') as f:\n",
    "        lst = f.readlines()\n",
    "        lst = sample(lst, int(len(lst)*0.99))\n",
    "        texts += '\\n' + ''.join(lst)\n",
    "    print('texts', path, len(texts))\n",
    "\n",
    "    path = 'data/parts/imgs_descs_memory_6.txt' \n",
    "    with codecs.open(f'{path}', 'r', 'utf8') as f:\n",
    "        lst = f.readlines()\n",
    "        lst = sample(lst, int(len(lst)*0.99))\n",
    "        texts += '\\n' + ''.join(lst)\n",
    "    print('texts', path, len(texts))\n",
    "\n",
    "    path = 'data/parts/imgs_descs_memory_7.txt' \n",
    "    with codecs.open(f'{path}', 'r', 'utf8') as f:\n",
    "        lst = f.readlines()\n",
    "        lst = sample(lst, int(len(lst)*0.99))\n",
    "        texts += '\\n' + ''.join(lst)\n",
    "    print('texts', path, len(texts))\n",
    "\n",
    "    path = 'data/parts/imgs_descs_memory_8.txt' \n",
    "    with codecs.open(f'{path}', 'r', 'utf8') as f:\n",
    "        lst = f.readlines()\n",
    "        lst = sample(lst, int(len(lst)*0.99))\n",
    "        texts += '\\n' + ''.join(lst)\n",
    "    print('texts', path, len(texts))\n",
    "\n",
    "    path = 'data/parts/imgs_descs_memory_9.txt' \n",
    "    with codecs.open(f'{path}', 'r', 'utf8') as f:\n",
    "        lst = f.readlines()\n",
    "        lst = sample(lst, int(len(lst)*0.99))\n",
    "        texts += '\\n' + ''.join(lst)\n",
    "    print('texts', path, len(texts))\n",
    "\n",
    "    path = 'data/parts/imgs_descs_memory_10.txt' \n",
    "    with codecs.open(f'{path}', 'r', 'utf8') as f:\n",
    "        lst = f.readlines()\n",
    "        lst = sample(lst, int(len(lst)*0.99))\n",
    "        texts += '\\n' + ''.join(lst)\n",
    "    print('texts', path, len(texts))\n",
    "\n",
    "    path = 'data/parts/imgs_descs_memory_11.txt' \n",
    "    with codecs.open(f'{path}', 'r', 'utf8') as f:\n",
    "        lst = f.readlines()\n",
    "        lst = sample(lst, int(len(lst)*0.99))\n",
    "        texts += '\\n' + ''.join(lst)\n",
    "    print('texts', path, len(texts))\n",
    "\n",
    "    path = 'data/parts/imgs_descs_memory_12.txt' \n",
    "    with codecs.open(f'{path}', 'r', 'utf8') as f:\n",
    "        lst = f.readlines()\n",
    "        lst = sample(lst, int(len(lst)*0.99))\n",
    "        texts += '\\n' + ''.join(lst)\n",
    "    print('texts', path, len(texts))\n",
    "    \n",
    "#R + descr\n",
    "if 0:\n",
    "    path = 'data/parts/imgs_descs_memory_13.txt' \n",
    "    with codecs.open(f'{path}', 'r', 'utf8') as f:\n",
    "        lst = f.readlines()\n",
    "        lst = sample(lst, int(len(lst)*0.99))\n",
    "        texts += '\\n' + ''.join(lst)\n",
    "    print('texts', path, len(texts))\n",
    "    \n",
    "    path = 'data/parts/imgs_descs_memory_14.txt' \n",
    "    with codecs.open(f'{path}', 'r', 'utf8') as f:\n",
    "        lst = f.readlines()\n",
    "        lst = sample(lst, int(len(lst)*0.99))\n",
    "        texts += '\\n' + ''.join(lst)\n",
    "    print('texts', path, len(texts))\n",
    "\n",
    "#R + descr + no summaries\n",
    "if 0:\n",
    "    path = 'data/parts/imgs_descs_memory_15.txt' \n",
    "    with codecs.open(f'{path}', 'r', 'utf8') as f:\n",
    "        lst = f.readlines()\n",
    "        lst = sample(lst, int(len(lst)*0.99))\n",
    "        texts += '\\n' + ''.join(lst)\n",
    "    print('texts', path, len(texts))\n",
    "    \n",
    "    path = 'data/parts/imgs_descs_memory_16.txt' \n",
    "    with codecs.open(f'{path}', 'r', 'utf8') as f:\n",
    "        lst = f.readlines()\n",
    "        lst = sample(lst, int(len(lst)*0.99))\n",
    "        texts += '\\n' + ''.join(lst)\n",
    "    print('texts', path, len(texts))\n",
    "    \n",
    "    path = 'data/parts/imgs_descs_memory_17.txt' \n",
    "    with codecs.open(f'{path}', 'r', 'utf8') as f:\n",
    "        lst = f.readlines()\n",
    "        lst = sample(lst, int(len(lst)*0.99))\n",
    "        texts += '\\n' + ''.join(lst)\n",
    "    print('texts', path, len(texts))\n",
    "    \n",
    "    path = 'data/parts/imgs_descs_memory_18.txt' \n",
    "    with codecs.open(f'{path}', 'r', 'utf8') as f:\n",
    "        lst = f.readlines()\n",
    "        lst = sample(lst, int(len(lst)*0.99))\n",
    "        texts += '\\n' + ''.join(lst)\n",
    "    print('texts', path, len(texts))\n",
    "\n",
    "#R + descr + no summaries + correct reward\n",
    "if 1:\n",
    "    path = 'data/parts/imgs_descs_memory_19.txt' \n",
    "    with codecs.open(f'{path}', 'r', 'utf8') as f:\n",
    "        lst = f.readlines()\n",
    "        lst = sample(lst, int(len(lst)*0.99))\n",
    "        texts += '\\n' + ''.join(lst)\n",
    "    print('texts', path, len(texts))\n",
    "    \n",
    "    \n",
    "    path = 'data/parts/imgs_descs_memory_20.txt' \n",
    "    with codecs.open(f'{path}', 'r', 'utf8') as f:\n",
    "        lst = f.readlines()\n",
    "        lst = sample(lst, int(len(lst)*0.99))\n",
    "        texts += '\\n' + ''.join(lst)\n",
    "    print('texts', path, len(texts))\n",
    "    \n",
    "    path = 'data/parts/imgs_descs_memory_21.txt' \n",
    "    with codecs.open(f'{path}', 'r', 'utf8') as f:\n",
    "        lst = f.readlines()\n",
    "        lst = sample(lst, int(len(lst)*0.99))\n",
    "        texts += '\\n' + ''.join(lst)\n",
    "    print('texts', path, len(texts))\n",
    "    \n",
    "    path = 'data/parts/imgs_descs_memory_hum.txt' \n",
    "    with codecs.open(f'{path}', 'r', 'utf8') as f:\n",
    "        lst = f.readlines()\n",
    "        lst = sample(lst, int(len(lst)*0.99))\n",
    "        for i in range(18):\n",
    "            texts += '\\n' + ''.join(lst)\n",
    "    print('texts', path, len(texts))\n",
    "    \n",
    "texts = texts.replace('<s>', '<END>').replace('\\r\\n', '\\n').replace('</s>', '')\n",
    "with codecs.open('data/parts/all_txt.txt', 'a', 'utf8') as f:\n",
    "    f.write(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8327647c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cut text\n",
    "import codecs\n",
    "thresh = 10000000\n",
    "thresh = 300000\n",
    "with codecs.open('data/parts/all_txt.txt', 'r', 'utf8', errors='ignore') as f:\n",
    "    lines = f.readlines()\n",
    "print(len(lines))\n",
    "lines = [line[:thresh] for line in lines]\n",
    "lines_new = []\n",
    "for line in lines:\n",
    "    maxlen = 256*5\n",
    "    if ('plan:<OUT>' in line) and (len(line) > maxlen):\n",
    "        print(len(line), line)\n",
    "        line = line[-maxlen:]\n",
    "    if ('<r-' in line) and ('kill all plan' in line):\n",
    "        line = \"\"\n",
    "    if len(line)>1:\n",
    "        lines_new.append(line)\n",
    "lines = lines_new\n",
    "lines = '\\n'.join(lines)\n",
    "lines = lines.replace('\\n\\n', '\\n').replace('\\n\\n', '\\n')\n",
    "\n",
    "with codecs.open('data/all_txt_cut_r.txt', 'w', 'utf8') as f:\n",
    "    f.write(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdc36d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with codecs.open('data/all_txt_cut_r_low.txt', 'w', 'utf8') as f:\n",
    "    f.write(lines[-10000000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52107772",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with codecs.open('data/all_txt_cut_r_low.txt', 'w', 'utf8') as f:\n",
    "#    f.write(lines[-10000:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
