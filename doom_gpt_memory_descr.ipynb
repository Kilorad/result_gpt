{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 638,
     "status": "ok",
     "timestamp": 1602319586434,
     "user": {
      "displayName": "Сергей Довгань",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3MZ2GUNo7qvuOUXjppWtslpJefb5Bk2H8pvQgsg=s64",
      "userId": "11204475592062912374"
     },
     "user_tz": -180
    },
    "id": "GpmKtdv6Lohe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "E:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "E:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\numpy\\.libs\\libopenblas.JPIJNSWNNAN3CE6LLI5FWSPHUT2VXMTH.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "#Result-GPT для Doom. Но теперь с памятью. И с дескрипшнами перед принятием решений\n",
    "import sys\n",
    "import os\n",
    "import importlib\n",
    "#root = './drive/My Drive/Colab Notebooks/rl/'\n",
    "root = './'\n",
    "sys.path.insert(1, root + 'env')\n",
    "sys.path.insert(1, root + 'agents')\n",
    "sys.path.insert(1, root + 'common')\n",
    "\n",
    "import gym\n",
    "import pylab\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import copy\n",
    "import vizdoom\n",
    "from vizdoom import *\n",
    "import cv2\n",
    "from os.path import exists\n",
    "import codecs\n",
    "\n",
    "import torch\n",
    "from transformers import GPT2Tokenizer\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')\n",
    "#device = torch.device('cpu', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPISODES=5\n",
    "episode_len = 1900#1900\n",
    "subtraj_len = 130\n",
    "#subtraj_selection = 450#1000\n",
    "subtraj_selection = 2\n",
    "recoms_count = 0\n",
    "#recoms_count = 0\n",
    "actions_count = 11\n",
    "frc_count = 10\n",
    "frc_len = 40\n",
    "\n",
    "subtraj_len_dense = 130#50\n",
    "recoms_dense_period = 1\n",
    "recoms_count_dense = 4000\n",
    "\n",
    "proba_desc = 0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<<image>> summarize: (обычное описание)\n",
    "#(summary) <<image>> plan: (обычный план)\n",
    "#А (summary) <<image>> summarize: history: (прошлое summary); (обычное описание)\n",
    "#ИЛИ\n",
    "#Б (summary) <<image>> summarize: history: (delta summary); (обычное описание)\n",
    "#А проще, а если summary ещё и обрезать, то А вполне реализуемо"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install numpy==1.23.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Я не знаю, где они лежат, надо искать\n",
    "data_path = '../gpt/chatgpt/data/all_txt_cut.txt'\n",
    "model_name = \"../gpt/chatgpt/gpt2_finetuned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<IN><714><872><373><545><698><887><803><718><40><790><505><692><40><751><269><597><587><514><255><891><870><556><706><208><897><362><937><572><330><358><626><635><830><362><910><751><553><966><414><758><219><125><928><887><526><297><313><878><806><922><598><582><358><308><7><433><66><172><202><44><192><528><994><301><780><539><316><80><988><523><630><585><500><32><172><642><746><109><590><379><661> description:<OUT><OUT> serious sam, machinegun in hands, shooting, klir right-ahead, klir ahead, kilr at left, purple zombie far at right, blue ammo box far left-ahead<END>\\n\\n<IN><714><872><373><545><698><887><803><718><40><790><505><692><40><751><269><597><587><514><255><891><870><556><706><208><897><362><937><572><330><358><626><635><830><362><910><751><553><966><414><758><219><125><928><887><526><297><313><878><806><922><598><582><358><308><7><433><66><172><202><44><192><528><994><301><780><539><316><80><988><523><630><585><500><32><172><642><746><109><590><379><661> kill all plan:<OUT><OU'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import codecs\n",
    "with codecs.open(data_path, 'r', 'utf8', errors='ignore') as f:\n",
    "    lines = f.readlines()\n",
    "lines = ''.join(lines)\n",
    "lines[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../gpt/chatgpt/gpt2_finetuned were not used when initializing GPT2LMHeadModel: ['v_head.2.bias', 'v_head.4.weight', 'v_head.4.bias', 'v_head.0.weight', 'v_head.0.bias', 'v_head.2.weight']\n",
      "- This IS expected if you are initializing GPT2LMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPT2LMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(51785, 1024)\n",
       "    (wpe): Embedding(1024, 1024)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-23): 24 x GPT2Block(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=51785, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. load a pretrained model\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-25.0 - 24.9\n"
     ]
    }
   ],
   "source": [
    "reward2substr = {}\n",
    "step = 0.1\n",
    "max_val = 25\n",
    "min_val = -25\n",
    "for val in np.arange(min_val, max_val, step):\n",
    "    val = np.round(val, 2)\n",
    "    key = f'<r{val}>'\n",
    "    reward2substr[val] = key\n",
    "print(list(reward2substr.keys())[0],'-',list(reward2substr.keys())[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_make_substr(r):\n",
    "    if r in list(reward2substr.keys()):\n",
    "        return reward2substr[r]\n",
    "    else:\n",
    "        if r>max_val:\n",
    "            r = max_val - 0.1\n",
    "        elif r<min_val:\n",
    "            r = min_val\n",
    "        r = np.round(r, 1)\n",
    "        return reward2substr[r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<|endoftext|>', '|PAD|', '<0>', '<1>', '<2>', '<3>', '<4>', '<5>', '<6>', '<7>', '<8>', '<9>', '<10>', '<11>', '<12>', '<13>', '<14>', '<15>', '<16>', '<17>', '<18>', '<19>', '<20>', '<21>', '<22>', '<23>', '<24>', '<25>', '<26>', '<27>', '<28>', '<29>', '<30>', '<31>', '<32>', '<33>', '<34>', '<35>', '<36>', '<37>', '<38>', '<39>', '<40>', '<41>', '<42>', '<43>', '<44>', '<45>', '<46>', '<47>', '<48>', '<49>', '<50>', '<51>', '<52>', '<53>', '<54>', '<55>', '<56>', '<57>', '<58>', '<59>', '<60>', '<61>', '<62>', '<63>', '<64>', '<65>', '<66>', '<67>', '<68>', '<69>', '<70>', '<71>', '<72>', '<73>', '<74>', '<75>', '<76>', '<77>', '<78>', '<79>', '<80>', '<81>', '<82>', '<83>', '<84>', '<85>', '<86>', '<87>', '<88>', '<89>', '<90>', '<91>', '<92>', '<93>', '<94>', '<95>', '<96>', '<97>', '<98>', '<99>', '<100>', '<101>', '<102>', '<103>', '<104>', '<105>', '<106>', '<107>', '<108>', '<109>', '<110>', '<111>', '<112>', '<113>', '<114>', '<115>', '<116>', '<117>', '<118>', '<119>', '<120>', '<121>', '<122>', '<123>', '<124>', '<125>', '<126>', '<127>', '<128>', '<129>', '<130>', '<131>', '<132>', '<133>', '<134>', '<135>', '<136>', '<137>', '<138>', '<139>', '<140>', '<141>', '<142>', '<143>', '<144>', '<145>', '<146>', '<147>', '<148>', '<149>', '<150>', '<151>', '<152>', '<153>', '<154>', '<155>', '<156>', '<157>', '<158>', '<159>', '<160>', '<161>', '<162>', '<163>', '<164>', '<165>', '<166>', '<167>', '<168>', '<169>', '<170>', '<171>', '<172>', '<173>', '<174>', '<175>', '<176>', '<177>', '<178>', '<179>', '<180>', '<181>', '<182>', '<183>', '<184>', '<185>', '<186>', '<187>', '<188>', '<189>', '<190>', '<191>', '<192>', '<193>', '<194>', '<195>', '<196>', '<197>', '<198>', '<199>', '<200>', '<201>', '<202>', '<203>', '<204>', '<205>', '<206>', '<207>', '<208>', '<209>', '<210>', '<211>', '<212>', '<213>', '<214>', '<215>', '<216>', '<217>', '<218>', '<219>', '<220>', '<221>', '<222>', '<223>', '<224>', '<225>', '<226>', '<227>', '<228>', '<229>', '<230>', '<231>', '<232>', '<233>', '<234>', '<235>', '<236>', '<237>', '<238>', '<239>', '<240>', '<241>', '<242>', '<243>', '<244>', '<245>', '<246>', '<247>', '<248>', '<249>', '<250>', '<251>', '<252>', '<253>', '<254>', '<255>', '<256>', '<257>', '<258>', '<259>', '<260>', '<261>', '<262>', '<263>', '<264>', '<265>', '<266>', '<267>', '<268>', '<269>', '<270>', '<271>', '<272>', '<273>', '<274>', '<275>', '<276>', '<277>', '<278>', '<279>', '<280>', '<281>', '<282>', '<283>', '<284>', '<285>', '<286>', '<287>', '<288>', '<289>', '<290>', '<291>', '<292>', '<293>', '<294>', '<295>', '<296>', '<297>', '<298>', '<299>', '<300>', '<301>', '<302>', '<303>', '<304>', '<305>', '<306>', '<307>', '<308>', '<309>', '<310>', '<311>', '<312>', '<313>', '<314>', '<315>', '<316>', '<317>', '<318>', '<319>', '<320>', '<321>', '<322>', '<323>', '<324>', '<325>', '<326>', '<327>', '<328>', '<329>', '<330>', '<331>', '<332>', '<333>', '<334>', '<335>', '<336>', '<337>', '<338>', '<339>', '<340>', '<341>', '<342>', '<343>', '<344>', '<345>', '<346>', '<347>', '<348>', '<349>', '<350>', '<351>', '<352>', '<353>', '<354>', '<355>', '<356>', '<357>', '<358>', '<359>', '<360>', '<361>', '<362>', '<363>', '<364>', '<365>', '<366>', '<367>', '<368>', '<369>', '<370>', '<371>', '<372>', '<373>', '<374>', '<375>', '<376>', '<377>', '<378>', '<379>', '<380>', '<381>', '<382>', '<383>', '<384>', '<385>', '<386>', '<387>', '<388>', '<389>', '<390>', '<391>', '<392>', '<393>', '<394>', '<395>', '<396>', '<397>', '<398>', '<399>', '<400>', '<401>', '<402>', '<403>', '<404>', '<405>', '<406>', '<407>', '<408>', '<409>', '<410>', '<411>', '<412>', '<413>', '<414>', '<415>', '<416>', '<417>', '<418>', '<419>', '<420>', '<421>', '<422>', '<423>', '<424>', '<425>', '<426>', '<427>', '<428>', '<429>', '<430>', '<431>', '<432>', '<433>', '<434>', '<435>', '<436>', '<437>', '<438>', '<439>', '<440>', '<441>', '<442>', '<443>', '<444>', '<445>', '<446>', '<447>', '<448>', '<449>', '<450>', '<451>', '<452>', '<453>', '<454>', '<455>', '<456>', '<457>', '<458>', '<459>', '<460>', '<461>', '<462>', '<463>', '<464>', '<465>', '<466>', '<467>', '<468>', '<469>', '<470>', '<471>', '<472>', '<473>', '<474>', '<475>', '<476>', '<477>', '<478>', '<479>', '<480>', '<481>', '<482>', '<483>', '<484>', '<485>', '<486>', '<487>', '<488>', '<489>', '<490>', '<491>', '<492>', '<493>', '<494>', '<495>', '<496>', '<497>', '<498>', '<499>', '<500>', '<501>', '<502>', '<503>', '<504>', '<505>', '<506>', '<507>', '<508>', '<509>', '<510>', '<511>', '<512>', '<513>', '<514>', '<515>', '<516>', '<517>', '<518>', '<519>', '<520>', '<521>', '<522>', '<523>', '<524>', '<525>', '<526>', '<527>', '<528>', '<529>', '<530>', '<531>', '<532>', '<533>', '<534>', '<535>', '<536>', '<537>', '<538>', '<539>', '<540>', '<541>', '<542>', '<543>', '<544>', '<545>', '<546>', '<547>', '<548>', '<549>', '<550>', '<551>', '<552>', '<553>', '<554>', '<555>', '<556>', '<557>', '<558>', '<559>', '<560>', '<561>', '<562>', '<563>', '<564>', '<565>', '<566>', '<567>', '<568>', '<569>', '<570>', '<571>', '<572>', '<573>', '<574>', '<575>', '<576>', '<577>', '<578>', '<579>', '<580>', '<581>', '<582>', '<583>', '<584>', '<585>', '<586>', '<587>', '<588>', '<589>', '<590>', '<591>', '<592>', '<593>', '<594>', '<595>', '<596>', '<597>', '<598>', '<599>', '<600>', '<601>', '<602>', '<603>', '<604>', '<605>', '<606>', '<607>', '<608>', '<609>', '<610>', '<611>', '<612>', '<613>', '<614>', '<615>', '<616>', '<617>', '<618>', '<619>', '<620>', '<621>', '<622>', '<623>', '<624>', '<625>', '<626>', '<627>', '<628>', '<629>', '<630>', '<631>', '<632>', '<633>', '<634>', '<635>', '<636>', '<637>', '<638>', '<639>', '<640>', '<641>', '<642>', '<643>', '<644>', '<645>', '<646>', '<647>', '<648>', '<649>', '<650>', '<651>', '<652>', '<653>', '<654>', '<655>', '<656>', '<657>', '<658>', '<659>', '<660>', '<661>', '<662>', '<663>', '<664>', '<665>', '<666>', '<667>', '<668>', '<669>', '<670>', '<671>', '<672>', '<673>', '<674>', '<675>', '<676>', '<677>', '<678>', '<679>', '<680>', '<681>', '<682>', '<683>', '<684>', '<685>', '<686>', '<687>', '<688>', '<689>', '<690>', '<691>', '<692>', '<693>', '<694>', '<695>', '<696>', '<697>', '<698>', '<699>', '<700>', '<701>', '<702>', '<703>', '<704>', '<705>', '<706>', '<707>', '<708>', '<709>', '<710>', '<711>', '<712>', '<713>', '<714>', '<715>', '<716>', '<717>', '<718>', '<719>', '<720>', '<721>', '<722>', '<723>', '<724>', '<725>', '<726>', '<727>', '<728>', '<729>', '<730>', '<731>', '<732>', '<733>', '<734>', '<735>', '<736>', '<737>', '<738>', '<739>', '<740>', '<741>', '<742>', '<743>', '<744>', '<745>', '<746>', '<747>', '<748>', '<749>', '<750>', '<751>', '<752>', '<753>', '<754>', '<755>', '<756>', '<757>', '<758>', '<759>', '<760>', '<761>', '<762>', '<763>', '<764>', '<765>', '<766>', '<767>', '<768>', '<769>', '<770>', '<771>', '<772>', '<773>', '<774>', '<775>', '<776>', '<777>', '<778>', '<779>', '<780>', '<781>', '<782>', '<783>', '<784>', '<785>', '<786>', '<787>', '<788>', '<789>', '<790>', '<791>', '<792>', '<793>', '<794>', '<795>', '<796>', '<797>', '<798>', '<799>', '<800>', '<801>', '<802>', '<803>', '<804>', '<805>', '<806>', '<807>', '<808>', '<809>', '<810>', '<811>', '<812>', '<813>', '<814>', '<815>', '<816>', '<817>', '<818>', '<819>', '<820>', '<821>', '<822>', '<823>', '<824>', '<825>', '<826>', '<827>', '<828>', '<829>', '<830>', '<831>', '<832>', '<833>', '<834>', '<835>', '<836>', '<837>', '<838>', '<839>', '<840>', '<841>', '<842>', '<843>', '<844>', '<845>', '<846>', '<847>', '<848>', '<849>', '<850>', '<851>', '<852>', '<853>', '<854>', '<855>', '<856>', '<857>', '<858>', '<859>', '<860>', '<861>', '<862>', '<863>', '<864>', '<865>', '<866>', '<867>', '<868>', '<869>', '<870>', '<871>', '<872>', '<873>', '<874>', '<875>', '<876>', '<877>', '<878>', '<879>', '<880>', '<881>', '<882>', '<883>', '<884>', '<885>', '<886>', '<887>', '<888>', '<889>', '<890>', '<891>', '<892>', '<893>', '<894>', '<895>', '<896>', '<897>', '<898>', '<899>', '<900>', '<901>', '<902>', '<903>', '<904>', '<905>', '<906>', '<907>', '<908>', '<909>', '<910>', '<911>', '<912>', '<913>', '<914>', '<915>', '<916>', '<917>', '<918>', '<919>', '<920>', '<921>', '<922>', '<923>', '<924>', '<925>', '<926>', '<927>', '<928>', '<929>', '<930>', '<931>', '<932>', '<933>', '<934>', '<935>', '<936>', '<937>', '<938>', '<939>', '<940>', '<941>', '<942>', '<943>', '<944>', '<945>', '<946>', '<947>', '<948>', '<949>', '<950>', '<951>', '<952>', '<953>', '<954>', '<955>', '<956>', '<957>', '<958>', '<959>', '<960>', '<961>', '<962>', '<963>', '<964>', '<965>', '<966>', '<967>', '<968>', '<969>', '<970>', '<971>', '<972>', '<973>', '<974>', '<975>', '<976>', '<977>', '<978>', '<979>', '<980>', '<981>', '<982>', '<983>', '<984>', '<985>', '<986>', '<987>', '<988>', '<989>', '<990>', '<991>', '<992>', '<993>', '<994>', '<995>', '<996>', '<997>', '<998>', '<999>', '<1000>', '<1001>', '<1002>', '<1003>', '<1004>', '<1005>', '<1006>', '<1007>', '<1008>', '<1009>', '<1010>', '<1011>', '<1012>', '<1013>', '<1014>', '<1015>', '<1016>', '<1017>', '<1018>', '<1019>', '<1020>', '<1021>', '<1022>', '<1023>', '<IN>', '<OUT>', '<END>', '<r-25.0>', '<r-24.9>', '<r-24.8>', '<r-24.7>', '<r-24.6>', '<r-24.5>', '<r-24.4>', '<r-24.3>', '<r-24.2>', '<r-24.1>', '<r-24.0>', '<r-23.9>', '<r-23.8>', '<r-23.7>', '<r-23.6>', '<r-23.5>', '<r-23.4>', '<r-23.3>', '<r-23.2>', '<r-23.1>', '<r-23.0>', '<r-22.9>', '<r-22.8>', '<r-22.7>', '<r-22.6>', '<r-22.5>', '<r-22.4>', '<r-22.3>', '<r-22.2>', '<r-22.1>', '<r-22.0>', '<r-21.9>', '<r-21.8>', '<r-21.7>', '<r-21.6>', '<r-21.5>', '<r-21.4>', '<r-21.3>', '<r-21.2>', '<r-21.1>', '<r-21.0>', '<r-20.9>', '<r-20.8>', '<r-20.7>', '<r-20.6>', '<r-20.5>', '<r-20.4>', '<r-20.3>', '<r-20.2>', '<r-20.1>', '<r-20.0>', '<r-19.9>', '<r-19.8>', '<r-19.7>', '<r-19.6>', '<r-19.5>', '<r-19.4>', '<r-19.3>', '<r-19.2>', '<r-19.1>', '<r-19.0>', '<r-18.9>', '<r-18.8>', '<r-18.7>', '<r-18.6>', '<r-18.5>', '<r-18.4>', '<r-18.3>', '<r-18.2>', '<r-18.1>', '<r-18.0>', '<r-17.9>', '<r-17.8>', '<r-17.7>', '<r-17.6>', '<r-17.5>', '<r-17.4>', '<r-17.3>', '<r-17.2>', '<r-17.1>', '<r-17.0>', '<r-16.9>', '<r-16.8>', '<r-16.7>', '<r-16.6>', '<r-16.5>', '<r-16.4>', '<r-16.3>', '<r-16.2>', '<r-16.1>', '<r-16.0>', '<r-15.9>', '<r-15.8>', '<r-15.7>', '<r-15.6>', '<r-15.5>', '<r-15.4>', '<r-15.3>', '<r-15.2>', '<r-15.1>', '<r-15.0>', '<r-14.9>', '<r-14.8>', '<r-14.7>', '<r-14.6>', '<r-14.5>', '<r-14.4>', '<r-14.3>', '<r-14.2>', '<r-14.1>', '<r-14.0>', '<r-13.9>', '<r-13.8>', '<r-13.7>', '<r-13.6>', '<r-13.5>', '<r-13.4>', '<r-13.3>', '<r-13.2>', '<r-13.1>', '<r-13.0>', '<r-12.9>', '<r-12.8>', '<r-12.7>', '<r-12.6>', '<r-12.5>', '<r-12.4>', '<r-12.3>', '<r-12.2>', '<r-12.1>', '<r-12.0>', '<r-11.9>', '<r-11.8>', '<r-11.7>', '<r-11.6>', '<r-11.5>', '<r-11.4>', '<r-11.3>', '<r-11.2>', '<r-11.1>', '<r-11.0>', '<r-10.9>', '<r-10.8>', '<r-10.7>', '<r-10.6>', '<r-10.5>', '<r-10.4>', '<r-10.3>', '<r-10.2>', '<r-10.1>', '<r-10.0>', '<r-9.9>', '<r-9.8>', '<r-9.7>', '<r-9.6>', '<r-9.5>', '<r-9.4>', '<r-9.3>', '<r-9.2>', '<r-9.1>', '<r-9.0>', '<r-8.9>', '<r-8.8>', '<r-8.7>', '<r-8.6>', '<r-8.5>', '<r-8.4>', '<r-8.3>', '<r-8.2>', '<r-8.1>', '<r-8.0>', '<r-7.9>', '<r-7.8>', '<r-7.7>', '<r-7.6>', '<r-7.5>', '<r-7.4>', '<r-7.3>', '<r-7.2>', '<r-7.1>', '<r-7.0>', '<r-6.9>', '<r-6.8>', '<r-6.7>', '<r-6.6>', '<r-6.5>', '<r-6.4>', '<r-6.3>', '<r-6.2>', '<r-6.1>', '<r-6.0>', '<r-5.9>', '<r-5.8>', '<r-5.7>', '<r-5.6>', '<r-5.5>', '<r-5.4>', '<r-5.3>', '<r-5.2>', '<r-5.1>', '<r-5.0>', '<r-4.9>', '<r-4.8>', '<r-4.7>', '<r-4.6>', '<r-4.5>', '<r-4.4>', '<r-4.3>', '<r-4.2>', '<r-4.1>', '<r-4.0>', '<r-3.9>', '<r-3.8>', '<r-3.7>', '<r-3.6>', '<r-3.5>', '<r-3.4>', '<r-3.3>', '<r-3.2>', '<r-3.1>', '<r-3.0>', '<r-2.9>', '<r-2.8>', '<r-2.7>', '<r-2.6>', '<r-2.5>', '<r-2.4>', '<r-2.3>', '<r-2.2>', '<r-2.1>', '<r-2.0>', '<r-1.9>', '<r-1.8>', '<r-1.7>', '<r-1.6>', '<r-1.5>', '<r-1.4>', '<r-1.3>', '<r-1.2>', '<r-1.1>', '<r-1.0>', '<r-0.9>', '<r-0.8>', '<r-0.7>', '<r-0.6>', '<r-0.5>', '<r-0.4>', '<r-0.3>', '<r-0.2>', '<r-0.1>', '<r0.0>', '<r0.1>', '<r0.2>', '<r0.3>', '<r0.4>', '<r0.5>', '<r0.6>', '<r0.7>', '<r0.8>', '<r0.9>', '<r1.0>', '<r1.1>', '<r1.2>', '<r1.3>', '<r1.4>', '<r1.5>', '<r1.6>', '<r1.7>', '<r1.8>', '<r1.9>', '<r2.0>', '<r2.1>', '<r2.2>', '<r2.3>', '<r2.4>', '<r2.5>', '<r2.6>', '<r2.7>', '<r2.8>', '<r2.9>', '<r3.0>', '<r3.1>', '<r3.2>', '<r3.3>', '<r3.4>', '<r3.5>', '<r3.6>', '<r3.7>', '<r3.8>', '<r3.9>', '<r4.0>', '<r4.1>', '<r4.2>', '<r4.3>', '<r4.4>', '<r4.5>', '<r4.6>', '<r4.7>', '<r4.8>', '<r4.9>', '<r5.0>', '<r5.1>', '<r5.2>', '<r5.3>', '<r5.4>', '<r5.5>', '<r5.6>', '<r5.7>', '<r5.8>', '<r5.9>', '<r6.0>', '<r6.1>', '<r6.2>', '<r6.3>', '<r6.4>', '<r6.5>', '<r6.6>', '<r6.7>', '<r6.8>', '<r6.9>', '<r7.0>', '<r7.1>', '<r7.2>', '<r7.3>', '<r7.4>', '<r7.5>', '<r7.6>', '<r7.7>', '<r7.8>', '<r7.9>', '<r8.0>', '<r8.1>', '<r8.2>', '<r8.3>', '<r8.4>', '<r8.5>', '<r8.6>', '<r8.7>', '<r8.8>', '<r8.9>', '<r9.0>', '<r9.1>', '<r9.2>', '<r9.3>', '<r9.4>', '<r9.5>', '<r9.6>', '<r9.7>', '<r9.8>', '<r9.9>', '<r10.0>', '<r10.1>', '<r10.2>', '<r10.3>', '<r10.4>', '<r10.5>', '<r10.6>', '<r10.7>', '<r10.8>', '<r10.9>', '<r11.0>', '<r11.1>', '<r11.2>', '<r11.3>', '<r11.4>', '<r11.5>', '<r11.6>', '<r11.7>', '<r11.8>', '<r11.9>', '<r12.0>', '<r12.1>', '<r12.2>', '<r12.3>', '<r12.4>', '<r12.5>', '<r12.6>', '<r12.7>', '<r12.8>', '<r12.9>', '<r13.0>', '<r13.1>', '<r13.2>', '<r13.3>', '<r13.4>', '<r13.5>', '<r13.6>', '<r13.7>', '<r13.8>', '<r13.9>', '<r14.0>', '<r14.1>', '<r14.2>', '<r14.3>', '<r14.4>', '<r14.5>', '<r14.6>', '<r14.7>', '<r14.8>', '<r14.9>', '<r15.0>', '<r15.1>', '<r15.2>', '<r15.3>', '<r15.4>', '<r15.5>', '<r15.6>', '<r15.7>', '<r15.8>', '<r15.9>', '<r16.0>', '<r16.1>', '<r16.2>', '<r16.3>', '<r16.4>', '<r16.5>', '<r16.6>', '<r16.7>', '<r16.8>', '<r16.9>', '<r17.0>', '<r17.1>', '<r17.2>', '<r17.3>', '<r17.4>', '<r17.5>', '<r17.6>', '<r17.7>', '<r17.8>', '<r17.9>', '<r18.0>', '<r18.1>', '<r18.2>', '<r18.3>', '<r18.4>', '<r18.5>', '<r18.6>', '<r18.7>', '<r18.8>', '<r18.9>', '<r19.0>', '<r19.1>', '<r19.2>', '<r19.3>', '<r19.4>', '<r19.5>', '<r19.6>', '<r19.7>', '<r19.8>', '<r19.9>', '<r20.0>', '<r20.1>', '<r20.2>', '<r20.3>', '<r20.4>', '<r20.5>', '<r20.6>', '<r20.7>', '<r20.8>', '<r20.9>', '<r21.0>', '<r21.1>', '<r21.2>', '<r21.3>', '<r21.4>', '<r21.5>', '<r21.6>', '<r21.7>', '<r21.8>', '<r21.9>', '<r22.0>', '<r22.1>', '<r22.2>', '<r22.3>', '<r22.4>', '<r22.5>', '<r22.6>', '<r22.7>', '<r22.8>', '<r22.9>', '<r23.0>', '<r23.1>', '<r23.2>', '<r23.3>', '<r23.4>', '<r23.5>', '<r23.6>', '<r23.7>', '<r23.8>', '<r23.9>', '<r24.0>', '<r24.1>', '<r24.2>', '<r24.3>', '<r24.4>', '<r24.5>', '<r24.6>', '<r24.7>', '<r24.8>', '<r24.9>']\n"
     ]
    }
   ],
   "source": [
    "#Учим эту модель. У Nehc есть пример, как это делать\n",
    "#Модификация токенайзера \n",
    "#добавляем несколько токенов нашей разметки\n",
    "\n",
    "#сюда надо фигануть весь словарь картинок\n",
    "video_tokens_cnt = 1024\n",
    "video_tokens = []\n",
    "for i in range(video_tokens_cnt):\n",
    "    video_tokens.append(f'<{i}>')\n",
    "    \n",
    "special_tokens_dict = {'additional_special_tokens': video_tokens + ['<IN>','<OUT>','<END>','|PAD|'] + list(reward2substr.values())}\n",
    "num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "print(tokenizer.all_special_tokens)\n",
    "tokenizer.pad_token = '|PAD|'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<r-25.0> <r24.9>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(51282, 51283, 51284, 50381, 51685, 51784)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#специальные токены { vertical-output: true }\n",
    "T_OUT = tokenizer.encode('<OUT>')[0]\n",
    "T_END = tokenizer.encode('<END>')[0]\n",
    "T_PAD = tokenizer.encode('|PAD|')[0]\n",
    "T_124 = tokenizer.encode('<124>')[0]\n",
    "#reward-токен:\n",
    "rmin = list(reward2substr.values())[0]\n",
    "rmax = list(reward2substr.values())[-1]\n",
    "T_RMIN = tokenizer.encode(rmin)[0]\n",
    "T_RMAX = tokenizer.encode(rmax)[0]\n",
    "print(rmin, rmax)\n",
    "T_OUT, T_END, T_PAD, T_124, T_RMIN, T_RMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n",
      "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips\\vgg.pth\n",
      "VQLPIPSWithDiscriminator running with hinge loss.\n"
     ]
    }
   ],
   "source": [
    "#VQ-GAN 1024 \n",
    "Model = \"f16_1024\" #param [\"f16_1024\", \"f16_16384\", \"f16_16384_hf\"]\n",
    "import cv2\n",
    "import torch\n",
    "import yaml\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from omegaconf import OmegaConf\n",
    "from taming.models.vqgan import VQModel\n",
    "\n",
    "def load_config(config_path, display=False):\n",
    "  config = OmegaConf.load(config_path)\n",
    "  if display:\n",
    "    print(yaml.dump(OmegaConf.to_container(config)))\n",
    "  return config\n",
    "\n",
    "def load_vqgan(config, ckpt_path=None):\n",
    "  model = VQModel(**config.model.params)\n",
    "  if ckpt_path is not None:\n",
    "    sd = torch.load(ckpt_path, map_location=\"cpu\")[\"state_dict\"]\n",
    "    missing, unexpected = model.load_state_dict(sd, strict=False)\n",
    "  return model.eval()\n",
    "\n",
    "def preprocess_vqgan(x, roll=True):\n",
    "  x = 2.*x - 1.\n",
    "  if roll:\n",
    "    x = np.rollaxis(x,3,1)\n",
    "  x = torch.Tensor(x)\n",
    "  return x\n",
    "\n",
    "def preprocess(x, permt=True):\n",
    "  if permt:\n",
    "    x = x.permute(0,2,3,1).numpy()\n",
    "  x = np.clip(x, -1., 1.)\n",
    "  x = (x + 1.)/2.\n",
    "  return x\n",
    "\n",
    "def custom_to_pil(x):\n",
    "  x = np.clip(x, -1., 1.)\n",
    "  x = (x + 1.)/2.\n",
    "  x = (255*x).astype(np.uint8)\n",
    "  x = Image.fromarray(x)\n",
    "  if not x.mode == \"RGB\":\n",
    "    x = x.convert(\"RGB\")\n",
    "  return x\n",
    "\n",
    "vq_conf = load_config(f\"../gpt/chatgpt/chk_points/vqgan_imagenet_{Model}.yaml\", display=False)\n",
    "vq_model = load_vqgan(vq_conf, ckpt_path=f\"../gpt/chatgpt/chk_points/vqgan_imagenet_{Model}.ckpt\").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "imsize = [16*9, 16*9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fire': 2,\n",
       " 'strafe left': 0,\n",
       " 'turn left': 5,\n",
       " 'strafe right': 1,\n",
       " 'turn right': 6,\n",
       " 'move ahead': 3,\n",
       " 'use': 7,\n",
       " 'move back': 4}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_to_action_desc = {2:'fire', 0:'strafe left', 5:'turn left', 1:'strafe right', 6:'turn right', 3:'move ahead', 7:'use', 4:'move back'}\n",
    "action_to_num_desc = {num_to_action_desc[k] : k for k in num_to_action_desc}\n",
    "action_to_num_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer(text, max_tokens=5, random=False):\n",
    "    context_max_size = 256\n",
    "    #text = '\\n' + text\n",
    "    inpt = tokenizer.encode(text, return_tensors=\"pt\")\n",
    "    inpt = tokenizer.encode(text, return_tensors=\"pt\")\n",
    "\n",
    "    inpt = inpt[-context_max_size:]\n",
    "    inpt = inpt.to(device)\n",
    "\n",
    "    gener_len = max_tokens\n",
    "    tokens_use = 5\n",
    "    #out = model.generate(inpt,  max_length=len(inpt[0])+300, do_sample=True, top_k=5, top_p=0.95, temperature=1, eos_token_id=T_END, pad_token_id=T_PAD)\n",
    "    temperature = 0.01\n",
    "    temperature = 0.9\n",
    "    if random and not (np.random.rand()<0.1):\n",
    "        random = False\n",
    "\n",
    "    if random:\n",
    "        out = model.generate(inpt,  max_length=len(inpt[0])+gener_len, do_sample=True, top_k=1, top_p=0.95, temperature=0.1, eos_token_id=T_END, pad_token_id=T_PAD)\n",
    "    else:\n",
    "        out = model.generate(inpt,  max_length=len(inpt[0])+gener_len, do_sample=False, top_k=1, top_p=0.95, temperature=0.01, eos_token_id=T_END, pad_token_id=T_PAD)\n",
    "        \n",
    "    out_tokens = torch.where(out[0]==T_OUT)\n",
    "    #last_repl = out[0][out_tokens[0][-1]+1:-1]\n",
    "    #print(out)\n",
    "    out_tokens = out_tokens[-tokens_use:][:max_tokens]\n",
    "    last_repl = out[0][out_tokens[0][-1]+1:-1]\n",
    "    repl = tokenizer.decode(last_repl)\n",
    "\n",
    "    return repl\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 205
    },
    "executionInfo": {
     "elapsed": 300770,
     "status": "ok",
     "timestamp": 1602319324307,
     "user": {
      "displayName": "Сергей Довгань",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3MZ2GUNo7qvuOUXjppWtslpJefb5Bk2H8pvQgsg=s64",
      "userId": "11204475592062912374"
     },
     "user_tz": -180
    },
    "id": "rYwEk2lipCWy",
    "outputId": "432ce7f1-044c-4051-bfae-9b0a33f23d1b"
   },
   "outputs": [],
   "source": [
    "#!sudo apt-get install build-essential zlib1g-dev libsdl2-dev libjpeg-dev \\\n",
    "#nasm tar libbz2-dev libgtk2.0-dev cmake git libfluidsynth-dev libgme-dev \\\n",
    "#libopenal-dev timidity libwildmidi-dev unzip\n",
    "#!sudo apt-get install libboost-all-dev\n",
    "#!pip install vizdoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 1645,
     "status": "aborted",
     "timestamp": 1602318324666,
     "user": {
      "displayName": "Сергей Довгань",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3MZ2GUNo7qvuOUXjppWtslpJefb5Bk2H8pvQgsg=s64",
      "userId": "11204475592062912374"
     },
     "user_tz": -180
    },
    "id": "6RbjeiDPLohs"
   },
   "outputs": [],
   "source": [
    "#как сделать запись в файл? Перегони в картинку, её перегони в верный формат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 1639,
     "status": "aborted",
     "timestamp": 1602318324668,
     "user": {
      "displayName": "Сергей Довгань",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3MZ2GUNo7qvuOUXjppWtslpJefb5Bk2H8pvQgsg=s64",
      "userId": "11204475592062912374"
     },
     "user_tz": -180
    },
    "id": "kvcT0WIHLoh3"
   },
   "outputs": [],
   "source": [
    "#(224, 224, 3) - размеры resnet101, resnet 101v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 674,
     "status": "ok",
     "timestamp": 1602319600340,
     "user": {
      "displayName": "Сергей Довгань",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3MZ2GUNo7qvuOUXjppWtslpJefb5Bk2H8pvQgsg=s64",
      "userId": "11204475592062912374"
     },
     "user_tz": -180
    },
    "id": "Q4RqCrHQLoiO"
   },
   "outputs": [],
   "source": [
    "# Creates and initializes ViZDoom environment.\n",
    "def initialize_vizdoom(config_file_path,doom_map=\"map01\"):\n",
    "    print(\"Initializing doom...\")\n",
    "    game = DoomGame()\n",
    "    game.load_config(config_file_path)\n",
    "    game.set_doom_map(doom_map)\n",
    "    game.set_screen_format(ScreenFormat.RGB24)\n",
    "    game.set_screen_resolution(ScreenResolution.RES_200X150)\n",
    "    game.set_depth_buffer_enabled(True)\n",
    "    # Enables depth buffer.\n",
    "    # Enables labeling of in game objects labeling.\n",
    "    game.set_labels_buffer_enabled(True)\n",
    "    # Enables buffer with top down map of the current episode/level.\n",
    "    game.set_automap_buffer_enabled(True)\n",
    "    game.set_depth_buffer_enabled(True)\n",
    "    # Enables information about all objects present in the current episode/level.\n",
    "    #game.set_objects_info_enabled(True)\n",
    "    # Enables information about all sectors (map layout).\n",
    "    #game.set_sectors_info_enabled(True)\n",
    "    # Sets other rendering options (all of these options except crosshair are enabled (set to True) by default)\n",
    "    game.set_render_hud(True)\n",
    "    #game.set_render_hud(False)\n",
    "    #game.set_render_minimal_hud(False)  # If hud is enabled\n",
    "    #game.set_render_minimal_hud(True)  # If hud is enabled\n",
    "    game.set_render_crosshair(False)\n",
    "    game.set_render_weapon(True)\n",
    "    #game.set_render_weapon(False)\n",
    "    \n",
    "    game.set_render_decals(False)  # Bullet holes and blood on the walls\n",
    "    game.set_render_particles(False)\n",
    "    game.set_render_effects_sprites(True)  # Smoke and blood\n",
    "    game.set_render_messages(False)  # In-game messages\n",
    "    game.set_render_corpses(True)\n",
    "    game.set_render_screen_flashes(True)  # Effect upon taking damage or picking up items\n",
    "    #game.set_objects_info_enabled(True)\n",
    "    # Adds buttons that will be allowed.\n",
    "    lst_acts = [Button.ATTACK,Button.USE,Button.MOVE_LEFT,Button.MOVE_RIGHT,Button.MOVE_FORWARD,Button.MOVE_BACKWARD,Button.TURN_LEFT,Button.TURN_RIGHT]#,Button.SELECT_NEXT_WEAPON]\n",
    "    for action in lst_acts:\n",
    "        game.add_available_button(action)\n",
    "    # Adds game variables that will be included in state.\n",
    "    game.add_available_game_variable(GameVariable.SELECTED_WEAPON)\n",
    "    game.add_available_game_variable(GameVariable.AMMO2)\n",
    "    game.add_available_game_variable(GameVariable.HEALTH)\n",
    "    game.add_available_game_variable(GameVariable.FRAGCOUNT)\n",
    "    game.add_available_game_variable(GameVariable.KILLCOUNT)\n",
    "    game.add_available_game_variable(GameVariable.ITEMCOUNT)\n",
    "    game.add_available_game_variable(GameVariable.HITCOUNT)\n",
    "    # Causes episodes to finish after 200 tics (actions)\n",
    "    game.set_episode_timeout(episode_len)\n",
    "    # Makes episodes start after 10 tics (~after raising the weapon)\n",
    "    game.set_episode_start_time(10)\n",
    "    # Makes the window appear (turned on by default)\n",
    "    game.set_window_visible(True)\n",
    "    # Turns on the sound. (turned off by default)\n",
    "    game.set_sound_enabled(False)\n",
    "    # Sets the living reward (for each move) to -1\n",
    "    game.set_living_reward(1)\n",
    "    # Sets ViZDoom mode (PLAYER, ASYNC_PLAYER, SPECTATOR, ASYNC_SPECTATOR, PLAYER mode is default)\n",
    "    #game.set_mode(Mode.PLAYER)\n",
    "    game.set_mode(Mode.PLAYER)\n",
    "    # Enables engine output to console.\n",
    "    #game.set_console_enabled(True)\n",
    "    # Initialize the game. Further configuration won't take any effect from now on.\n",
    "    time.sleep(1)\n",
    "    game.init()\n",
    "    print(\"Doom initialized.\")\n",
    "    return game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 711,
     "status": "ok",
     "timestamp": 1602319602312,
     "user": {
      "displayName": "Сергей Довгань",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3MZ2GUNo7qvuOUXjppWtslpJefb5Bk2H8pvQgsg=s64",
      "userId": "11204475592062912374"
     },
     "user_tz": -180
    },
    "id": "1YLJp4MJLoie"
   },
   "outputs": [],
   "source": [
    "black_square = np.zeros((224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397
    },
    "executionInfo": {
     "elapsed": 2872,
     "status": "error",
     "timestamp": 1602319652606,
     "user": {
      "displayName": "Сергей Довгань",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3MZ2GUNo7qvuOUXjppWtslpJefb5Bk2H8pvQgsg=s64",
      "userId": "11204475592062912374"
     },
     "user_tz": -180
    },
    "id": "7vwiA2PMLojM",
    "outputId": "f78ed97b-ab9b-4a55-aae3-aa6450f7b9ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____ 2023-10-03 20:23:40.642587\n",
      "Initializing doom...\n",
      "Doom initialized.\n"
     ]
    }
   ],
   "source": [
    "doom=1\n",
    "\n",
    "print('_____',pd.Timestamp.now())\n",
    "\n",
    "env = initialize_vizdoom(root + 'doom_files/scenarios/doom2.cfg',doom_map=\"e1m1\")\n",
    "#env = initialize_vizdoom(root + 'doom_files/scenarios/basic.cfg',doom_map=\"map06\")\n",
    "#[Button.ATTACK,Button.USE,Button.MOVE_LEFT,Button.MOVE_RIGHT,Button.MOVE_FORWARD,Button.MOVE_BACKWARD,Button.TURN_LEFT,Button.TURN_RIGHT]\n",
    "actions = [[1,0,0,0,0,0,0,0], [0,1,0,0,0,0,0,0], [0,0,1,0,0,0,0,0], [0,0,0,1,0,0,0,0], [0,0,0,0,1,0,0,0], [0,0,0,0,0,1,0,0], [0,0,0,0,0,0,1,0],[0,0,0,0,0,0,0,1]]\n",
    "\n",
    "\n",
    "state_size = (env.get_screen_height(),env.get_screen_width(),3)\n",
    "\n",
    "action_size = len(actions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.shape(state) # (150, 200, 3)world model mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features(state, verbose=False,extended=False):\n",
    "    if state is None:\n",
    "        return np.zeros([1,15])\n",
    "    shape = np.shape(state.labels_buffer)\n",
    "    shape = [shape[1],shape[0]]\n",
    "    enemy_types = ['PainElemental','FloatingSkull','Mastermind','MasterMind','Cyberdemon','CyberDemon','BaronOfHell','HellKnight','LostSoul','Archvile','Revenant','Arachnotron','Cacodemon','Fatso','ChaingunGuy','ShotgunGuy','DoomImp','DoomPinky','Zombieman','Spectre','Demon']\n",
    "    item_types = ['BFGExtra','RedSkull','BlueSkull','YellowSkull','Allmap','RadSuit','Chainsaw','InvulnerabilitySphere','BFG9000','RocketBox','ClipBox','YellowCard','RedCard','CellPack','Cell','Backpack','ShellBox','RocketLauncher','RocketAmmo','PlasmaRifle','Megasphere','Chaingun','BlurSphere','Berserk','HealthBonus','Stimpack','Medikit','Shotgun','Chaingun','ArmorBonus','BlueCard','Clip','BlueArmor','GreenArmor','Shell','Soulsphere','SuperShotgun']\n",
    "    weapon_types = ['Chainsaw','BFG9000','RocketLauncher','PlasmaRifle','Chaingun','Shotgun','Chaingun','BlueArmor','InvulnerabilitySphere','Soulsphere','SuperShotgun']\n",
    "    projectile_types = ['ArchvileFire','RevenantTracer','ArachnotronPlasma','DoomImpBall','FatShot','CacodemonBall','BaronBall']\n",
    "    #проверить наличие объектов обоих типов \n",
    "    d = {'enemy_fwd':0,'enemy_lft':0,'enemy_rgt':0,'enemy_vlft':0,'enemy_vrgt':0,\n",
    "        'item_fwd':0,'item_lft':0,'item_rgt':0,'item_vlft':0,'item_vrgt':0,\n",
    "        'projectile_fwd':0,'projectile_lft':0,'projectile_rgt':0,'projectile_vlft':0,'projectile_vrgt':0,\n",
    "        'weapon_fwd':0,'weapon_lft':0,'weapon_rgt':0,'weapon_vlft':0,'weapon_vrgt':0\n",
    "        }\n",
    "    obj_list = []\n",
    "    obj_matrix = np.zeros([shape[1],shape[0],6])\n",
    "    obj_matrix[:,:,-1] = state.depth_buffer\n",
    "    description = ''\n",
    "    description_enemies = ''\n",
    "    description_items = ''\n",
    "    description_projectiles = ''\n",
    "    description_corpses = ''\n",
    "    for obj in state_raw.labels:\n",
    "        x = int(obj.x)\n",
    "        y = int(obj.y)\n",
    "        w = int(obj.width)\n",
    "        h = int(obj.height)\n",
    "        if np.abs(obj.x-shape[0]*0.5)<6:\n",
    "            where = 'ahead'\n",
    "        elif ((obj.x-shape[0]*0.5)>=6) and ((obj.x-shape[0]*0.5)<40):\n",
    "            where = 'right-ahead'\n",
    "        elif (obj.x-shape[0]*0.5)>=40:\n",
    "            where = 'at right'\n",
    "        elif ((obj.x-shape[0]*0.5)<=-6) and ((obj.x-shape[0]*0.5)>-40):\n",
    "            where = 'left-ahead'\n",
    "        elif (obj.x-shape[0]*0.5)<=-40:\n",
    "            where = 'at left'\n",
    "            \n",
    "        obj_alias = obj.object_name\n",
    "        obj_alias = obj_alias.replace('Zombieman', 'rifleman zombie').replace('ShotgunGuy', 'shotgun zombie')\n",
    "        obj_alias = obj_alias.replace('SuperShotgun', 'double-barrel').replace('DoomImp', 'imp').replace('Fatso','mancubus')\n",
    "        obj_alias = obj_alias.replace('FloatingSkull', 'lostsoul').replace('DoomPinky', 'pinky').replace('impBall','fireball')\n",
    "        obj_alias = obj_alias.replace('RevenantTracer', 'rocket').replace('DoomImpBall', 'fireball').replace('CacodemonBall','fireball')\n",
    "        obj_alias = obj_alias.replace('BaronBall', 'green projectile').replace('BaronOfHell', 'hell baron').replace('YellowCard','yellow key')\n",
    "        obj_alias = obj_alias.replace('YellowCard','yellow key').replace('BlueCard','blue key').replace('RedCard','red key').replace('FatShot','fireball').replace('ArachnotronPlasma','green plasma').replace('PlasmaRifle','plasmagun')\n",
    "        obj_alias = obj_alias.replace('Dead','dead ')\n",
    "        \n",
    "        if obj.object_name in enemy_types:\n",
    "            obj_type = 'enemy'\n",
    "            obj_type_num = 0\n",
    "            description_enemies += f'{obj_alias} {where},'\n",
    "        elif obj.object_name in weapon_types:\n",
    "            obj_type = 'weapon'\n",
    "            obj_type_num = 5\n",
    "            description_items += f'{obj_alias} {where},'\n",
    "        elif obj.object_name in item_types:\n",
    "            obj_type = 'item'\n",
    "            obj_type_num = 1\n",
    "            description_items += f'{obj_alias} {where},'\n",
    "        elif obj.object_name in projectile_types:\n",
    "            obj_type = 'projectile'\n",
    "            obj_type_num = 2\n",
    "            description_projectiles += f'{obj_alias} {where},'\n",
    "        elif 'Dead' in obj.object_name:\n",
    "            obj_type = 'corpse'\n",
    "            obj_type_num = 3\n",
    "            description_corpses += f'{obj_alias} {where},'\n",
    "        else:\n",
    "            if obj.object_name!='DoomPlayer':\n",
    "                obj_type = ''\n",
    "                obj_type_num = 4\n",
    "            else:\n",
    "                continue\n",
    "        \n",
    "        wp_name = GameVariable.SELECTED_WEAPON.value\n",
    "        if wp_name==15:\n",
    "            wp_name='pistol'\n",
    "        elif wp_name==16:\n",
    "            wp_name='shotgun'\n",
    "        elif wp_name==17:\n",
    "            wp_name='double-barrel'\n",
    "        elif wp_name==14:\n",
    "            wp_name='nothing'\n",
    "        elif wp_name==18:\n",
    "            wp_name='chaingun'\n",
    "        \n",
    "        \n",
    "        #f'{wp_name} in hands,' +\n",
    "        description = description_enemies + description_projectiles + description_items + description_corpses\n",
    "        description = description[:-1]\n",
    "        \n",
    "        \n",
    "        rec = {'obj_type':obj_type,'obj_name':obj.object_name,'x':obj.x,'y':obj.y}\n",
    "        obj_list.append(rec)\n",
    "        obj_matrix[y:y+h,x:x+w,obj_type_num] = 1\n",
    "        if obj_type!='':\n",
    "            if np.abs(obj.x-shape[0]*0.5)<6:\n",
    "                d[obj_type+'_fwd']=1\n",
    "            elif ((obj.x-shape[0]*0.5)>=6) and ((obj.x-shape[0]*0.5)<40):\n",
    "                d[obj_type+'_rgt']=1\n",
    "            elif (obj.x-shape[0]*0.5)>=40:\n",
    "                d[obj_type+'_vrgt']=1\n",
    "            elif ((obj.x-shape[0]*0.5)<=-6) and ((obj.x-shape[0]*0.5)>-40):\n",
    "                d[obj_type+'_lft']=1\n",
    "            elif (obj.x-shape[0]*0.5)<=-40:\n",
    "                d[obj_type+'_vlft']=1            \n",
    "    #if np.random.rand()<0.1:\n",
    "    #    print(description)\n",
    "    if verbose:\n",
    "        print(d)\n",
    "    if extended:\n",
    "        return np.array(list(d.values()),ndmin=2), obj_list, obj_matrix, description\n",
    "    else:\n",
    "        return np.array(list(d.values()),ndmin=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTION_PERIOD = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResultGPT:\n",
    "    def __init__(self, mode='one_frame_mode'):\n",
    "        self.max_summary_write = 30\n",
    "        self.max_summary_show_simbols = 900#900*2\n",
    "        self.plan_max_tokens = 9\n",
    "        self.task = 'kill all'\n",
    "        self.prev_summary = ''\n",
    "        #если да, то мы генерим description на базе summary и картинки (под это надо специально учить нейронку)\n",
    "        self.use_complex_summary = False\n",
    "        #если да, то мы генерим план на базе summary и картинки (под это надо специально учить нейронку)\n",
    "        self.plan_complex_summary = False#False\n",
    "        #если да, то просим summary, иначе description\n",
    "        self.ask_summary = False\n",
    "        \n",
    "        #добавить дескрипшн после токенов картинки\n",
    "        self.descriptions_to_history = True#в логах\n",
    "        self.descriptions_to_actions = True#False#в фактических действиях\n",
    "        #\n",
    "        self.critical_trials = 1\n",
    "        self.plan_max_check_tokens = 40\n",
    "        \n",
    "        #стоит ли искать точный аналог в базе примеров\n",
    "        self.report_fullstring_search = True\n",
    "        \n",
    "        self.actions_from_keyboard = False\n",
    "        \n",
    "        \n",
    "        #mode = 'one_frame_mode'# 'hand_mode' 'simple_test_mode' 'full_test_mode' 'one_frame_mode'\n",
    "        \n",
    "        self.deterministic_memory = False\n",
    "        self.deterministic_plan = False#True\n",
    "        \n",
    "        if mode == 'hand_mode':\n",
    "            #Принимаем решения вручную\n",
    "            self.ask_summary = False\n",
    "            self.use_complex_summary = False\n",
    "            self.plan_complex_summary = False\n",
    "            self.actions_from_keyboard = True\n",
    "            self.critical_trials = 1\n",
    "        if mode == 'simple_test_mode':\n",
    "            #Принимаем решения с учетом памяти, но генерим память через description\n",
    "            self.ask_summary = False\n",
    "            self.use_complex_summary = False\n",
    "            self.plan_complex_summary = True\n",
    "            self.actions_from_keyboard = False\n",
    "        if mode == 'full_test_mode':\n",
    "            #Принимаем решения с учетом памяти, генерим память правильным образом\n",
    "            self.ask_summary = True\n",
    "            self.use_complex_summary = True\n",
    "            self.plan_complex_summary = True\n",
    "            self.actions_from_keyboard = False\n",
    "        if mode == 'one_frame_mode':\n",
    "            #Принимаем решения без учёта памяти\n",
    "            self.ask_summary = False\n",
    "            self.use_complex_summary = False\n",
    "            self.plan_complex_summary = False\n",
    "            self.actions_from_keyboard = False\n",
    "            self.deterministic_memory = True\n",
    "            self.deterministic_plan = False\n",
    "        \n",
    "        self.random_step_proba = 0.03\n",
    "    def act(self, img):\n",
    "        verbose = False\n",
    "        action = int(np.round(np.random.rand()*7))    \n",
    "        \n",
    "        img_orig = np.array(cv2.resize(img, imsize), dtype=np.float32)/255.\n",
    "        img = preprocess_vqgan(np.stack(1*[img_orig]), True)       \n",
    "\n",
    "        z, _, [_, _, ind] = vq_model.encode(img.to(device))\n",
    "        ind.squeeze_()\n",
    "        b,c,h,w = z.shape\n",
    "        token_string = '<' + '><'.join( [str(el) for el in list(ind.detach().cpu().numpy())] ) + '>'\n",
    "\n",
    "        #запоминаем\n",
    "        if self.ask_summary:\n",
    "            description_name = 'summarize'\n",
    "        else:\n",
    "            description_name = 'description'\n",
    "        text_for_summary_complex = f\"<IN>{self.prev_summary}{token_string} {description_name}:<OUT>\"\n",
    "        text_for_summary_simple = f\"<IN>{token_string} {description_name}:<OUT>\"\n",
    "        self.desc_simple = answer(text_for_summary_simple, self.max_summary_write, random=self.deterministic_memory)\n",
    "        \n",
    "        answer(text_for_summary_simple, self.max_summary_write, random=self.deterministic_memory)\n",
    "       \n",
    "        \n",
    "        if self.use_complex_summary:\n",
    "            self.summary = answer(text_for_summary_complex, self.max_summary_write, random=self.deterministic_memory)\n",
    "            if verbose:\n",
    "                print('asked cplx summary:  ',text_for_summary_complex)\n",
    "                print('answer:  ', self.summary)\n",
    "                index = lines.find(text_for_summary_complex)\n",
    "                offset = 150\n",
    "                if index>=0:\n",
    "                    print('ans in DATASET:', lines[index + 81*4 - 1: index + 81*4 + offset])\n",
    "                    \n",
    "            self.summary_simple = ''\n",
    "        else:\n",
    "            #self.summary = answer(text_for_summary_simple, self.max_summary_write, random=self.deterministic_memory)\n",
    "            self.summary = self.desc_simple\n",
    "            if verbose:\n",
    "                print('asked descr summary:  ',text_for_summary_simple)\n",
    "                print('answer:  ', self.summary)\n",
    "                index = lines.find(text_for_summary_simple)\n",
    "                offset = 150\n",
    "                if index>=0:\n",
    "                    print('ans in DATASET:', lines[index + 81*4 - 1: index + 81*4 + offset])\n",
    "            self.summary_simple = self.summary\n",
    "            self.summary = self.prev_summary + ';' + self.summary\n",
    "            #if verbose:\n",
    "            #    print('final summary', self.summary)\n",
    "            \n",
    "        \n",
    "        #планируем\n",
    "        if self.descriptions_to_actions:\n",
    "            self.desc_simple_if_need = self.desc_simple\n",
    "        else:\n",
    "            self.desc_simple_if_need = ''\n",
    "        text_for_plan_complex = f\"<IN>{self.prev_summary}{token_string}{self.desc_simple_if_need} {self.task} plan:<OUT>\"\n",
    "        text_for_plan_simple = f\"<IN>{token_string}{self.desc_simple_if_need} {self.task} plan:<OUT>\"\n",
    "        \n",
    "        if self.descriptions_to_history:\n",
    "            self.desc_simple_if_need = self.desc_simple\n",
    "        else:\n",
    "            self.desc_simple_if_need = ''\n",
    "        text_for_plan_complex4logs = f\"<IN>{self.prev_summary}{token_string}{self.desc_simple_if_need} {self.task} plan:<OUT>\"\n",
    "        text_for_plan_simple4logs = f\"<IN>{token_string}{self.desc_simple_if_need} {self.task} plan:<OUT>\"\n",
    "        if self.actions_from_keyboard:\n",
    "            #num_to_action_desc = {2:'fire', 0:'strafe left', 5:'turn left', 1:'strafe right', 6:'turn right', 3:'move ahead', 7:'use', 4:'move back'}\n",
    "            key_to_action = {'w':'move ahead', 'a':'turn left', 's':'move back', 'd':'turn right', 'q':'strafe left', 'e':'strafe right', 'f':'use', ' ':'fire'}\n",
    "            key = input()\n",
    "            if key in key_to_action.keys():\n",
    "                action = key_to_action[key]\n",
    "            else:\n",
    "                action = num_to_action_desc[int(np.round(np.random.rand()*7))]\n",
    "            plan = action + ','\n",
    "        else:\n",
    "            df_plans = []\n",
    "            for i in range(self.critical_trials):\n",
    "                if self.plan_complex_summary:\n",
    "                    plan = answer(text_for_plan_complex, self.plan_max_tokens, random=self.deterministic_plan)\n",
    "                    if verbose:\n",
    "                        print('asked plan:  ',text_for_plan_complex)\n",
    "                        print('ans plan:  ',plan)\n",
    "                else:\n",
    "                    plan = answer(text_for_plan_simple, self.plan_max_tokens, random=self.deterministic_plan)\n",
    "                    if verbose:\n",
    "                        print('asked plan:  ',text_for_plan_simple)\n",
    "                        print('ans plan:  ',plan)\n",
    "                if self.critical_trials > 1:\n",
    "                    try:\n",
    "                        #проверить\n",
    "                        #f'<<{img_name1}>> plan:{plan} forecast vars: kills:{kills}, hits:{hits}, delta hp:{dhp}, items:{items}<END>\\n'\n",
    "                        check_ask = f'<IN>{token_string} plan:{plan} forecast vars:<OUT>'\n",
    "                        estimation = answer(check_ask, self.plan_max_check_tokens)\n",
    "                        estimation = estimation.replace(' ', '')\n",
    "                        estimation_lst = estimation.split(',')\n",
    "                        estimation_lst = estimation_lst[:6]\n",
    "                        estimation_d = {el.split(':')[0]:el.split(':')[1] for el in estimation_lst}\n",
    "                        if verbose:\n",
    "                            print('estimation', estimation)\n",
    "                        rec = {'kills':estimation_d['kills'], 'hits':estimation_d['hits'], 'plan':plan}\n",
    "                        df_plans.append(rec)\n",
    "                    except Exception:\n",
    "                        pass\n",
    "            if self.critical_trials > 1:\n",
    "                try:\n",
    "                    df_plans = pd.DataFrame(df_plans)\n",
    "                    df_plans['kills'] = df_plans['kills'].astype(float)\n",
    "                    df_plans['hits'] = df_plans['hits'].astype(float)\n",
    "                    df_plans['q'] = df_plans['kills'] + df_plans['hits']*0.3\n",
    "                    amax = df_plans.q.argmax()\n",
    "                    plan = df_plans.plan.iloc[amax]\n",
    "                    if verbose:\n",
    "                        print('df_plans', df_plans)\n",
    "                        print('plan', plan)\n",
    "                    #if df_plans['q'].max() != df_plans['q'].min():\n",
    "                    #    print('critical: made plan q=', df_plans['q'].max(), 'qmin=', df_plans['q'].min())\n",
    "                except Exception:\n",
    "                        pass\n",
    "                    \n",
    "            \n",
    "\n",
    "        plan_action_idx = plan.find(',')\n",
    "        if plan_action_idx>0:\n",
    "            plan_action = plan[:plan_action_idx]\n",
    "            if verbose:\n",
    "                print('plan_action:  ',plan_action)\n",
    "\n",
    "            for key in action_to_num_desc.keys():\n",
    "                if key in plan_action:\n",
    "                    #print(key, 'plan', plan)\n",
    "                    action = action_to_num_desc[key]\n",
    "                    if verbose:\n",
    "                        print('key_action:  ',action)\n",
    "                    break\n",
    "            \n",
    "            self.summary += '|' + plan_action + ' '\n",
    "            if len(self.summary)>self.max_summary_show_simbols:\n",
    "                self.summary = self.summary[-self.max_summary_show_simbols:]\n",
    "            self.prev_summary = self.summary\n",
    "        \n",
    "\n",
    "        if self.report_fullstring_search:\n",
    "            if self.plan_complex_summary:\n",
    "                text = text_for_summary_complex\n",
    "            else:\n",
    "                text = text_for_summary_simple\n",
    "            index = lines.find(text)\n",
    "            #print('index', index)\n",
    "            offset = 150\n",
    "            if index>=0:\n",
    "                print('plan in DATASET:', lines[index + 81*4 - 1: index + 81*4 + offset])\n",
    "        \n",
    "        gpt_memory_report = {'text_for_plan_complex': text_for_plan_complex4logs, 'plan': plan, 'text_for_summary_complex': text_for_summary_complex, 'text_for_summary_simple': text_for_summary_simple, 'summary': self.summary, 'summary_simple': self.summary_simple}\n",
    "        \n",
    "        if np.random.rand() < self.random_step_proba:\n",
    "            action = int(np.round(np.random.rand()*7))\n",
    "        if verbose:\n",
    "            print('final key_action:  ',action)\n",
    "        return action, gpt_memory_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt_strategy_inertial(img, action_prev=None, t_now=None):\n",
    "    #почему-то 0 - стрейф влево, 1 - стрейф вправо, 2 - огонь, 3 - use, 4 - вперёд, 5 - turn_right, 6 - turn_left, 7 - back\n",
    "    if t_now is None:\n",
    "        t_now = 0\n",
    "    if t_now%ACTION_PERIOD==0:\n",
    "        action, gpt_memory_report = agent.act(img)\n",
    "        #action = plan_picture(img, task='scouting')\n",
    "        #print(num_to_action_desc[action])\n",
    "        return action, gpt_memory_report\n",
    "    else:\n",
    "        return action_prev, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_txt_memory = '../gpt/chatgpt/data/imgs_descs_memory_3.txt'\n",
    "path_txt_memory = '../gpt/chatgpt/data/imgs_descs_memory_5.txt'\n",
    "path_txt_memory = '../gpt/chatgpt/data/imgs_descs_memory_7.txt'\n",
    "path_txt_memory = '../gpt/chatgpt/data/imgs_descs_memory_8.txt'\n",
    "path_txt_memory = '../gpt/chatgpt/data/imgs_descs_memory_9.txt'\n",
    "path_txt_memory = '../gpt/chatgpt/data/imgs_descs_memory_10.txt'\n",
    "path_txt_memory = '../gpt/chatgpt/data/imgs_descs_memory_11.txt'\n",
    "path_txt_memory = '../gpt/chatgpt/data/imgs_descs_memory_12.txt'\n",
    "#\n",
    "path_txt_memory = '../gpt/chatgpt/data/imgs_descs_memory_13.txt'\n",
    "path_txt_memory = '../gpt/chatgpt/data/imgs_descs_memory_14.txt'\n",
    "\n",
    "path_txt_memory = '../gpt/chatgpt/data/imgs_descs_memory_15.txt'\n",
    "path_txt_memory = '../gpt/chatgpt/data/imgs_descs_memory_16.txt'\n",
    "path_txt_memory = '../gpt/chatgpt/data/imgs_descs_memory_17.txt'\n",
    "path_txt_memory = '../gpt/chatgpt/data/imgs_descs_memory_18.txt'\n",
    "\n",
    "path_txt_memory = '../gpt/chatgpt/data/imgs_descs_memory_19.txt'\n",
    "path_txt_memory = '../gpt/chatgpt/data/imgs_descs_memory_20.txt'\n",
    "path_txt_memory = '../gpt/chatgpt/data/imgs_descs_memory_21.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path_txt_memory = '../gpt/chatgpt/data/imgs_descs_memory_hum.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing doom...\n",
      "Doom initialized.\n",
      "one_frame_mode\n",
      "plan in DATASET: <657><541><945><642><788><729><608><468><140><672><681><675><217><498><562><7> description:<OUT><END>\n",
      "\n",
      "<IN><772><313><577><761><500><250><363><925><425\n",
      "plan in DATASET: 985><494><922><129><552><362><469><608><39><945><230><576><316><217><498><562><414> description:<OUT><OUT><END>\n",
      "\n",
      "<IN><250><821><556><695><965><618><72>\n",
      "reward 0.15\n",
      "reward -0.15\n",
      "reward 2.05\n",
      "reward -0.015\n",
      "reward -0.03\n",
      "reward -0.075\n",
      "reward 1.45\n",
      "reward -0.06\n",
      "reward -0.03\n",
      "reward -0.105\n",
      "reward -0.09\n",
      "episode: 0   score: 3.095 KILLS 2.0 HITS 11.0 ITEMS 0.0\n",
      "full_test_mode\n"
     ]
    }
   ],
   "source": [
    "items_set = []\n",
    "doom_type = 2\n",
    "for mapnum in range(3,33):\n",
    "#for mapnum in range(5,31):\n",
    "    if doom_type==1:\n",
    "        e_num = mapnum//10 + 1\n",
    "        mapnum = mapnum%10\n",
    "        if mapnum==0:\n",
    "            mapnum=1\n",
    "        mapname = f'e{e_num}m{mapnum}'\n",
    "    else:\n",
    "        mapname = str(mapnum)\n",
    "        if mapnum<10:\n",
    "            mapname = '0' + mapname\n",
    "        mapname = 'map' + mapname\n",
    "    #env = initialize_vizdoom(root + 'doom_files/scenarios/doom1.cfg',doom_map=mapname)\n",
    "    env = initialize_vizdoom(root + 'doom_files/scenarios/doom2.cfg',doom_map=mapname)\n",
    "    #env = initialize_vizdoom(root + 'doom_files/scenarios/plutonia.cfg',doom_map=mapname)\n",
    "    \n",
    "    logs_episodes = []\n",
    "    for ep in range(EPISODES):\n",
    "        rnd = np.random.rand()\n",
    "        #'hand_mode' 'simple_test_mode' 'full_test_mode' 'one_frame_mode'\n",
    "        if rnd<0.35:\n",
    "            mode = 'simple_test_mode'\n",
    "        elif rnd<0.68:\n",
    "            mode = 'full_test_mode'\n",
    "        else:\n",
    "            mode = 'one_frame_mode'\n",
    "        #mode = 'one_frame_mode'\n",
    "        print(mode)\n",
    "        #mode = 'hand_mode'\n",
    "        agent = ResultGPT(mode)\n",
    "        \n",
    "        done = False\n",
    "        score = 0\n",
    "        if doom:\n",
    "            env.new_episode()\n",
    "            state_raw = env.get_state()\n",
    "        state = prepare_features(state_raw)\n",
    "\n",
    "        kills = 0\n",
    "        items = 0\n",
    "        health = 100\n",
    "        hits = 0\n",
    "        x_start = env.get_game_variable(GameVariable.POSITION_X)\n",
    "        y_start = env.get_game_variable(GameVariable.POSITION_Y)\n",
    "        z_start = env.get_game_variable(GameVariable.POSITION_Z)\n",
    "        \n",
    "        action = None\n",
    "        t = -1\n",
    "        while not done:\n",
    "            # get action for the current state and go one step in environment\n",
    "            t += 1\n",
    "            action, gpt_memory_report = gpt_strategy_inertial(state_raw.screen_buffer,action, t)\n",
    "            \n",
    "            if doom:\n",
    "                reward = env.make_action(actions[action])\n",
    "                reward = env.get_game_variable(GameVariable.KILLCOUNT)-kills#я считаю как хочу\n",
    "                reward += (env.get_game_variable(GameVariable.ITEMCOUNT)-items)*0.1\n",
    "                reward += (env.get_game_variable(GameVariable.HITCOUNT)-hits)*0.15\n",
    "                reward += (env.get_game_variable(GameVariable.HEALTH)-health)*0.005\n",
    "                kills = env.get_game_variable(GameVariable.KILLCOUNT)\n",
    "                items = env.get_game_variable(GameVariable.ITEMCOUNT)\n",
    "                health = env.get_game_variable(GameVariable.HEALTH)\n",
    "                hits = env.get_game_variable(GameVariable.HITCOUNT)\n",
    "                if t%ACTION_PERIOD==0:\n",
    "                    x = env.get_game_variable(GameVariable.POSITION_X)\n",
    "                    y = env.get_game_variable(GameVariable.POSITION_Y)\n",
    "                    z = env.get_game_variable(GameVariable.POSITION_Z)\n",
    "                    rec = {'ep':ep, 't':int(t/ACTION_PERIOD),'img': state_raw.screen_buffer, 'kills':kills, 'items':items, 'health':health, 'hits':hits, 'action':num_to_action_desc[action], 'x':x - x_start, 'y':y - y_start, 'z':z - z_start}\n",
    "                    for key in gpt_memory_report.keys():\n",
    "                        rec[key] = gpt_memory_report[key]\n",
    "                    logs_episodes.append(rec)\n",
    "                if reward!=0:\n",
    "                    print('reward',reward,flush=True)\n",
    "                try:\n",
    "                    next_state_raw = env.get_state()\n",
    "                except Exception:\n",
    "                    print('cannot parse frame')\n",
    "                #next_state = np.reshape(next_state, [state_size[0], state_size[1], state_size[2]])\n",
    "                done = env.is_episode_finished() or env.is_player_dead()\n",
    "                #if env.is_player_dead():\n",
    "                #    reward = -100\n",
    "            else:\n",
    "                next_state, reward, done, info = env.step(action)\n",
    "\n",
    "            # if an action make the episode end, then gives penalty of -100\n",
    "\n",
    "            if np.random.rand()<0.003:\n",
    "                #запись автоаннотированной картинки\n",
    "                encoded, obj_list, obj_matrix, description = prepare_features(state_raw,extended=True)\n",
    "                img_orig = state_raw.screen_buffer\n",
    "                b,g,r = img_orig[:,:,0], img_orig[:,:,1], img_orig[:,:,2]\n",
    "                img_orig = np.dstack([r, g, b])\n",
    "                \n",
    "                img_name = f\"autoannotated_{str(pd.Timestamp.now()).replace(' ', '_').replace(':', '_').replace('.', '_')}.png\"\n",
    "                description = description + '<END>\\n'\n",
    "                path_txt = '../gpt/chatgpt/data/imgs_descs.txt'\n",
    "                path_img = f'../gpt/chatgpt/data/imgs/{img_name}'\n",
    "                cv2.imwrite(path_img, img_orig)\n",
    "                \n",
    "                \n",
    "                sting_add = f'<<{img_name}>> description:{description}'\n",
    "                with codecs.open(path_txt, 'a', 'utf8') as f:\n",
    "                    f.write(sting_add)\n",
    "                #pass\n",
    "\n",
    "            for obj in state_raw.labels:\n",
    "                items_set.append(obj.object_name)\n",
    "            if np.random.rand()<0.000:\n",
    "                if not (state_raw is None):\n",
    "                    #plt.imshow(state_raw.labels_buffer)\n",
    "                    #plt.show()\n",
    "                    encoded, obj_list, obj_matrix, description = prepare_features(state_raw,extended=True)\n",
    "                    plt.imshow(state_raw.screen_buffer)\n",
    "                    plt.show()\n",
    "                    print(prepare_features(state_raw,True))\n",
    "\n",
    "                    print('enemies')\n",
    "                    plt.imshow(obj_matrix[:,:,0])\n",
    "                    plt.show()\n",
    "                    print('items')\n",
    "                    plt.imshow(obj_matrix[:,:,1])\n",
    "                    plt.show()\n",
    "                    print('projectiles')\n",
    "                    plt.imshow(obj_matrix[:,:,2])\n",
    "                    plt.show()\n",
    "                    print('corpses')\n",
    "                    plt.imshow(obj_matrix[:,:,3])\n",
    "                    plt.show()\n",
    "                    print('other')\n",
    "                    plt.imshow(obj_matrix[:,:,4])\n",
    "                    plt.show()\n",
    "                    print('depth')\n",
    "                    plt.imshow(obj_matrix[:,:,5]/100)\n",
    "                    plt.show()\n",
    "\n",
    "            score += reward\n",
    "            state_raw = next_state_raw\n",
    "\n",
    "            if doom:\n",
    "                if env.is_player_dead():\n",
    "                    # Use this to respawn immediately after death, new state will be available.\n",
    "                    env.respawn_player()\n",
    "\n",
    "            if done:\n",
    "                # every episode, plot the play time\n",
    "\n",
    "                print(\"episode:\", ep, \"  score:\", score, 'KILLS',kills,'HITS',hits,'ITEMS',items,flush=True)\n",
    "                #if score>1:\n",
    "                #    stop_train = True\n",
    "         \n",
    "        \n",
    "    #записать реворды\n",
    "    if 1:\n",
    "        logs_episodes = pd.DataFrame(logs_episodes)\n",
    "        logs_episodes['killpoints'] = logs_episodes['kills'] + logs_episodes['hits']*0.3\n",
    "        logs_episodes['distance'] = logs_episodes['x']**2 + logs_episodes['y']**2 + logs_episodes['z']**2\n",
    "\n",
    "        for start in range(logs_episodes.shape[0]):\n",
    "            subtraj = logs_episodes.iloc[start:start + subtraj_len]\n",
    "            ep = subtraj.ep.iloc[0]\n",
    "            subtraj = subtraj.loc[subtraj.ep == ep]\n",
    "            if subtraj.shape[0]<4:\n",
    "                continue\n",
    "            reward_d = {}\n",
    "            reward_d['dhp'] = 0\n",
    "            reward_d['distance'] = 0\n",
    "            reward_d['killpoints'] = 0\n",
    "            reward_d['items'] = 0\n",
    "            for subtraj_len_cur in [subtraj_len, subtraj_len//2, subtraj_len//4]:\n",
    "                subtraj_cur = subtraj.iloc[:subtraj_len_cur]\n",
    "                reward_d['dhp'] += (subtraj_cur.health.iloc[-1] - subtraj_cur.health.iloc[0]) / subtraj_len_cur\n",
    "                reward_d['distance'] += np.abs(subtraj_cur.distance.iloc[-1] - subtraj_cur.distance.iloc[0]) / subtraj_len_cur\n",
    "                reward_d['killpoints'] += (subtraj_cur.killpoints.iloc[-1] - subtraj_cur.killpoints.iloc[0])/ subtraj_len_cur\n",
    "                reward_d['items'] += (subtraj_cur['items'].iloc[-1] - subtraj_cur['items'].iloc[0]) / subtraj_len_cur\n",
    "            reward_d['dhp'] /= (3 * 5)\n",
    "            reward_d['distance'] /= (3 * 500000)\n",
    "            reward_d['killpoints']/= (3 * 0.1)\n",
    "            reward_d['items'] /= 3\n",
    "\n",
    "            summary_simple = subtraj['summary_simple'].iloc[0]\n",
    "            summary = subtraj['summary'].iloc[0]\n",
    "            plan = ''\n",
    "            len_frc_cur = np.min([subtraj.shape[0], actions_count])\n",
    "            for t in range(len_frc_cur):\n",
    "                if len(subtraj) > t:\n",
    "                    plan += subtraj.action.iloc[t] + ', '\n",
    "\n",
    "            #for goal in ['dhp', 'killpoints', 'items', 'distance']:\n",
    "            for goal in ['killpoints']:\n",
    "                r = reward_d[goal]\n",
    "                path_txt = path_txt_memory\n",
    "                #<<image>> summarize: (обычное описание)\n",
    "                if summary_simple!='':\n",
    "                    sting_add = f\"{subtraj['text_for_summary_simple'].iloc[0]}summarize: {summary_simple}\"\n",
    "                    sting_add = sting_add.replace('description:<OUT>summarize:', 'summarize:<OUT>')\n",
    "                    sting_add += str(reward_make_substr(r))\n",
    "                    with codecs.open(path_txt, 'a', 'utf8') as f:\n",
    "                        f.write(sting_add + '<END>\\n')\n",
    "                #(summary) <<image>>goal plan: (обычный план)\n",
    "                sting_add = f\"{subtraj['text_for_plan_complex'].iloc[0]}{plan}\"\n",
    "                sting_add = sting_add.replace('description:<OUT>summarize:', 'summarize:<OUT>')\n",
    "                sting_add += str(reward_make_substr(r))\n",
    "\n",
    "                with codecs.open(path_txt, 'a', 'utf8') as f:\n",
    "                    f.write(sting_add + '<END>\\n')\n",
    "                #(summary) <<image>> summarize: (прошлое summary); (обычное описание)\n",
    "                sting_add = f\"{subtraj['text_for_summary_complex'].iloc[0]}summarize: {subtraj['summary'].iloc[0]}\"\n",
    "                sting_add = sting_add.replace('description:<OUT>summarize:', 'summarize:<OUT>')\n",
    "                sting_add += str(reward_make_substr(r))\n",
    "\n",
    "                with codecs.open(path_txt, 'a', 'utf8') as f:\n",
    "                    f.write(sting_add + '<END>\\n')\n",
    "\n",
    "        print('written')\n",
    "\n",
    "                        \n",
    "        #отобрать рандомные траектории для прогноза\n",
    "        logs_episodes = pd.DataFrame(logs_episodes)\n",
    "        logs_episodes['killpoints'] = logs_episodes['kills'] + logs_episodes['hits']*0.3\n",
    "        logs_episodes['distance'] = logs_episodes['x']**2 + logs_episodes['y']**2 + logs_episodes['z']**2\n",
    "        #отобрать рандомные траектории для прогноза\n",
    "        frc_count = 160\n",
    "        for frc_num in range(frc_count):\n",
    "            try:\n",
    "                ep = int(np.random.rand()*logs_episodes.ep.max())\n",
    "                traj_num = ep\n",
    "                len_frc_cur = int(frc_len*np.random.rand()) + 1\n",
    "                subtraj_len_cur = len_frc_cur\n",
    "                t_start = int(np.random.rand() * (logs_episodes[logs_episodes.ep == traj_num].t.max() - subtraj_len_cur))\n",
    "                img_start = logs_episodes[(logs_episodes.t==t_start)&(logs_episodes.ep==ep)].img.iloc[0]\n",
    "                b,g,r = img_start[:,:,0], img_start[:,:,1], img_start[:,:,2]\n",
    "                img_start = np.dstack([r, g, b])\n",
    "\n",
    "\n",
    "                img_end = logs_episodes[(logs_episodes.t==t_start + len_frc_cur)&(logs_episodes.ep==ep)].img.iloc[0]\n",
    "                b,g,r = img_end[:,:,0], img_end[:,:,1], img_end[:,:,2]\n",
    "                img_end = np.dstack([r, g, b])\n",
    "\n",
    "                #Прогноз картинки\n",
    "                img_name1 = f\"autofrcstart_{str(pd.Timestamp.now()).replace(' ', '_').replace(':', '_').replace('.', '_')}.png\"\n",
    "                path_img = f'../gpt/chatgpt/data/imgs/{img_name1}'\n",
    "                cv2.imwrite(path_img, img_start)\n",
    "                img_name2 = f\"autofrcend_{str(pd.Timestamp.now()).replace(' ', '_').replace(':', '_').replace('.', '_')}.png\"\n",
    "                path_img = f'../gpt/chatgpt/data/imgs/{img_name2}'\n",
    "                cv2.imwrite(path_img, img_end)\n",
    "\n",
    "                plan = ''\n",
    "                for i in range(len_frc_cur):\n",
    "                    plan += logs_episodes[(logs_episodes.t==t_start+i)&(logs_episodes.ep==ep)].action.iloc[0] + ', '\n",
    "\n",
    "                #forecast\n",
    "                sting_add = f'<<{img_name1}>> plan:{plan} forecast img: <<{img_name2}>><END>\\n'\n",
    "\n",
    "                path_txt = '../gpt/chatgpt/data/imgs_descs.txt'\n",
    "                with codecs.open(path_txt, 'a', 'utf8') as f:\n",
    "                    f.write(sting_add)\n",
    "\n",
    "                #goal agent or calculate diff between frames\n",
    "                sting_add = f'<<{img_name1}>> task: <<{img_name2}>> plan:{plan}<END>\\n'\n",
    "\n",
    "                path_txt = '../gpt/chatgpt/data/imgs_descs.txt'\n",
    "                with codecs.open(path_txt, 'a', 'utf8') as f:\n",
    "                    f.write(sting_add)\n",
    "\n",
    "                #Прогноз переменных\n",
    "                log_start = logs_episodes[(logs_episodes.t==t_start)&(logs_episodes.ep==ep)]\n",
    "                log_end = logs_episodes[(logs_episodes.t==t_start + len_frc_cur)&(logs_episodes.ep==ep)]\n",
    "                kills = int(log_end['kills'].iloc[0] - log_start['kills'].iloc[0])\n",
    "                hits = int(log_end['hits'].iloc[0] - log_start['hits'].iloc[0])\n",
    "                dhp = int(log_end['health'].iloc[0] - log_start['health'].iloc[0])\n",
    "                items = int(log_end['items'].iloc[0] - log_start['items'].iloc[0])\n",
    "                sting_add = f'<<{img_name1}>> plan:{plan} forecast vars: kills:{kills}, hits:{hits}, delta hp:{dhp}, items:{items}<END>\\n'\n",
    "                with codecs.open(path_txt, 'a', 'utf8') as f:\n",
    "                    f.write(sting_add)\n",
    "            except Exception as e:\n",
    "                print('frc error,', e)\n",
    "        print('written frc')\n",
    "\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '<IN><325><730><771><710><916><992><710><26><556><168><517><498><414><845><92><414><663><534><168><323><988><695><526><589><72><287><884><965><868><589><803><897><12><695><263><7><389><462><107><358><187><828><200><202><328><870><746><40><269><913><148><269><417><698><358><245><263><518><685><220><432><66><243><657><58><644><892><129><608><382><624><945><468><140><230><382><371><608><784><713><7> kill all plan:<OUT>'\n",
    "index = lines.find(text)\n",
    "#print('index', index)\n",
    "offset = 250\n",
    "l_offset = 350\n",
    "if index>=0:\n",
    "    print('plan in DATASET:', lines[index + 81*4 - 1 - l_offset: index + 81*4 + offset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subtraj_len = 140\n",
    "#subtraj_selection = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_episodes = pd.DataFrame(logs_episodes)\n",
    "logs_episodes.iloc[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_episodes.iloc[-10:]['summary_simple'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_episodes.iloc[:10]['text_for_summary_simple'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_episodes.iloc[-15:]['summary_simple'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_episodes.iloc[-15:]['text_for_plan_complex'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_description = {'dhp':'save hp', 'killpoints':'kill all', 'items':'pickup items', 'distance': 'scouting'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recoms_count_dense = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path_txt_memory = '../gpt/chatgpt/data/imgs_descs_memory_20.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#записать реворды\n",
    "if 1:\n",
    "    logs_episodes = pd.DataFrame(logs_episodes)\n",
    "    logs_episodes['killpoints'] = logs_episodes['kills'] + logs_episodes['hits']*0.3\n",
    "    logs_episodes['distance'] = logs_episodes['x']**2 + logs_episodes['y']**2 + logs_episodes['z']**2\n",
    "\n",
    "    for start in range(logs_episodes.shape[0]):\n",
    "        subtraj = logs_episodes.iloc[start:start + subtraj_len]\n",
    "        ep = subtraj.ep.iloc[0]\n",
    "        subtraj = subtraj.loc[subtraj.ep == ep]\n",
    "        if subtraj.shape[0]<4:\n",
    "            continue\n",
    "        reward_d = {}\n",
    "        reward_d['dhp'] = 0\n",
    "        reward_d['distance'] = 0\n",
    "        reward_d['killpoints'] = 0\n",
    "        reward_d['items'] = 0\n",
    "        for subtraj_len_cur in [subtraj_len, subtraj_len//2, subtraj_len//4]:\n",
    "            subtraj_cur = subtraj.iloc[:subtraj_len_cur]\n",
    "            reward_d['dhp'] += (subtraj_cur.health.iloc[-1] - subtraj_cur.health.iloc[0]) / subtraj_len_cur\n",
    "            reward_d['distance'] += np.abs(subtraj_cur.distance.iloc[-1] - subtraj_cur.distance.iloc[0]) / subtraj_len_cur\n",
    "            reward_d['killpoints'] += (subtraj_cur.killpoints.iloc[-1] - subtraj_cur.killpoints.iloc[0])/ subtraj_len_cur\n",
    "            reward_d['items'] += (subtraj_cur['items'].iloc[-1] - subtraj_cur['items'].iloc[0]) / subtraj_len_cur\n",
    "        reward_d['dhp'] /= (3 * 5)\n",
    "        reward_d['distance'] /= (3 * 500000)\n",
    "        reward_d['killpoints']/= (3 * 0.1)\n",
    "        reward_d['items'] /= 3\n",
    "\n",
    "        summary_simple = subtraj['summary_simple'].iloc[0]\n",
    "        summary = subtraj['summary'].iloc[0]\n",
    "        plan = ''\n",
    "        len_frc_cur = np.min([subtraj.shape[0], actions_count])\n",
    "        for t in range(len_frc_cur):\n",
    "            if len(subtraj) > t:\n",
    "                plan += subtraj.action.iloc[t] + ', '\n",
    "\n",
    "        #for goal in ['dhp', 'killpoints', 'items', 'distance']:\n",
    "        for goal in ['killpoints']:\n",
    "            r = reward_d[goal]\n",
    "            path_txt = path_txt_memory\n",
    "            #<<image>> summarize: (обычное описание)\n",
    "            if summary_simple!='':\n",
    "                sting_add = f\"{subtraj['text_for_summary_simple'].iloc[0]}summarize: {summary_simple}\"\n",
    "                sting_add = sting_add.replace('description:<OUT>summarize:', 'summarize:<OUT>')\n",
    "                sting_add += str(reward_make_substr(r))\n",
    "                with codecs.open(path_txt, 'a', 'utf8') as f:\n",
    "                    f.write(sting_add + '<END>\\n')\n",
    "            #(summary) <<image>>goal plan: (обычный план)\n",
    "            sting_add = f\"{subtraj['text_for_plan_complex'].iloc[0]}{plan}\"\n",
    "            sting_add = sting_add.replace('description:<OUT>summarize:', 'summarize:<OUT>')\n",
    "            sting_add += str(reward_make_substr(r))\n",
    "\n",
    "            with codecs.open(path_txt, 'a', 'utf8') as f:\n",
    "                f.write(sting_add + '<END>\\n')\n",
    "            #(summary) <<image>> summarize: (прошлое summary); (обычное описание)\n",
    "            sting_add = f\"{subtraj['text_for_summary_complex'].iloc[0]}summarize: {subtraj['summary'].iloc[0]}\"\n",
    "            sting_add = sting_add.replace('description:<OUT>summarize:', 'summarize:<OUT>')\n",
    "            sting_add += str(reward_make_substr(r))\n",
    "            if '-' in reward_make_substr(r):\n",
    "                1/0\n",
    "            with codecs.open(path_txt, 'a', 'utf8') as f:\n",
    "                f.write(sting_add + '<END>\\n')\n",
    "            print('r', r)\n",
    "\n",
    "    print('written')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#отобрать рандомные траектории для прогноза\n",
    "logs_episodes = pd.DataFrame(logs_episodes)\n",
    "logs_episodes['killpoints'] = logs_episodes['kills'] + logs_episodes['hits']*0.3\n",
    "logs_episodes['distance'] = logs_episodes['x']**2 + logs_episodes['y']**2 + logs_episodes['z']**2\n",
    "#отобрать рандомные траектории для прогноза\n",
    "frc_count = 40\n",
    "for frc_num in range(frc_count):\n",
    "    ep = int(np.random.rand()*logs_episodes.ep.max())\n",
    "    traj_num = ep\n",
    "    len_frc_cur = int(frc_len*np.random.rand()) + 1\n",
    "    subtraj_len_cur = len_frc_cur\n",
    "    t_start = int(np.random.rand() * (logs_episodes[logs_episodes.ep == traj_num].t.max() - subtraj_len_cur))\n",
    "    img_start = logs_episodes[(logs_episodes.t==t_start)&(logs_episodes.ep==ep)].img.iloc[0]\n",
    "    b,g,r = img_start[:,:,0], img_start[:,:,1], img_start[:,:,2]\n",
    "    img_start = np.dstack([r, g, b])\n",
    "\n",
    "\n",
    "    img_end = logs_episodes[(logs_episodes.t==t_start + len_frc_cur)&(logs_episodes.ep==ep)].img.iloc[0]\n",
    "    b,g,r = img_end[:,:,0], img_end[:,:,1], img_end[:,:,2]\n",
    "    img_end = np.dstack([r, g, b])\n",
    "\n",
    "    #Прогноз картинки\n",
    "    img_name1 = f\"autofrcstart_{str(pd.Timestamp.now()).replace(' ', '_').replace(':', '_').replace('.', '_')}.png\"\n",
    "    path_img = f'../gpt/chatgpt/data/imgs/{img_name1}'\n",
    "    cv2.imwrite(path_img, img_start)\n",
    "    img_name2 = f\"autofrcend_{str(pd.Timestamp.now()).replace(' ', '_').replace(':', '_').replace('.', '_')}.png\"\n",
    "    path_img = f'../gpt/chatgpt/data/imgs/{img_name2}'\n",
    "    cv2.imwrite(path_img, img_end)\n",
    "\n",
    "    plan = ''\n",
    "    for i in range(len_frc_cur):\n",
    "        plan += logs_episodes[(logs_episodes.t==t_start+i)&(logs_episodes.ep==ep)].action.iloc[0] + ', '\n",
    "\n",
    "    #forecast\n",
    "    sting_add = f'<<{img_name1}>> plan:{plan} forecast img: <<{img_name2}>><END>\\n'\n",
    "\n",
    "    path_txt = '../gpt/chatgpt/data/imgs_descs.txt'\n",
    "    with codecs.open(path_txt, 'a', 'utf8') as f:\n",
    "        f.write(sting_add)\n",
    "\n",
    "    #goal agent or calculate diff between frames\n",
    "    sting_add = f'<<{img_name1}>> task: <<{img_name2}>> plan:{plan}<END>\\n'\n",
    "\n",
    "    path_txt = '../gpt/chatgpt/data/imgs_descs.txt'\n",
    "    with codecs.open(path_txt, 'a', 'utf8') as f:\n",
    "        f.write(sting_add)\n",
    "\n",
    "    #Прогноз переменных\n",
    "    log_start = logs_episodes[(logs_episodes.t==t_start)&(logs_episodes.ep==ep)]\n",
    "    log_end = logs_episodes[(logs_episodes.t==t_start + len_frc_cur)&(logs_episodes.ep==ep)]\n",
    "    kills = int(log_end['kills'].iloc[0] - log_start['kills'].iloc[0])\n",
    "    hits = int(log_end['hits'].iloc[0] - log_start['hits'].iloc[0])\n",
    "    dhp = int(log_end['health'].iloc[0] - log_start['health'].iloc[0])\n",
    "    items = int(log_end['items'].iloc[0] - log_start['items'].iloc[0])\n",
    "    sting_add = f'<<{img_name1}>> plan:{plan} forecast vars: kills:{kills}, hits:{hits}, delta hp:{dhp}, items:{items}<END>\\n'\n",
    "    with codecs.open(path_txt, 'a', 'utf8') as f:\n",
    "        f.write(sting_add)\n",
    "    print('written frc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#запись в файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_episodes = pd.DataFrame(logs_episodes)\n",
    "idx = logs_episodes.ep==0\n",
    "video = logs_episodes['img'].values\n",
    "video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#video = video[-153:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#записать видео\n",
    "#draw video\n",
    "import cv2\n",
    "name = 'map13'\n",
    "path = f\"./out_videos/{name}.mp4\"\n",
    "writer = cv2.VideoWriter(path,cv2.VideoWriter_fourcc(*\"MP4V\"),30//8,(512,512))\n",
    "for i in range(0,len(video),1):\n",
    "    resize = cv2.resize(np.array(video[i]), (512, 512))\n",
    "    frame = resize*0\n",
    "    frame[:,:,0],frame[:,:,1],frame[:,:,2] = resize[:,:,2],resize[:,:,1], resize[:,:,0]\n",
    "    writer.write(frame)\n",
    "writer.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from moviepy.editor import ImageSequenceClip\n",
    "\n",
    "video = np.array(video)\n",
    "path = f\"./out_videos/{name}.gif\"\n",
    "def gif(filename, array, fps=10, scale=1.0):\n",
    "    \"\"\"Creates a gif given a stack of images using moviepy\n",
    "    Notes\n",
    "    -----\n",
    "    works with current Github version of moviepy (not the pip version)\n",
    "    https://github.com/Zulko/moviepy/commit/d4c9c37bc88261d8ed8b5d9b7c317d13b2cdf62e\n",
    "    Usage\n",
    "    -----\n",
    "    >>> X = randn(100, 64, 64)\n",
    "    >>> gif('test.gif', X)\n",
    "    Parameters\n",
    "    ----------\n",
    "    filename : string\n",
    "        The filename of the gif to write to\n",
    "    array : array_like\n",
    "        A numpy array that contains a sequence of images\n",
    "    fps : int\n",
    "        frames per second (default: 10)\n",
    "    scale : float\n",
    "        how much to rescale each image by (default: 1.0)\n",
    "    \"\"\"\n",
    "\n",
    "    # ensure that the file has the .gif extension\n",
    "    fname, _ = os.path.splitext(filename)\n",
    "    filename = fname + '.gif'\n",
    "\n",
    "    # copy into the color dimension if the images are black and white\n",
    "    if array.ndim == 3:\n",
    "        array = array[..., np.newaxis] * np.ones(3)\n",
    "\n",
    "    # make the moviepy clip\n",
    "    clip = ImageSequenceClip(list(array), fps=fps).resize(scale)\n",
    "    clip.write_gif(filename, fps=fps)\n",
    "    return clip\n",
    "\n",
    "gif(path, video, fps=10, scale=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Выяснить, сколько времени идёт preprocess_vqgan на GPU и на CPU. GPU: 0 days 00:00:00.016816540 CPU: 0 days 00:00:00.268827660\n",
    "Выяснить, сколько времени идёт answer на GPU и на CPU. GPU: 0 days 00:00:01.682268666 CPU: 0 days 00:00:08.292097500\n",
    "Выяснить, сколько времени идёт encode, generate, decode на GPU\n",
    "encode 0 days 00:00:00.000166833\n",
    "model.generate 0 days 00:00:01.663960\n",
    "decode 0 days 00:00:00.000083500\n",
    "model.generate \n",
    "tokp=1 gener_len=1 0 days 00:00:00.041204083\n",
    "tokp=1 max_length=1 0 days 00:00:00.043289416\n",
    "tokp=10 gener_len=1 0 days 00:00:00.041537666\n",
    "tokp=10 max_length=1 0 days 00:00:00.042955833\n",
    "tokp=1 gener_len=10 0 days 00:00:00.273122166\n",
    "tokp=1 max_length=10 0 days 00:00:00.042081250\n",
    "tokp=10 gener_len=100 0 days 00:00:02.356350416 !!!\n",
    "tokp=10 max_length=100 0 days 00:00:00.379942250\n",
    "Время генерации ~gener_len и ~tokp\n",
    "Итого, генерация занимает 1.6 для генерации описания (70 токенов. Если сделать 40 токенов, то 1.08). Если генерировать только план, получится 00.27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "example_autoencoder_rl.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
