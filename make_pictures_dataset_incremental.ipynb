{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98f3259",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VQ-GAN 1024 \n",
    "Model = \"f16_1024\" #param [\"f16_1024\", \"f16_16384\", \"f16_16384_hf\"]\n",
    "import cv2\n",
    "import torch\n",
    "import yaml\n",
    "import torch\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from omegaconf import OmegaConf\n",
    "from taming.models.vqgan import VQModel\n",
    "\n",
    "def load_config(config_path, display=False):\n",
    "  config = OmegaConf.load(config_path)\n",
    "  if display:\n",
    "    print(yaml.dump(OmegaConf.to_container(config)))\n",
    "  return config\n",
    "\n",
    "def load_vqgan(config, ckpt_path=None):\n",
    "  model = VQModel(**config.model.params)\n",
    "  if ckpt_path is not None:\n",
    "    sd = torch.load(ckpt_path, map_location=\"cpu\")[\"state_dict\"]\n",
    "    missing, unexpected = model.load_state_dict(sd, strict=False)\n",
    "  return model.eval()\n",
    "\n",
    "def preprocess_vqgan(x, roll=True):\n",
    "  x = 2.*x - 1.\n",
    "  if roll:\n",
    "    x = np.rollaxis(x,3,1)\n",
    "  x = torch.Tensor(x)\n",
    "  return x\n",
    "\n",
    "def preprocess(x, permt=True):\n",
    "  if permt:\n",
    "    x = x.permute(0,2,3,1).numpy()\n",
    "  x = np.clip(x, -1., 1.)\n",
    "  x = (x + 1.)/2.\n",
    "  return x\n",
    "\n",
    "def custom_to_pil(x):\n",
    "  x = np.clip(x, -1., 1.)\n",
    "  x = (x + 1.)/2.\n",
    "  x = (255*x).astype(np.uint8)\n",
    "  x = Image.fromarray(x)\n",
    "  if not x.mode == \"RGB\":\n",
    "    x = x.convert(\"RGB\")\n",
    "  return x\n",
    "\n",
    "vq_conf = load_config(f\"chk_points/vqgan_imagenet_{Model}.yaml\", display=False)\n",
    "vq_model = load_vqgan(vq_conf, ckpt_path=f\"chk_points/vqgan_imagenet_{Model}.ckpt\").to('cuda')\n",
    "\n",
    "'''\n",
    "sz = []\n",
    "\n",
    "plt.figure(figsize=(20, 40))\n",
    "img_rec = []\n",
    "for i in range(1):\n",
    "  #quant_states, indices = V_encoder.encode(DS.obs[i+2][0])\n",
    "  x = preprocess_vqgan(DS.obs[i+2])\n",
    "  with torch.no_grad():\n",
    "    z, _, [_, _, ind] = vq_model.encode(x.to('cuda'))\n",
    "    b,c,h,w = z.shape\n",
    "    nz = vq_model.quantize.get_codebook_entry(ind, (b,h,w,c))\n",
    "    rec = vq_model.decode(nz).detach().cpu()\n",
    "    sz.append(h*w)\n",
    "  #print(rec.shape)\n",
    "  img_rec.append(preprocess(rec))\n",
    "\n",
    "for i in range(1):\n",
    "  for j in range(1):\n",
    "    plt.subplot(10, 6, i*6+j+1)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(DS.obs[j+2][i])\n",
    "    plt.title(f'origin {DS.obs[j+2][i].shape}')\n",
    "  for j in range(1):\n",
    "    plt.subplot(10, 6, i*6+j+4)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img_rec[j][i])\n",
    "    plt.title(f'sintetic {sz[j]} token')\n",
    "\n",
    "plt.show();\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac27df97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "#time.sleep(3600*8)#16:00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5790816e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.Timestamp.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b4bc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "imsize = [16*9, 16*9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ab0f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "if 1:\n",
    "    path = './data/imgs_descs.txt'\n",
    "    with codecs.open(f'{path}', 'r', 'utf8', errors='ignore') as f:\n",
    "        #full_text_list = ''.join(f.readlines())\n",
    "        full_text_list = f.readlines()\n",
    "if 0:    \n",
    "    path = './data/image_annotations_plans.txt'\n",
    "    with codecs.open(f'{path}', 'r', 'utf8', errors='ignore') as f:\n",
    "        #full_text_list = ''.join(f.readlines())\n",
    "        full_text_list = f.readlines()\n",
    "    \n",
    "path = './data/image_annotations_plans.txt'\n",
    "with codecs.open(f'{path}', 'r', 'utf8', errors='ignore') as f:\n",
    "    annotated_text_list = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4004d1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_for_annotation = full_text_list[len(annotated_text_list):]\n",
    "print('to add:', len(text_for_annotation))\n",
    "text_for_annotation = ''.join(text_for_annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387d1f0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "p = Path(\"./data/imgs\")\n",
    "i = 0\n",
    "for img_name in p.rglob(\"*\"):\n",
    "    img_name_short = str(img_name).replace('data\\imgs\\\\', '')\n",
    "    if img_name_short in text_for_annotation:\n",
    "        i += 1\n",
    "        #скачать и декодировать картинку\n",
    "        img_orig = np.array(cv2.resize(cv2.imread(str(img_name)), imsize), dtype=np.float32)/255.\n",
    "        b,g,r = img_orig[:,:,0], img_orig[:,:,1], img_orig[:,:,2]\n",
    "        img_orig = np.dstack([r, g, b])\n",
    "        img = preprocess_vqgan(np.stack(1*[img_orig]), True)       \n",
    "        \n",
    "        z, _, [_, _, ind] = vq_model.encode(img.to('cuda'))\n",
    "        ind.squeeze_()\n",
    "        b,c,h,w = z.shape\n",
    "        #nz = vq_model.quantize.get_codebook_entry(ind, (b,h,w,c))\n",
    "        #print('nz', nz)\n",
    "        token_string = '<' + '><'.join( [str(el) for el in list(ind.detach().cpu().numpy())] ) + '>'\n",
    "        nz = vq_model.quantize.get_codebook_entry(ind, (b,h,w,c))\n",
    "        rec = vq_model.decode(nz).detach().cpu()\n",
    "        if np.random.rand()<0.002:\n",
    "            print(i)\n",
    "            plt.imshow(img_orig)\n",
    "            plt.show()\n",
    "            plt.imshow(preprocess(rec)[0])\n",
    "            plt.show()\n",
    "        \n",
    "        \n",
    "        text_for_annotation = text_for_annotation.replace(f'<<{img_name_short}>>', token_string)\n",
    "        \n",
    "#text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c1f9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_for_annotation = text_for_annotation.replace('description:', 'description:<OUT>').replace('forecast vars:', 'forecast vars:<OUT>').replace('forecast img:', 'forecast img:<OUT>').replace('plan:', 'plan:<OUT>').replace('<END>\\r\\n', '<END>\\r\\n<IN>')\n",
    "#text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094aef5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with codecs.open('data/image_annotations_plans.txt', 'a', 'utf8') as f:\n",
    "    f.write(text_for_annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36220c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './data/image_annotations_plans.txt'\n",
    "with codecs.open(f'{path}', 'r', 'utf8', errors='ignore') as f:\n",
    "    annotated_text = ''.join(f.readlines())\n",
    "for num in range(10):\n",
    "    annotated_text = annotated_text.replace(f'<END>\\n<{num}', f'<END>\\n<IN><{num}').replace(f'<END>\\r\\n<{num}', f'<END>\\n<IN><{num}').replace('<IN><IN>', \"<IN>\")\n",
    "\n",
    "with codecs.open('data/image_annotations_plans.txt', 'w', 'utf8') as f:\n",
    "    f.write(annotated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b1a069",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.Timestamp.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effacbdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e0dd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#обновить all_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553d9a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#аннотированные картинки\n",
    "path = 'data/image_annotations_plans.txt' \n",
    "with codecs.open(f'{path}', 'r', 'utf8') as f:\n",
    "    texts = ''.join(f.readlines())\n",
    "texts = texts.replace('<s>', '<END>').replace('\\r\\n', '\\n').replace('</s>', '')\n",
    "#.replace('<IN>', '')\n",
    "texts = texts.replace('>f', '> f').replace('>d', '> d').replace('>p', '> p').replace('>s', '> s').replace('>k', '> k').replace('  ', ' ').replace('\\n', '\\n<IN>').replace('<IN><IN>', '<IN>')\n",
    "print('texts', len(texts))\n",
    "with codecs.open('data/all_txt.txt', 'w', 'utf8') as f:\n",
    "    f.write(texts)\n",
    "    \n",
    "    \n",
    "def process_book(path, drop_spaces=True):  \n",
    "    with codecs.open(f'{path}', 'r', 'utf8', errors='ignore') as f:\n",
    "        texts = ''.join(f.readlines())\n",
    "    texts = texts.replace('<s>', '<END>').replace('\\r\\n', '\\n').replace('</s>', '')\n",
    "    if drop_spaces:\n",
    "        texts = texts.replace('\\n', '\\t')#у нас датасет такой\n",
    "        texts = '\\n' + texts\n",
    "    print(path, 'texts', len(texts))\n",
    "    with codecs.open('data/all_txt.txt', 'a', 'utf8') as f:\n",
    "        f.write(texts)\n",
    "#вики\n",
    "path = 'data/wiki_data.txt'\n",
    "process_book(path)\n",
    "process_book(path, drop_spaces=False)\n",
    "\n",
    "    \n",
    "#/toy_text_doom_tasks\n",
    "path = 'data/toy_text_doom_tasks.txt'     \n",
    "process_book(path, drop_spaces=False)\n",
    "    \n",
    "#logic\n",
    "path = 'data/formal_logic_textbook.txt'     \n",
    "process_book(path)\n",
    "process_book(path, drop_spaces=False)\n",
    "    \n",
    "    \n",
    "#hpmor\n",
    "path = 'data/hpmor.txt'     \n",
    "process_book(path)   \n",
    "process_book(path, drop_spaces=False)\n",
    "\n",
    "path = \"data/Book 1 - The Philosopher's Stone.txt\"\n",
    "process_book(path)   \n",
    "process_book(path, drop_spaces=False)\n",
    "\n",
    "path = 'data/Book 2 - The Chamber of Secrets.txt'\n",
    "process_book(path)\n",
    "process_book(path, drop_spaces=False)\n",
    "\n",
    "path = 'data/Book 4 - The Goblet of Fire.txt'\n",
    "process_book(path)\n",
    "process_book(path, drop_spaces=False)\n",
    "    \n",
    "#rationality.txt\n",
    "path = 'data/Map and Territory.txt'     \n",
    "process_book(path)\n",
    "process_book(path, drop_spaces=False)\n",
    "\n",
    "path = 'data/doom fanfics.txt' \n",
    "process_book(path)\n",
    "process_book(path, drop_spaces=False)\n",
    "\n",
    "path = 'data/treasure island.txt' \n",
    "process_book(path)\n",
    "process_book(path, drop_spaces=False)\n",
    "\n",
    "path = 'data/robinson crusoe.txt' \n",
    "process_book(path)\n",
    "process_book(path, drop_spaces=False)\n",
    "\n",
    "path = 'data/Sherlock Holmes.txt' \n",
    "process_book(path)\n",
    "\n",
    "path = 'data/scrum.txt' \n",
    "process_book(path)\n",
    "process_book(path, drop_spaces=False)\n",
    "\n",
    "path = 'data/military stories.txt' \n",
    "process_book(path)\n",
    "process_book(path, drop_spaces=False)\n",
    "\n",
    "path = 'data/military stories 2.txt' \n",
    "process_book(path)\n",
    "process_book(path, drop_spaces=False)\n",
    "\n",
    "path = 'data/doom wiki.txt'\n",
    "process_book(path)\n",
    "process_book(path, drop_spaces=False)\n",
    "\n",
    "path = 'data/homm.txt'\n",
    "process_book(path)\n",
    "process_book(path, drop_spaces=False)\n",
    "\n",
    "path = 'data/military materials.txt'\n",
    "process_book(path)\n",
    "process_book(path, drop_spaces=False)\n",
    "\n",
    "path = 'data/military materials 2.txt'\n",
    "process_book(path)\n",
    "process_book(path, drop_spaces=False)\n",
    "\n",
    "path = 'data/anatomy.txt'\n",
    "process_book(path)\n",
    "process_book(path, drop_spaces=False)\n",
    "\n",
    "path = 'data/churchill.txt'\n",
    "process_book(path)\n",
    "process_book(path, drop_spaces=False)\n",
    "\n",
    "path = 'data/summary_data.txt'\n",
    "process_book(path, drop_spaces=False)\n",
    "\n",
    "path = 'data/dialogues_text.txt'\n",
    "process_book(path, drop_spaces=False)\n",
    "\n",
    "path = 'data/chat_data.txt'\n",
    "process_book(path, drop_spaces=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fdea92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#аннотированные картинки с памятью\n",
    "path = 'data/imgs_descs_memory.txt' \n",
    "with codecs.open(f'{path}', 'r', 'utf8') as f:\n",
    "    texts += '\\n' + ''.join(f.readlines())\n",
    "print('texts', len(texts))\n",
    "\n",
    "path = 'data/imgs_descs_memory_2.txt' \n",
    "with codecs.open(f'{path}', 'r', 'utf8') as f:\n",
    "    texts += '\\n' + ''.join(f.readlines())\n",
    "print('texts', len(texts))\n",
    "\n",
    "path = 'data/imgs_descs_memory_3.txt' \n",
    "with codecs.open(f'{path}', 'r', 'utf8') as f:\n",
    "    texts += '\\n' + ''.join(f.readlines())\n",
    "print('texts', len(texts))\n",
    "\n",
    "path = 'data/imgs_descs_memory_4.txt' \n",
    "with codecs.open(f'{path}', 'r', 'utf8') as f:\n",
    "    texts += '\\n' + ''.join(f.readlines())\n",
    "print('texts', len(texts))\n",
    "\n",
    "path = 'data/imgs_descs_memory_5.txt' \n",
    "with codecs.open(f'{path}', 'r', 'utf8') as f:\n",
    "    texts += '\\n' + ''.join(f.readlines())\n",
    "print('texts', len(texts))\n",
    "    \n",
    "path = 'data/imgs_descs_memory_6.txt' \n",
    "with codecs.open(f'{path}', 'r', 'utf8') as f:\n",
    "    texts += '\\n' + ''.join(f.readlines())\n",
    "print('texts', len(texts))\n",
    "    \n",
    "path = 'data/imgs_descs_memory_7.txt' \n",
    "with codecs.open(f'{path}', 'r', 'utf8') as f:\n",
    "    texts += '\\n' + ''.join(f.readlines())\n",
    "print('texts', len(texts))\n",
    "    \n",
    "path = 'data/imgs_descs_memory_8.txt' \n",
    "with codecs.open(f'{path}', 'r', 'utf8') as f:\n",
    "    texts += '\\n' + ''.join(f.readlines())\n",
    "print('texts', len(texts))\n",
    "\n",
    "path = 'data/imgs_descs_memory_9.txt' \n",
    "with codecs.open(f'{path}', 'r', 'utf8') as f:\n",
    "    texts += '\\n' + ''.join(f.readlines())\n",
    "print('texts', len(texts))\n",
    "\n",
    "path = 'data/imgs_descs_memory_10.txt' \n",
    "with codecs.open(f'{path}', 'r', 'utf8') as f:\n",
    "    texts += '\\n' + ''.join(f.readlines())\n",
    "print('texts', len(texts))\n",
    "\n",
    "path = 'data/imgs_descs_memory_11.txt' \n",
    "with codecs.open(f'{path}', 'r', 'utf8') as f:\n",
    "    texts += '\\n' + ''.join(f.readlines())\n",
    "print('texts', len(texts))\n",
    "\n",
    "\n",
    "texts = texts.replace('<s>', '<END>').replace('\\r\\n', '\\n').replace('</s>', '')\n",
    "with codecs.open('data/all_txt.txt', 'a', 'utf8') as f:\n",
    "    f.write(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115ba5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.Timestamp.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afad3275",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cut text\n",
    "import codecs\n",
    "thresh = 30000000\n",
    "with codecs.open('data/all_txt.txt', 'r', 'utf8', errors='ignore') as f:\n",
    "    lines = f.readlines()\n",
    "lines = [line[:thresh] for line in lines]\n",
    "lines = '\\n'.join(lines)\n",
    "\n",
    "with codecs.open('data/all_txt_cut.txt', 'w', 'utf8') as f:\n",
    "    f.write(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fceda555",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318613fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f927f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_to_tokens(path):\n",
    "    img_orig = np.array(cv2.resize(cv2.imread(str(path)), imsize), dtype=np.float32)/255.\n",
    "    b,g,r = img_orig[:,:,0], img_orig[:,:,1], img_orig[:,:,2]\n",
    "    img_orig = np.dstack([r, g, b])\n",
    "    img = preprocess_vqgan(np.stack(1*[img_orig]), True)       \n",
    "\n",
    "    z, _, [_, _, ind] = vq_model.encode(img.to('cuda'))\n",
    "    ind.squeeze_()\n",
    "    token_string = '<' + '><'.join( [str(el) for el in list(ind.detach().cpu().numpy())] ) + '>'\n",
    "    return ind, token_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987e7331",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './data/imgs/images (2).jpg'\n",
    "img_to_tokens(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6376480e",
   "metadata": {},
   "outputs": [],
   "source": [
    "1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a4d187",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c160d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
